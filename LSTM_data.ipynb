{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install pandas\n",
    "!pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose_time</th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-05 00:05:00</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-05 00:10:00</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-05 00:15:00</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-05 00:20:00</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-05 00:25:00</td>\n",
       "      <td>116.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Glucose_time  reading\n",
       "0  2023-03-05 00:05:00    115.0\n",
       "1  2023-03-05 00:10:00    115.0\n",
       "2  2023-03-05 00:15:00    114.0\n",
       "3  2023-03-05 00:20:00    116.0\n",
       "4  2023-03-05 00:25:00    116.5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./CSV_Files/resampled_glucose_data.csv\")\n",
    "# Drop all the columns which have unnamed in them\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:05:00</th>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:10:00</th>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:15:00</th>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:20:00</th>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:25:00</th>\n",
       "      <td>116.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     reading\n",
       "Glucose_time                \n",
       "2023-03-05 00:05:00    115.0\n",
       "2023-03-05 00:10:00    115.0\n",
       "2023-03-05 00:15:00    114.0\n",
       "2023-03-05 00:20:00    116.0\n",
       "2023-03-05 00:25:00    116.5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the Glucose_time to datetime format and set it as the index\n",
    "df['Glucose_time'] = pd.to_datetime(df['Glucose_time'])\n",
    "df.set_index('Glucose_time', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:05:00</th>\n",
       "      <td>0.840909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:10:00</th>\n",
       "      <td>0.840909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:15:00</th>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:20:00</th>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:25:00</th>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      reading\n",
       "Glucose_time                 \n",
       "2023-03-05 00:05:00  0.840909\n",
       "2023-03-05 00:10:00  0.840909\n",
       "2023-03-05 00:15:00  0.818182\n",
       "2023-03-05 00:20:00  0.863636\n",
       "2023-03-05 00:25:00  0.875000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['reading'] = scaler.fit_transform(df[['reading']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(time_series_data, n_features):\n",
    "    X, y = [], []\n",
    "    for i in range(len(time_series_data)):\n",
    "        end_ix = i + n_features\n",
    "        if end_ix > len(time_series_data)-1:\n",
    "            break\n",
    "        seq_x, seq_y = time_series_data[i:end_ix], time_series_data[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_lst = [2, 4, 5, 6, 8, 10]\n",
    "patience_lst = [5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_data = df['reading'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameter = {}\n",
    "best_rmse = float('inf')\n",
    "best_predictions = None\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "**************************************************\n",
      "Best Parameters:  {'n_features': 2, 'patience': 15}\n",
      "Best RMSE:  0.04097690496221036\n",
      "Prediction :-  [[0.345416  ]\n",
      " [0.34466258]\n",
      " [0.33380234]\n",
      " [0.33691314]\n",
      " [0.3649072 ]\n",
      " [0.38733324]\n",
      " [0.38106096]\n",
      " [0.41012087]\n",
      " [0.43327206]\n",
      " [0.39681515]\n",
      " [0.38898957]\n",
      " [0.3777744 ]\n",
      " [0.46918926]\n",
      " [0.46528322]\n",
      " [0.4772248 ]\n",
      " [0.5363768 ]\n",
      " [0.4795125 ]\n",
      " [0.44801638]\n",
      " [0.41716167]\n",
      " [0.36730653]\n",
      " [0.52596337]\n",
      " [0.63904244]\n",
      " [0.63888156]\n",
      " [0.6442889 ]]\n"
     ]
    }
   ],
   "source": [
    "for n in n_features_lst:\n",
    "    for pat in patience_lst:\n",
    "        X, y = prepare_data(time_series_data, n)\n",
    "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        train_size = 240\n",
    "        val_size = 24\n",
    "\n",
    "        X_train, y_train = X[:train_size], y[:train_size]\n",
    "        X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\n",
    "        X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]\n",
    "\n",
    "        \n",
    "        # Building the LSTM Model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n, 1)))\n",
    "        model.add(LSTM(50, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        # Early stopping\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "\n",
    "        # Fitting the model\n",
    "        model.fit(X_train, y_train, epochs = 300, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "        # Choosing the best model based on the validation loss\n",
    "        predictions = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_parameter['n_features'] = n\n",
    "            best_parameter['patience'] = pat\n",
    "            best_predictions = predictions\n",
    "            best_model = model\n",
    "\n",
    "print(\"*\" * 50)\n",
    "print(\"Best Parameters: \", best_parameter)\n",
    "print(\"Best RMSE: \", best_rmse)\n",
    "print(\"Prediction :- \", best_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 93.1983  ,  93.16515 ,  92.68731 ,  92.82417 ,  94.055916,\n",
       "        95.042656,  94.766685,  96.04532 ,  97.06397 ,  95.45986 ,\n",
       "        95.11555 ,  94.62208 ,  98.644325,  98.47246 ,  98.997894,\n",
       "       101.60057 ,  99.09855 ,  97.71272 ,  96.35512 ,  94.16148 ,\n",
       "       101.14239 , 106.11787 , 106.110794, 106.34872 ], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_predictions_in_original_scale = scaler.inverse_transform(best_predictions)\n",
    "xlst = validation_predictions_in_original_scale.flatten()\n",
    "xlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.66666666666667"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_previous_3_values_mean(df, index):\n",
    "    # Get the previous 3 values of the index\n",
    "    previous_3_values = df.iloc[index-3:index]\n",
    "\n",
    "    # Inverse transform the values\n",
    "    previous_3_values = scaler.inverse_transform(previous_3_values)\n",
    "\n",
    "    # Take the mean of the previous 3 values\n",
    "    return np.mean(previous_3_values)\n",
    "\n",
    "mean_240 = get_previous_3_values_mean(df, 240)\n",
    "mean_240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 96.        ,  94.        ,  93.5       ,  93.        ,\n",
       "        93.        ,  94.        ,  95.        ,  95.        ,\n",
       "        96.        ,  97.        ,  96.        ,  95.5       ,\n",
       "        95.        ,  98.        ,  98.5       ,  99.        ,\n",
       "       101.        ,  99.66666667,  98.33333333,  97.        ,\n",
       "        95.        , 100.        , 105.        , 106.        ])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual values of the validation set\n",
    "actual_values = df['reading'].values[train_size:train_size+val_size]\n",
    "actual_values = actual_values.reshape(-1, 1)\n",
    "actual_values_in_original_scale = scaler.inverse_transform(actual_values)\n",
    "actual_values_in_original_scale.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I want it to be printed in the form of a dataframe with the predicted values with a shift of 1 and the actual values\n",
    "\n",
    "final = pd.DataFrame()\n",
    "# Append the time of time series from values 240 to 264\n",
    "final['time'] = df.index[train_size:train_size+val_size]\n",
    "\n",
    "# To get the mean of 240 pass the value of 240 in the get_previous_3_values_mean function\n",
    "mean_240 = get_previous_3_values_mean(df, 240)\n",
    "\n",
    "# Remove the last value of the predicted values and store it in a variable\n",
    "last_value = validation_predictions_in_original_scale[-1]\n",
    "validation_predictions_in_original_scale = validation_predictions_in_original_scale[:-1]\n",
    "\n",
    "# Append the precited values with a shift of 1 and the predicted value at 240 being the mean of actual values at 237, 238 and 239. Append the mean first and then the predicted values\n",
    "final['Shifted_prediction'] = [mean_240] + validation_predictions_in_original_scale.flatten().tolist()\n",
    "final['unshifted_prediction'] = xlst.flatten().tolist()\n",
    "\n",
    "# Append the actual values\n",
    "final['actual'] = actual_values_in_original_scale.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Shifted_prediction</th>\n",
       "      <th>unshifted_prediction</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-05 20:05:00</td>\n",
       "      <td>95.666667</td>\n",
       "      <td>93.198303</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-05 20:10:00</td>\n",
       "      <td>93.198303</td>\n",
       "      <td>93.165154</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-05 20:15:00</td>\n",
       "      <td>93.165154</td>\n",
       "      <td>92.687309</td>\n",
       "      <td>93.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-05 20:20:00</td>\n",
       "      <td>92.687309</td>\n",
       "      <td>92.824173</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-05 20:25:00</td>\n",
       "      <td>92.824173</td>\n",
       "      <td>94.055916</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-03-05 20:30:00</td>\n",
       "      <td>94.055916</td>\n",
       "      <td>95.042656</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-03-05 20:35:00</td>\n",
       "      <td>95.042656</td>\n",
       "      <td>94.766685</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-03-05 20:40:00</td>\n",
       "      <td>94.766685</td>\n",
       "      <td>96.045319</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-03-05 20:45:00</td>\n",
       "      <td>96.045319</td>\n",
       "      <td>97.063972</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-03-05 20:50:00</td>\n",
       "      <td>97.063972</td>\n",
       "      <td>95.459862</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-03-05 20:55:00</td>\n",
       "      <td>95.459862</td>\n",
       "      <td>95.115547</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-03-05 21:00:00</td>\n",
       "      <td>95.115547</td>\n",
       "      <td>94.622078</td>\n",
       "      <td>95.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-03-05 21:05:00</td>\n",
       "      <td>94.622078</td>\n",
       "      <td>98.644325</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-03-05 21:10:00</td>\n",
       "      <td>98.644325</td>\n",
       "      <td>98.472458</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-03-05 21:15:00</td>\n",
       "      <td>98.472458</td>\n",
       "      <td>98.997894</td>\n",
       "      <td>98.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-03-05 21:20:00</td>\n",
       "      <td>98.997894</td>\n",
       "      <td>101.600571</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-03-05 21:25:00</td>\n",
       "      <td>101.600571</td>\n",
       "      <td>99.098549</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-03-05 21:30:00</td>\n",
       "      <td>99.098549</td>\n",
       "      <td>97.712723</td>\n",
       "      <td>99.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-03-05 21:35:00</td>\n",
       "      <td>97.712723</td>\n",
       "      <td>96.355118</td>\n",
       "      <td>98.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-03-05 21:40:00</td>\n",
       "      <td>96.355118</td>\n",
       "      <td>94.161484</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-03-05 21:45:00</td>\n",
       "      <td>94.161484</td>\n",
       "      <td>101.142387</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-03-05 21:50:00</td>\n",
       "      <td>101.142387</td>\n",
       "      <td>106.117867</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-03-05 21:55:00</td>\n",
       "      <td>106.117867</td>\n",
       "      <td>106.110794</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-03-05 22:00:00</td>\n",
       "      <td>106.110794</td>\n",
       "      <td>106.348717</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  Shifted_prediction  unshifted_prediction      actual\n",
       "0  2023-03-05 20:05:00           95.666667             93.198303   96.000000\n",
       "1  2023-03-05 20:10:00           93.198303             93.165154   94.000000\n",
       "2  2023-03-05 20:15:00           93.165154             92.687309   93.500000\n",
       "3  2023-03-05 20:20:00           92.687309             92.824173   93.000000\n",
       "4  2023-03-05 20:25:00           92.824173             94.055916   93.000000\n",
       "5  2023-03-05 20:30:00           94.055916             95.042656   94.000000\n",
       "6  2023-03-05 20:35:00           95.042656             94.766685   95.000000\n",
       "7  2023-03-05 20:40:00           94.766685             96.045319   95.000000\n",
       "8  2023-03-05 20:45:00           96.045319             97.063972   96.000000\n",
       "9  2023-03-05 20:50:00           97.063972             95.459862   97.000000\n",
       "10 2023-03-05 20:55:00           95.459862             95.115547   96.000000\n",
       "11 2023-03-05 21:00:00           95.115547             94.622078   95.500000\n",
       "12 2023-03-05 21:05:00           94.622078             98.644325   95.000000\n",
       "13 2023-03-05 21:10:00           98.644325             98.472458   98.000000\n",
       "14 2023-03-05 21:15:00           98.472458             98.997894   98.500000\n",
       "15 2023-03-05 21:20:00           98.997894            101.600571   99.000000\n",
       "16 2023-03-05 21:25:00          101.600571             99.098549  101.000000\n",
       "17 2023-03-05 21:30:00           99.098549             97.712723   99.666667\n",
       "18 2023-03-05 21:35:00           97.712723             96.355118   98.333333\n",
       "19 2023-03-05 21:40:00           96.355118             94.161484   97.000000\n",
       "20 2023-03-05 21:45:00           94.161484            101.142387   95.000000\n",
       "21 2023-03-05 21:50:00          101.142387            106.117867  100.000000\n",
       "22 2023-03-05 21:55:00          106.117867            106.110794  105.000000\n",
       "23 2023-03-05 22:00:00          106.110794            106.348717  106.000000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Now we train the model again using the best parameters but now we will train it on the entire dataset and exclude the test data from the dataset\n",
    "\n",
    "X, y = prepare_data(time_series_data, best_parameter['n_features'])\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Splitting the data into train, validation and test sets\n",
    "# Train data should be of 264 values of the data set and not 240\n",
    "# Validation data is remaining 24 values of the data set\n",
    "\n",
    "train_size = 264\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "\n",
    "# Building the LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(best_parameter['n_features'], 1)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train, epochs = 300, verbose=0)\n",
    "\n",
    "# Now we will predict the test data\n",
    "predictions = model.predict(X[train_size:])\n",
    "rmse = np.sqrt(mean_squared_error(y[train_size:], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([107.01616 ,  99.1131  , 100.39814 ,  99.391495,  98.398605,\n",
       "       100.19362 ,  99.80129 , 101.21674 , 100.10227 ,  99.59859 ,\n",
       "       104.06789 ,  98.51876 ,  94.26603 ,  89.45571 ,  91.292816,\n",
       "       100.14491 , 100.5874  , 101.21674 , 103.68684 , 104.34146 ,\n",
       "       100.87141 ], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now converting the predictions to the original scale\n",
    "predictions_in_original_scale = scaler.inverse_transform(predictions)\n",
    "plst = predictions_in_original_scale.flatten()\n",
    "plst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_in_original_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_features': 2, 'patience': 15}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([102. , 101. , 100. ,  99. , 100. , 100. , 101. , 100.5, 100. ,\n",
       "       103. , 100. ,  96. ,  91. ,  91. ,  98. , 100. , 101. , 103. ,\n",
       "       104. , 102. , 107. ])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the actual values of the test data\n",
    "actual_values = df['reading'].values[train_size+best_parameter['n_features']:]\n",
    "actual_values = actual_values.reshape(-1, 1)\n",
    "actual_values_in_original_scale = scaler.inverse_transform(actual_values)\n",
    "actual_values_in_original_scale.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>unshifted_predcition</th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-05 22:15:00</td>\n",
       "      <td>107.016159</td>\n",
       "      <td>103.666667</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-05 22:20:00</td>\n",
       "      <td>99.113098</td>\n",
       "      <td>107.016159</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-05 22:25:00</td>\n",
       "      <td>100.398140</td>\n",
       "      <td>99.113098</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-05 22:30:00</td>\n",
       "      <td>99.391495</td>\n",
       "      <td>100.398140</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-05 22:35:00</td>\n",
       "      <td>98.398605</td>\n",
       "      <td>99.391495</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-03-05 22:40:00</td>\n",
       "      <td>100.193619</td>\n",
       "      <td>98.398605</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-03-05 22:45:00</td>\n",
       "      <td>99.801292</td>\n",
       "      <td>100.193619</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-03-05 22:50:00</td>\n",
       "      <td>101.216743</td>\n",
       "      <td>99.801292</td>\n",
       "      <td>100.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-03-05 22:55:00</td>\n",
       "      <td>100.102272</td>\n",
       "      <td>101.216743</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-03-05 23:00:00</td>\n",
       "      <td>99.598587</td>\n",
       "      <td>100.102272</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-03-05 23:05:00</td>\n",
       "      <td>104.067886</td>\n",
       "      <td>99.598587</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-03-05 23:10:00</td>\n",
       "      <td>98.518761</td>\n",
       "      <td>104.067886</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-03-05 23:15:00</td>\n",
       "      <td>94.266029</td>\n",
       "      <td>98.518761</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-03-05 23:20:00</td>\n",
       "      <td>89.455711</td>\n",
       "      <td>94.266029</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-03-05 23:25:00</td>\n",
       "      <td>91.292816</td>\n",
       "      <td>89.455711</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-03-05 23:30:00</td>\n",
       "      <td>100.144913</td>\n",
       "      <td>91.292816</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-03-05 23:35:00</td>\n",
       "      <td>100.587402</td>\n",
       "      <td>100.144913</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-03-05 23:40:00</td>\n",
       "      <td>101.216743</td>\n",
       "      <td>100.587402</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-03-05 23:45:00</td>\n",
       "      <td>103.686836</td>\n",
       "      <td>101.216743</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-03-05 23:50:00</td>\n",
       "      <td>104.341461</td>\n",
       "      <td>103.686836</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-03-05 23:55:00</td>\n",
       "      <td>100.871407</td>\n",
       "      <td>104.341461</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  unshifted_predcition   predicted  actual\n",
       "0  2023-03-05 22:15:00            107.016159  103.666667   102.0\n",
       "1  2023-03-05 22:20:00             99.113098  107.016159   101.0\n",
       "2  2023-03-05 22:25:00            100.398140   99.113098   100.0\n",
       "3  2023-03-05 22:30:00             99.391495  100.398140    99.0\n",
       "4  2023-03-05 22:35:00             98.398605   99.391495   100.0\n",
       "5  2023-03-05 22:40:00            100.193619   98.398605   100.0\n",
       "6  2023-03-05 22:45:00             99.801292  100.193619   101.0\n",
       "7  2023-03-05 22:50:00            101.216743   99.801292   100.5\n",
       "8  2023-03-05 22:55:00            100.102272  101.216743   100.0\n",
       "9  2023-03-05 23:00:00             99.598587  100.102272   103.0\n",
       "10 2023-03-05 23:05:00            104.067886   99.598587   100.0\n",
       "11 2023-03-05 23:10:00             98.518761  104.067886    96.0\n",
       "12 2023-03-05 23:15:00             94.266029   98.518761    91.0\n",
       "13 2023-03-05 23:20:00             89.455711   94.266029    91.0\n",
       "14 2023-03-05 23:25:00             91.292816   89.455711    98.0\n",
       "15 2023-03-05 23:30:00            100.144913   91.292816   100.0\n",
       "16 2023-03-05 23:35:00            100.587402  100.144913   101.0\n",
       "17 2023-03-05 23:40:00            101.216743  100.587402   103.0\n",
       "18 2023-03-05 23:45:00            103.686836  101.216743   104.0\n",
       "19 2023-03-05 23:50:00            104.341461  103.686836   102.0\n",
       "20 2023-03-05 23:55:00            100.871407  104.341461   107.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_in_original_scale = predictions_in_original_scale.flatten()\n",
    "\n",
    "# We remove the last value of the predicted values and store it in a variable\n",
    "last_value = predictions_in_original_scale[-1]\n",
    "predictions_final = predictions_in_original_scale[:-1]\n",
    "\n",
    "# Now we add the mean of the last 3 values of the training data as the first value of the predictions_final and then append the predictions_final to the predictions_final\n",
    "mean_264 = get_previous_3_values_mean(df, 264)\n",
    "predictions_final = [mean_264] + predictions_final.tolist()\n",
    "\n",
    "# Now we will create a dataframe with the time series and the actual values and the predicted values\n",
    "final_test = pd.DataFrame()\n",
    "final_test['time'] = df.index[train_size+best_parameter['n_features']:]\n",
    "final_test[\"unshifted_predcition\"] = plst\n",
    "final_test['predicted'] = predictions_final\n",
    "final_test['actual'] = actual_values_in_original_scale.flatten()\n",
    "\n",
    "final_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
     ]
    }
   ],
   "source": [
    "# Now we will again train the data on entire dataset using the best parameters and then predict the future 10 values\n",
    "\n",
    "X, y = prepare_data(time_series_data, best_parameter['n_features'])\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Building the LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(best_parameter['n_features'], 1)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X, y, epochs = 300, verbose=0)\n",
    "\n",
    "# Now we will predict the future 10 values\n",
    "future_predictions = []\n",
    "last_values = X[-1]\n",
    "for i in range(10):\n",
    "    future_predictions.append(model.predict(last_values.reshape(1, best_parameter['n_features'], 1))[0][0])\n",
    "    last_values = np.append(last_values[1:], future_predictions[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_predictions = np.array(future_predictions)\n",
    "future_predictions = future_predictions.reshape(-1, 1)\n",
    "future_predictions_in_original_scale = scaler.inverse_transform(future_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101.688286, 102.273735, 103.32647 , 104.57723 , 105.75444 ,\n",
       "       106.78516 , 107.68057 , 108.46519 , 109.16128 , 109.78664 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_predictions_in_original_scale.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have a data frame called checked df which has the reading as a column and reading_time as the index\n",
    "# Now in this dataframe add 10 columns with their time and readings as predicted by the model\n",
    "\n",
    "# Get the last time of the checked_df\n",
    "last_time = checked_df.index[-1]\n",
    "\n",
    "# Get the time of the future predictions\n",
    "future_time = pd.date_range(start=last_time, periods=10, freq='5min')[0:]\n",
    "\n",
    "# Create a dataframe with the future time and the future predictions\n",
    "future_df = pd.DataFrame()\n",
    "future_df['time'] = future_time\n",
    "\n",
    "future_df['reading'] = future_predictions_in_original_scale.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-05 23:55:00</td>\n",
       "      <td>101.688286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-06 00:00:00</td>\n",
       "      <td>102.273735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-06 00:05:00</td>\n",
       "      <td>103.326469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-06 00:10:00</td>\n",
       "      <td>104.577232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-06 00:15:00</td>\n",
       "      <td>105.754440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-03-06 00:20:00</td>\n",
       "      <td>106.785156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-03-06 00:25:00</td>\n",
       "      <td>107.680573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-03-06 00:30:00</td>\n",
       "      <td>108.465187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-03-06 00:35:00</td>\n",
       "      <td>109.161278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-03-06 00:40:00</td>\n",
       "      <td>109.786636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time     reading\n",
       "0 2023-03-05 23:55:00  101.688286\n",
       "1 2023-03-06 00:00:00  102.273735\n",
       "2 2023-03-06 00:05:00  103.326469\n",
       "3 2023-03-06 00:10:00  104.577232\n",
       "4 2023-03-06 00:15:00  105.754440\n",
       "5 2023-03-06 00:20:00  106.785156\n",
       "6 2023-03-06 00:25:00  107.680573\n",
       "7 2023-03-06 00:30:00  108.465187\n",
       "8 2023-03-06 00:35:00  109.161278\n",
       "9 2023-03-06 00:40:00  109.786636"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading_time</th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-05 23:55:00</td>\n",
       "      <td>101.688286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-06 00:00:00</td>\n",
       "      <td>102.273735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-06 00:05:00</td>\n",
       "      <td>103.326469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-06 00:10:00</td>\n",
       "      <td>104.577232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-06 00:15:00</td>\n",
       "      <td>105.754440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         reading_time     reading\n",
       "0 2023-03-05 23:55:00  101.688286\n",
       "1 2023-03-06 00:00:00  102.273735\n",
       "2 2023-03-06 00:05:00  103.326469\n",
       "3 2023-03-06 00:10:00  104.577232\n",
       "4 2023-03-06 00:15:00  105.754440"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns of future df to match the checked df\n",
    "future_df.rename(columns={'time': 'reading_time', 'reading': 'reading'}, inplace=True)\n",
    "future_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_df.set_index('reading_time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:05:00</th>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:10:00</th>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:15:00</th>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:20:00</th>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:25:00</th>\n",
       "      <td>116.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     reading\n",
       "Glucose_time                \n",
       "2023-03-05 00:05:00    115.0\n",
       "2023-03-05 00:10:00    115.0\n",
       "2023-03-05 00:15:00    114.0\n",
       "2023-03-05 00:20:00    116.0\n",
       "2023-03-05 00:25:00    116.5"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([checked_df, future_df], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-05 23:10:00</th>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 23:15:00</th>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 23:20:00</th>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 23:25:00</th>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 23:30:00</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 23:35:00</th>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 23:40:00</th>\n",
       "      <td>103.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 23:45:00</th>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 23:50:00</th>\n",
       "      <td>102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 23:55:00</th>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 23:55:00</th>\n",
       "      <td>101.688286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-06 00:00:00</th>\n",
       "      <td>102.273735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-06 00:05:00</th>\n",
       "      <td>103.326469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-06 00:10:00</th>\n",
       "      <td>104.577232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-06 00:15:00</th>\n",
       "      <td>105.754440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-06 00:20:00</th>\n",
       "      <td>106.785156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-06 00:25:00</th>\n",
       "      <td>107.680573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-06 00:30:00</th>\n",
       "      <td>108.465187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-06 00:35:00</th>\n",
       "      <td>109.161278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-06 00:40:00</th>\n",
       "      <td>109.786636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        reading\n",
       "2023-03-05 23:10:00   96.000000\n",
       "2023-03-05 23:15:00   91.000000\n",
       "2023-03-05 23:20:00   91.000000\n",
       "2023-03-05 23:25:00   98.000000\n",
       "2023-03-05 23:30:00  100.000000\n",
       "2023-03-05 23:35:00  101.000000\n",
       "2023-03-05 23:40:00  103.000000\n",
       "2023-03-05 23:45:00  104.000000\n",
       "2023-03-05 23:50:00  102.000000\n",
       "2023-03-05 23:55:00  107.000000\n",
       "2023-03-05 23:55:00  101.688286\n",
       "2023-03-06 00:00:00  102.273735\n",
       "2023-03-06 00:05:00  103.326469\n",
       "2023-03-06 00:10:00  104.577232\n",
       "2023-03-06 00:15:00  105.754440\n",
       "2023-03-06 00:20:00  106.785156\n",
       "2023-03-06 00:25:00  107.680573\n",
       "2023-03-06 00:30:00  108.465187\n",
       "2023-03-06 00:35:00  109.161278\n",
       "2023-03-06 00:40:00  109.786636"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABlkAAANXCAYAAAC2XDkBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3hc5Zn+8XuKRqPeqyU32ZY7NpgWAzYdGzuBwAZICA6BtB8tlE3bNFI2m83SklCW4EA2gYQkQADTm+nGNrbBcpG7LVm99zIz5/fHa8kISbYkz8xR+X6uS1ekOWfOeTTY8XnPfZ73dViWZQkAAAAAAAAAAACD4rS7AAAAAAAAAAAAgJGIkAUAAAAAAAAAAGAICFkAAAAAAAAAAACGgJAFAAAAAAAAAABgCAhZAAAAAAAAAAAAhoCQBQAAAAAAAAAAYAgIWQAAAAAAAAAAAIaAkAUAAAAAAAAAAGAICFkAAAAAAAAAAACGgJAFAAAAGKMmTpyor3zlK90/r169Wg6HQ6tXr7atpk/7dI3Bsm/fPjkcDj3yyCNBPzYGjv8OAAAAGOkIWQAAAAAbPPLII3I4HN1fXq9X06ZN0/XXX6/y8nK7yxuU559/Xj/96U/tLkPt7e363e9+p9NOO01JSUnyeDzKzs7WZz/7Wf31r3+V3++3u0Rb/PSnP5XD4VBVVZXdpQAAAACjjtvuAgAAAICx7Gc/+5kmTZqktrY2vfPOO7r//vv1/PPPq6CgQNHR0WGt5YwzzlBra6s8Hs+g3vf888/r3nvvtTVoqays1JIlS/Thhx/q/PPP1w9/+EMlJyerrKxMr776qr74xS9q165d+tGPfmRbjQAAAABGH0IWAAAAwEZLlizRggULJEnXXnutUlJSdOedd+rpp5/WFVdc0ed7mpubFRMTE/RanE6nvF5v0I8bDl/+8pe1ceNGPfHEE/r85z/fY9v3v/99rV+/XoWFhTZVBwAAAGC0YrowAAAAYBg566yzJEl79+6VJH3lK19RbGysdu/eraVLlyouLk5f+tKXJEmBQEB33323Zs2aJa/Xq4yMDH3jG99QbW1tj2NalqVf/OIXysnJUXR0tM4880xt2bKl17n7W5Plgw8+0NKlS5WUlKSYmBjNnTtX99xzT3d99957ryT1mP6sS7Br7Mv777+vl156SV//+td7BSxdFixY0P259Wfx4sVavHhxr9e/8pWvaOLEiT1eCwQCuueeezRnzhx5vV6lpaXpggsu0Pr167v38fl8+vnPf668vDxFRkZq4sSJ+sEPfqD29vYex1q/fr3OP/98paamKioqSpMmTdJXv/rVXucbyOd4LLZv365LL71UycnJ8nq9WrBggZ555pkedTocDv3pT3/q9d6XXnpJDodDq1at6n7t4MGD+upXv6qMjAxFRkZq1qxZ+uMf/3jUOsrKynT11VcrJydHkZGRysrK0uc+9znt27cvKL8nAAAAEEx0sgAAAADDyO7duyVJKSkp3a/5fD6df/75Ou200/Q///M/3dOIfeMb39Ajjzyiq6++WjfeeKP27t2r3//+99q4caPeffddRURESJJ+/OMf6xe/+IWWLl2qpUuXasOGDTrvvPPU0dFx1HpeeeUVLVu2TFlZWbrpppuUmZmpbdu2adWqVbrpppv0jW98QyUlJXrllVf05z//udf7w1Hjs88+K0m68sorj7pvsFxzzTV65JFHtGTJEl177bXy+Xx6++23tWbNmh6dSX/605906aWX6tZbb9UHH3ygX/3qV9q2bZueeuopSVJFRYXOO+88paWl6Xvf+54SExO1b98+Pfnkkz3ON9DPcai2bNmihQsXaty4cfre976nmJgY/f3vf9dFF12kJ554QhdffLEWLFigyZMn6+9//7tWrFjR4/2PP/64kpKSdP7550uSysvLdcopp8jhcOj6669XWlqaXnjhBV1zzTVqaGjQt7/97X5rueSSS7RlyxbdcMMNmjhxoioqKvTKK6/owIEDvcIuAAAAwHYWAAAAgLB7+OGHLUnWq6++alVWVlpFRUXW3/72NyslJcWKioqyiouLLcuyrBUrVliSrO9973s93v/2229bkqxHH320x+svvvhij9crKiosj8djXXjhhVYgEOje7wc/+IElyVqxYkX3a2+88YYlyXrjjTcsy7Isn89nTZo0yZowYYJVW1vb4zyfPNZ1111n9TW0CEWNfbn44ostSVZdXV2P11tbW63Kysrur0/+Dnv37rUkWQ8//HD3a4sWLbIWLVrU6/grVqywJkyY0P3z66+/bkmybrzxxl77dtW/adMmS5J17bXX9th+2223WZKs119/3bIsy3rqqacsSda6dev6/f0G+jn25yc/+YklyaqsrOx3n7PPPtuaM2eO1dbW1uN3+cxnPmNNnTq1+7Xvf//7VkREhFVTU9P9Wnt7u5WYmGh99atf7X7tmmuusbKysqyqqqoe57n88suthIQEq6WlxbKs3v8damtrLUnWb37zmyP+TgAAAMBwwXRhAAAAgI3OOeccpaWlKTc3V5dffrliY2P11FNPady4cT32+9a3vtXj53/84x9KSEjQueeeq6qqqu6vE044QbGxsXrjjTckSa+++qo6Ojp0ww039JjG60idBF02btyovXv36tvf/rYSExN7bPvksfoTjholqaGhQZIUGxvb4/UHHnhAaWlp3V+nnXbagI53NE888YQcDod+8pOf9NrWVf/zzz8vSbrlllt6bL/11lslSc8995wkdX+uq1atUmdnZ5/nG+jnOFQ1NTV6/fXX9YUvfEGNjY3dx6+urtb555+vnTt36uDBg5Kkyy67TJ2dnT06bV5++WXV1dXpsssuk2SmfnviiSe0fPlyWZbVo+bzzz9f9fX12rBhQ5+1REVFyePxaPXq1UGdCg0AAAAIFaYLAwAAAGx07733atq0aXK73crIyFB+fr6czp7PQrndbuXk5PR4befOnaqvr1d6enqfx62oqJAk7d+/X5I0derUHtvT0tKUlJR0xNq6pi6bPXv2wH+hMNcoSXFxcZKkpqYmJSQkdL9+ySWXdNd+6623yu/3D/6X6MPu3buVnZ2t5OTkfvfZv3+/nE6npkyZ0uP1zMxMJSYmdv/OixYt0iWXXKLbb79dd911lxYvXqyLLrpIX/ziFxUZGSlp4J/jUO3atUuWZelHP/qRfvSjH/V7jnHjxum4447T9OnT9fjjj+uaa66RZKYKS01N7V5PqLKyUnV1dXrwwQf14IMPDqrmyMhI/frXv9att96qjIwMnXLKKVq2bJmuuuoqZWZmHtPvCQAAAIQCIQsAAABgo5NOOql7DY/+REZG9gpeAoGA0tPT9eijj/b5nrS0tKDVOFThqnH69OmSpIKCAi1cuLD79dzcXOXm5kqSkpKSVFVVdcTjOBwOWZbV6/VjCWeO1vHjcDj0z3/+U2vWrNGzzz6rl156SV/96ld1xx13aM2aNYqNjQ355xgIBCRJt912W/eaKp/2ybDosssu0y9/+UtVVVUpLi5OzzzzjK644gq53e4ex7vyyit7rd3SZe7cuf3W8+1vf1vLly/Xv/71L7300kv60Y9+pF/96ld6/fXXNX/+/CH9jgAAAECoELIAAAAAI1BeXp5effVVLVy4UFFRUf3uN2HCBEmmG2Ly5Mndr1dWVh51Oqa8vDxJJrw455xz+t2vvyAhHDVK0rJly/Rf//VfevTRR3uELIOVlJSkPXv29Hq9q+ukS15enl566SXV1NT0280yYcIEBQIB7dy5UzNmzOh+vby8XHV1dd2/c5dTTjlFp5xyin75y1/qscce05e+9CX97W9/07XXXjvgz3Gouj7ziIiII/537nLZZZfp9ttv1xNPPKGMjAw1NDTo8ssv796elpamuLg4+f3+AR2vL3l5ebr11lt16623aufOnZo3b57uuOMO/eUvfxnS8QAAAIBQYU0WAAAAYAT6whe+IL/fr5///Oe9tvl8PtXV1Ukya75ERETod7/7XY8ujbvvvvuo5zj++OM1adIk3X333d3H6/LJY8XExEhSr33CUaMkLVy4UOeee64efPBBPf30033u01eHyqfl5eVp+/btqqys7H7to48+0rvvvttjv0suuUSWZen222/v9zxLly7t83e48847JUkXXnihJKm2trZXbfPmzZMktbe3Sxr45zhU6enpWrx4sf73f/9XpaWlvbZ/8vOQpBkzZmjOnDl6/PHH9fjjjysrK0tnnHFG93aXy6VLLrlETzzxhAoKCo56vE9qaWlRW1tbj9fy8vIUFxfX/XkAAAAAwwmdLAAAAMAItGjRIn3jG9/Qr371K23atEnnnXeeIiIitHPnTv3jH//QPffco0svvVRpaWm67bbb9Ktf/UrLli3T0qVLtXHjRr3wwgtKTU094jmcTqfuv/9+LV++XPPmzdPVV1+trKwsbd++XVu2bNFLL70kSTrhhBMkSTfeeKPOP/98uVwuXX755WGpsctf/vIXXXDBBbrooou0ZMkSnXPOOUpKSlJZWZleffVVvfXWW1qyZMkRj/HVr35Vd955p84//3xdc801qqio0AMPPKBZs2apoaGhe78zzzxTX/7yl/Xb3/5WO3fu1AUXXKBAIKC3335bZ555pq6//nodd9xxWrFihR588EHV1dVp0aJFWrt2rf70pz/poosu0plnnilJ+tOf/qT77rtPF198sfLy8tTY2Kg//OEPio+P7w5qBvo5Hs2dd96p6OjoXv+Nf/CDH+jee+/Vaaedpjlz5uhrX/uaJk+erPLycr3//vsqLi7WRx991ON9l112mX784x/L6/Xqmmuu6TWd3X/913/pjTfe0Mknn6yvfe1rmjlzpmpqarRhwwa9+uqrqqmp6bPGHTt26Oyzz9YXvvAFzZw5U263W0899ZTKy8t7dMsAAAAAw4YFAAAAIOwefvhhS5K1bt26I+63YsUKKyYmpt/tDz74oHXCCSdYUVFRVlxcnDVnzhzrO9/5jlVSUtK9j9/vt26//XYrKyvLioqKshYvXmwVFBRYEyZMsFasWNG93xtvvGFJst54440e53jnnXesc88914qLi7NiYmKsuXPnWr/73e+6t/t8PuuGG26w0tLSLIfDYX16mBHMGo+ktbXVuvvuu61TTz3Vio+Pt9xut5WZmWktW7bMevTRRy2fz9e97969ey1J1sMPP9zjGH/5y1+syZMnWx6Px5o3b5710ksvWStWrLAmTJjQYz+fz2f95je/saZPn255PB4rLS3NWrJkifXhhx9279PZ2Wndfvvt1qRJk6yIiAgrNzfX+v73v2+1tbV177NhwwbriiuusMaPH29FRkZa6enp1rJly6z169f3+v0G8jn25Sc/+Yklqc8vl8vVvd/u3butq666ysrMzLQiIiKscePGWcuWLbP++c9/9jrmzp07u4/xzjvv9Hne8vJy67rrrrNyc3OtiIgIKzMz0zr77LOtBx98sN//DlVVVdZ1111nTZ8+3YqJibESEhKsk08+2fr73/9+xN8RAAAAsIvDsgbQNw8AAAAAAAAAAIAeWJMFAAAAAAAAAABgCAhZAAAAAAAAAAAAhoCQBQAAAAAAAAAAYAgIWQAAAAAAAAAAAIaAkAUAAAAAAAAAAGAICFkAAAAAAAAAAACGwG13AcNBIBBQSUmJ4uLi5HA47C4HAAAAAAAAAADYyLIsNTY2Kjs7W05n//0qhCySSkpKlJuba3cZAAAAAAAAAABgGCkqKlJOTk6/2wlZJMXFxUkyH1Z8fLzN1QAAAAAAAAAAADs1NDQoNze3Oz/oDyGL1D1FWHx8PCELAAAAAAAAAACQpKMuMcLC9wAAAAAAAAAAAENAyAIAAAAAAAAAADAEhCwAAAAAAAAAAABDwJosAAAAAAAAAICgsyxLPp9Pfr/f7lKAXlwul9xu91HXXDkaQhYAAAAAAAAAQFB1dHSotLRULS0tdpcC9Cs6OlpZWVnyeDxDPgYhCwAAAAAAAAAgaAKBgPbu3SuXy6Xs7Gx5PJ5j7hYAgsmyLHV0dKiyslJ79+7V1KlT5XQObXUVQhYAAAAAAAAAQNB0dHQoEAgoNzdX0dHRdpcD9CkqKkoRERHav3+/Ojo65PV6h3QcFr4HAAAAAAAAAATdUDsDgHAJxp9R/pQDAAAAAAAAAAAMASELAAAAAAAAAADAEBCyAAAAAAAAAAAwzDkcDv3rX/+yu4yjeuSRR5SYmNj9809/+lPNmzfPllrC8ZkRsgAAAAAAAAAA8Anvv/++XC6XLrzwwkG9b+LEibr77rtDU9QxeOSRR+RwOORwOOR0OpWTk6Orr75aFRUVIT/3bbfdptdee23A+4+UMKkLIQsAAAAAAAAAAJ+wcuVK3XDDDXrrrbdUUlJidzlHtW/fPjkcjiPuEx8fr9LSUhUXF+sPf/iDXnjhBX35y1/uc1+/369AIBCU2mJjY5WSkhKUYw1HhCwAAAAAAAAAgJCyLKm52Z4vyxpcrU1NTXr88cf1rW99SxdeeKEeeeSRHtufffZZnXjiifJ6vUpNTdXFF18sSVq8eLH279+vm2++ubtrROp7uqy7775bEydO7P553bp1Ovfcc5WamqqEhAQtWrRIGzZsGOzHfEQOh0OZmZnKzs7WkiVLdOONN+rVV19Va2tr9xRfzzzzjGbOnKnIyEgdOHBA7e3tuu222zRu3DjFxMTo5JNP1urVq3sc95FHHtH48eMVHR2tiy++WNXV1T229/X7//GPf9SsWbMUGRmprKwsXX/99ZLU/ZlcfPHFcjgcPT6jp59+Wscff7y8Xq8mT56s22+/XT6fr3v7zp07dcYZZ8jr9WrmzJl65ZVXgvbZHQkhCwAAAAAAAAAgpFpapNhYe75aWgZX69///ndNnz5d+fn5uvLKK/XHP/5R1qGk5rnnntPFF1+spUuXauPGjXrttdd00kknSZKefPJJ5eTk6Gc/+5lKS0tVWlo64HM2NjZqxYoVeuedd7RmzRpNnTpVS5cuVWNj4+CKH4SoqCgFAoHuoKKlpUW//vWv9dBDD2nLli1KT0/X9ddfr/fff19/+9vf9PHHH+vf/u3fdMEFF2jnzp2SpA8++EDXXHONrr/+em3atElnnnmmfvGLXxzxvPfff7+uu+46ff3rX9fmzZv1zDPPaMqUKZJM2CRJDz/8sEpLS7t/fvvtt3XVVVfppptu0tatW/W///u/euSRR/TLX/5SkhQIBPT5z39eHo9HH3zwgR544AF997vfDcnn9mnusJwFAAAAAAAAAIARYOXKlbryyislSRdccIHq6+v15ptvavHixfrlL3+pyy+/XLfffnv3/scdd5wkKTk5WS6XS3FxccrMzBzUOc8666wePz/44INKTEzUm2++qWXLlh3jb9Tbzp079cADD2jBggWKi4uTJHV2duq+++7r/n0OHDighx9+WAcOHFB2drYks77Kiy++qIcfflj/+Z//qXvuuUcXXHCBvvOd70iSpk2bpvfee08vvvhiv+f+xS9+oVtvvVU33XRT92snnniiJCktLU2SlJiY2OMzvP322/W9731PK1askCRNnjxZP//5z/Wd73xHP/nJT/Tqq69q+/bteumll7pr/c///E8tWbIkKJ/XkRCyAAAAAAAAAABCKjpaamqy79wDVVhYqLVr1+qpp56SJLndbl122WVauXKlFi9erE2bNulrX/ta0GssLy/XD3/4Q61evVoVFRXy+/1qaWnRgQMH+n3PrFmztH//fknq7rSJjY3t3n766afrhRde6P65vr5esbGxCgQCamtr02mnnaaHHnqoe7vH49HcuXO7f968ebP8fr+mTZvW47zt7e3da6xs27ate7q0Lqeeemq/IUtFRYVKSkp09tlnH/Hz+LSPPvpI7777bnfnimTWjWlra1NLS4u2bdum3Nzc7oClq45wIGQBAAAAAAAAAISUwyHFxNhdxdGtXLlSPp+vx816y7IUGRmp3//+94qKihr0MZ1OZ3cI0qWzs7PHzytWrFB1dbXuueceTZgwQZGRkTr11FPV0dHR73Gff/757uMcPHiwOwTq8ula4+LitGHDBjmdTmVlZfXaHhUV1b2OjGTWpnG5XPrwww/lcrl67PvJMGcwhvL5ddVy++236/Of/3yvbV6vd0jHDBZCFgAAAAAAAADAmOfz+fR///d/uuOOO3Teeef12HbRRRfpr3/9q+bOnavXXntNV199dZ/H8Hg88vv9PV5LS0tTWVmZLMvqDjE+GYZI0rvvvqv77rtPS5culSQVFRWpqqrqiPVOmDCh+3u329zq71rbpC9Op/OI2z9t/vz58vv9qqio0Omnn97nPjNmzNAHH3zQ47U1a9b0e8y4uDhNnDhRr732ms4888w+94mIiOj1GR5//PEqLCzst/4ZM2aoqKhIpaWlysrKOmodwUTIAgAAAAAAAAAY81atWqXa2lpdc801SkhI6LHtkksu0cqVK/Wb3/xGZ599tvLy8nT55ZfL5/Pp+eef715kfeLEiXrrrbd0+eWXKzIyUqmpqVq8eLEqKyv13//937r00kv14osv6oUXXlB8fHz38adOnao///nPWrBggRoaGvTv//7vQ+76CJZp06bpS1/6kq666irdcccdmj9/viorK/Xaa69p7ty5uvDCC3XjjTdq4cKF+p//+R997nOf00svvXTE9Vgk6ac//am++c1vKj09XUuWLFFjY6Peffdd3XDDDZLUHcIsXLhQkZGRSkpK0o9//GMtW7ZM48eP16WXXiqn06mPPvpIBQUF+sUvfqFzzjlH06ZN04oVK/Sb3/xGDQ0N+o//+I9wfExyhuUsAAAAAAAAAAAMYytXrtQ555zTK2CRTMiyfv16JScn6x//+IeeeeYZzZs3T2eddZbWrl3bvd/PfvYz7du3T3l5ed2LuM+YMUP33Xef7r33Xh133HFau3atbrvttl7nrq2t1fHHH68vf/nLuvHGG5Wenh7aX3gAHn74YV111VW69dZblZ+fr4suukjr1q3T+PHjJUmnnHKK/vCHP+iee+7Rcccdp5dfflk//OEPj3jMFStW6O6779Z9992nWbNmadmyZdq5c2f39jvuuEOvvPKKcnNzNX/+fEnS+eefr1WrVunll1/WiSeeqFNOOUV33XVXdzeP0+nUU089pdbWVp100km69tpre6zfEkoO69OTwY1BDQ0NSkhIUH19fY/0EAAAAAAAAAAwOG1tbdq7d68mTZpk+3oZwJEc6c/qQHMDOlkAAAAAAAAAAACGgJAFAAAAAAAAAABgCAhZAAAAAAAAAAAAhoCQBQAAAAAAAAAAYAgIWQAAAAAAAAAAAIaAkAUAAAAAAAAAAGAICFkAAAAAAAAAAACGgJAFAAAAAAAAAABgCNx2FwAMVltdmzbf87r8zW09Xo+dlq3Z155iU1UAAAAAAAAAjqajQ/L5wnc+t1vyeMJ3Pow9hCwYcdac+yMtXv8/fW5be+BZnfSzZWGuCAAAAAAAAMDRdHRIa9dKTU3hO2dsrHTSSaMjaHE4HHrqqad00UUX2V0KPoHpwjCiWAFLUzb+XZK0PWqePo5bqI/jFmq3Z4YkKfNXN6q1ptXOEgEAAAAAAAD0weczAYvHI8XFhf7L4zHnG0rnzPvvvy+Xy6ULL7xwUO+bOHGi7r777sGfECMWnSwYUXY+uVnT/AfUoihNKH5PUclRkqTmimaVZE/XeN9erf78r7V49U/tLRQAAAAAAABAnyIjJa83POfq6Bja+1auXKkbbrhBK1euVElJibKzs4NbGEYNOlkwopT877OSpIL0s7sDFkmKSY/R/pvukiSd8uZ/af/ru22pDwAAAAAAAMDI1tTUpMcff1zf+ta3dOGFF+qRRx7psf3ZZ5/ViSeeKK/Xq9TUVF188cWSpMWLF2v//v26+eab5XA45HA4JEk//elPNW/evB7HuPvuuzVx4sTun9etW6dzzz1XqampSkhI0KJFi7Rhw4ZQ/poIEkIWjCgpa1ZJktrOXd5r2ym/uUQfJp8rr9pVcfmNsgJWuMsDAAAAAAAAMML9/e9/1/Tp05Wfn68rr7xSf/zjH2VZ5l7jc889p4svvlhLly7Vxo0b9dprr+mkk06SJD355JPKycnRz372M5WWlqq0tHTA52xsbNSKFSv0zjvvaM2aNZo6daqWLl2qxsbGkPyOCB6mC8OIUbmlQrOaPpAkTbul9+L2DqdDSX/5nTqWztGJlc/rgx89q5N/+dlwlwkAAAAAAABgBFu5cqWuvPJKSdIFF1yg+vp6vfnmm1q8eLF++ctf6vLLL9ftt9/evf9xxx0nSUpOTpbL5VJcXJwyMzMHdc6zzjqrx88PPvigEhMT9eabb2rZst73QjF80MmCEWP7Hc/JKUtbo09Q5vF9z4E4eUm+3jvlVklS9n/fpNaa1nCWCAAAAAAAAGAEKyws1Nq1a3XFFVdIktxuty677DKtXLlSkrRp0yadffbZQT9veXm5vva1r2nq1KlKSEhQfHy8mpqadODAgaCfC8FFJwtGjIgXzXosFSct18wj7Hfi0z/UwexHlevbp9UX/5cWv3n7EfYGAAAAAAAAAGPlypXy+Xw9Frq3LEuRkZH6/e9/r6ioqCO8u29Op7N7urEunZ2dPX5esWKFqqurdc8992jChAmKjIzUqaeeqo6OjqH9IggbOlkwIrTVtWl26cuSpIxre6/H8kkx6TE6cNOdkqRT3vq19r+2K+T1AQAAAAAAABjZfD6f/u///k933HGHNm3a1P310UcfKTs7W3/96181d+5cvfbaa/0ew+PxyO/393gtLS1NZWVlPYKWTZs29djn3Xff1Y033qilS5dq1qxZioyMVFVVVVB/P4QGnSwYEQp+v1oL1KxSZ7amXzH/qPuf8ptL9OEj5+qEmldUccVNGl+2Sg6nIwyVAgAAAAAAADiS9vbheZ5Vq1aptrZW11xzjRISEnpsu+SSS7Ry5Ur95je/0dlnn628vDxdfvnl8vl8ev755/Xd735XkjRx4kS99dZbuvzyyxUZGanU1FQtXrxYlZWV+u///m9deumlevHFF/XCCy8oPj6++/hTp07Vn//8Zy1YsEANDQ3693//9yF1zSD86GTBiND8uJkqbOe0ZQMKSxxOh5L+8jt1KEInVj6vtT96NtQlAgAAAAAAADgCt1uKjZU6OqTGxtB/dXSY87kH2GqwcuVKnXPOOb0CFsmELOvXr1dycrL+8Y9/6JlnntG8efN01llnae3atd37/exnP9O+ffuUl5entLQ0SdKMGTN033336d5779Vxxx2ntWvX6rbbbut17traWh1//PH68pe/rBtvvFHp6elD/7ARNg7r05PBjUENDQ1KSEhQfX19j/QQw4MVsFTimaBx/iKt/dGzOulnywb83tWnfl+L1/yXil0TlFy2VdGp0SGsFAAAAAAAAEBbW5v27t2rSZMmyev19tjW0SH5fOGrxe2WPJ7wnQ8jy5H+rA40N2C6MAx7O5/crGn+IrUoSnO+ffag3nvi0z/UwexHlePfr9Wf/y8tfutnIaoSAAAAAAAAwNF4PIQeGF2YLgzDXsn/mqm+Nmeco6jkwc1DGJMeowM33yVJOvXtX2v/a7uCXh8AAAAAAAAAYGwiZMGwl/q+CVnaz1s+pPef8uvP68PkcxWpDlVccaOswJifIQ8AAAAAAAAAEASELBjWKgvKNbPZLByVf8vA12L5JIfToaS//E4ditCJlS9o7Q+fCWaJAAAAAAAAAIAxipAFw9r2O56TU5a2Ri9QxrysIR9n8pJ8vXfqbZKkmN/+Z7DKAwAAAAAAANAPy2JGGQxvwfgzSsiCYS3iJTNVWMVJQ+ti+aTxP1ohSZrUXMCUYQAAAAAAAECIRERESJJaWlpsrgQ4sq4/o11/ZofCHaxigGBrq2vTnNKXJUkZ1w5tPZZPyjl9knxyKUYtKt1QoqwF4475mAAAAAAAAAB6crlcSkxMVEVFhSQpOjpaDofD5qqAwyzLUktLiyoqKpSYmCiXyzXkYxGyYNgq+P1qLVCLSp3jNP2K+cd8PE+sR3sjJmtS506VvVlIyAIAAAAAAACESGZmpiR1By3AcJSYmNj9Z3WoCFkwbDU/bqYK25m/TFnO4CTdlUnTNKlipxo/3CHprKAcEwAAAAAAAEBPDodDWVlZSk9PV2dnp93lAL1EREQcUwdLF0IWDEtWwNKUbSZkifrCsU8V1qUlN1+qeE7W9sKgHRMAAAAAAABA31wuV1BuZAPDFQvfY1ja8c+PNc5fpBZFafaNwes4ceZPkyRFF+8I2jEBAAAAAAAAAGMTIQuGpdIHTRfL5sxzFZUcFbTjxp1gQpb0WjpZAAAAAAAAAADHhpAFw1LqGhOydJwXvKnCJClrcb4kKce3Vx1NHUE9NgAAAAAAAABgbCFkwbBT8XGZZjevlSRNu/nCoB47Y16WGhUrlwIqfmtPUI8NAAAAAAAAABhbCFkw7BTe+ZwkaWv0AmXMywrqsR1Oh4qjzJRhle8wZRgAAAAAAAAAYOgIWTDsRLy8SpJUcXJwpwrrUptmQpbWj3aE5PgAAAAAAAAAgLGBkAXDSltdm+aUvixJyvxaaEKWjklmXRbXLjpZAAAAAAAAAABDZ2vI8tZbb2n58uXKzs6Ww+HQv/71r+5tnZ2d+u53v6s5c+YoJiZG2dnZuuqqq1RSUtLjGDU1NfrSl76k+Ph4JSYm6pprrlFTU1OYfxMEy+bfvqEYtajElaP8y+aF5BwRs0wnS3wZnSwAAAAAAAAAgKGzNWRpbm7Wcccdp3vvvbfXtpaWFm3YsEE/+tGPtGHDBj355JMqLCzUZz/72R77felLX9KWLVv0yiuvaNWqVXrrrbf09a9/PVy/AoKs9e/PSpJ25S+Tw+kIyTmSTjYhS3YjnSwAAAAAAAAAgKFzWJZl2V2EJDkcDj311FO66KKL+t1n3bp1Oumkk7R//36NHz9e27Zt08yZM7Vu3TotWLBAkvTiiy9q6dKlKi4uVnZ29oDO3dDQoISEBNXX1ys+Pj4Yvw6GwApYKvFM0Dh/kdb99Dmd+JOlITlPQ3GD4nMTJEn1+2qVMCExJOcBAAAAxrKSD4q067fP66R7V8ib6LW7HAAAAGBQBpobjKg1Werr6+VwOJSYmChJev/995WYmNgdsEjSOeecI6fTqQ8++KDf47S3t6uhoaHHF+x34I3dGucvUqu8mn3DmSE7T3xOvMqdmZKkg6t3huw8AAAAwFi27wvf0RmPfVPrb/ub3aUAAAAAITNiQpa2tjZ997vf1RVXXNGdGpWVlSk9Pb3Hfm63W8nJySorK+v3WL/61a+UkJDQ/ZWbmxvS2jEwNR8VSZJKPBMVlRwV0nOVxuVLkmrXMGUYAAAAEArp5R9LknyFu22uBAAAAAidERGydHZ26gtf+IIsy9L9999/zMf7/ve/r/r6+u6voqKiIFSJY9Wyq0SS1BCdFfJzNWSZdVk6t+wI+bkAAACAscbf4Vdu+y5Jkqu8xOZqAAAAgNBx213A0XQFLPv379frr7/eY+6zzMxMVVRU9Njf5/OppqZGmZmZ/R4zMjJSkZGRIasZQ9N5oFSS1JI4sLV0jkVgSr60XfLso5MFAAAACLaD7+3XeHVIkrx1pTZXAwAAAITOsO5k6QpYdu7cqVdffVUpKSk9tp966qmqq6vThx9+2P3a66+/rkAgoJNPPjnc5eJYlZon3DrTQh+yRM8znSzJVXSyAAAAAMFW/tbhh5niG+lkAQAAwOhlaydLU1OTdu3a1f3z3r17tWnTJiUnJysrK0uXXnqpNmzYoFWrVsnv93evs5KcnCyPx6MZM2boggsu0Ne+9jU98MAD6uzs1PXXX6/LL79c2dmhv1GP4PJUHXrCLTv004WlfsaELLmtOxTwBeR0D+u8EQAAABhRWjYdfpgpuZ1OFgAAAIxett5ZXr9+vebPn6/58+dLkm655RbNnz9fP/7xj3Xw4EE988wzKi4u1rx585SVldX99d5773Uf49FHH9X06dN19tlna+nSpTrttNP04IMP2vUr4RhE15sn3DwTQh+Q5S6aLJ9cilGLyjfyZB0AAAAQTI4dhztZ0qwKdbZ02lgNAAAAEDq2drIsXrxYlmX1u/1I27okJyfrscceC2ZZsEliiwk7YqaEvpMlIjpCeyMma1LnTpWuLlTWiTkhPycAAAAwVsSW9JyWt3JzmbJPzrWpGgAAACB0mCMJw4IVsJTaaaYRSJwZnqneKpPyJUlNG1iXBQAAAAimzIbCHj/XbmXKMAAAAIxOhCwYFhpLGhWrZklS6pzQd7JIUkuuWZfFKiRkAQAAAIKluaJZ2f5iSdJ+d54kqWkHU/QCAABgdCJkwbBQ9bEZdNUrXjHpMWE5p3O66WSJLi48yp4AAAAABqp49S5JUo0jWWWpsyVJ7fvoZAEAAMDoRMiCYaF+uxl0VXnCM1WYJMUvMJ0s6bV0sgAAAADBUv2+eYjpYEy+2lPM9X2gmE4WAAAAjE6ELBgWWnaZQVdDdHimCpOkzDNMyJLj26v2hvawnRcAAAAYzTo2m4eY6jOmKZBpQhZXOSELAAAARidCFgwLnQdMJ0tLYvg6WTLmZalRsXIpoOK39oTtvAAAAMBo5t5jOll8efly5ZiHqLx1TBcGAACA0YmQBcNDqXmyrTMtfCGLw+lQcZTpZql6l3VZAAAAgGBIrDCdLJFzp8k72VzfxzfSyQIAAIDRiZAFw4Kn8tCgKzt804VJUk16viSp9SPWZQEAAAC2/3Wj3rz4bvk7/P3uYwUsvfmFe/Xxfe/0uS232TzAlPqZfMVPNyFLcjshCwAAAEYnQhYMC9ENZvoAz4TwdbJIUmfeDHPegg1hPS8AAAAwHPm+9i0t+tfNWnPTX/vdZ/0vXtSif1yvzBsuVcAX6LGtalulElSvgBzKWZSn5FnmIao0q1KdLZ0hrR0AAACwAyELhoXEFvNkW8zU8IYsKZedI0maVfQigz4AAACMaVbA0sTmAkmSc9Uz/e7X+renJUnpgXJtfWRtj22lb5oO8RLXeEUlRyklP1WdckuSKjeXhaJsAAAAwFaELLCdFbCU1mlClsQZ4Z0ubOZXTlKlI00JqlfBA72nOwAAAADGivJNpYpVsyRpVvGL6mjq6LWPFbA0tXBV989VDz/bY3v9WjNVWFmimZbX6XaqwmWu8Wu3loakbgAAAMBOhCywXWNJo2LUIklKnRPekMXlcalw8lJJUv2jzx5lbwAAAGD0Kl1d2P19vBpVcN9bvfYpfHyTsgIHu3/O2rCqx3b/NtPJ0pw9rfu1Wq+5xm/awbosAAAAGH0IWWC7qo/NYKte8YpJjwn7+V0XL5ckTdz8rKyAFfbzAwAAAMNB44c7ev78WO+HkMr+YF77KP50+eVUftvHKn53f/f2qAOHgpr8/O7XmuLNlMBtewlZAAAAMPoQssB29dvNtAFVnvCux9Jl9s3nqV0eTezcpb0vFh79DQAAAMAoFNhuroX3u/MkSZO29H4IKf0DE7I0XLxCBfELJUm77znczZJaY4Ka2OMPd7J0JJtOFusg04UBAABg9CFkge1adh3qZImxJ2SJy47T5pTFkqQD96068s4AAADAKBVdbAKSvRd8S22K1HjfXu1eta17e9mGEs1sWS9Jyr/lQtWeZjrCY143wYuvzafcjl2SpIwzDneyBDLNdb6rnE4WAAAAjD6ELLBd534z2GpNCO96LJ/UfKYZICa+w7osAAAAGJvSa00nS8KZx2tz2lmSpOL7D18f77j7OUlSQcxJSp+bqfHXmWvoOdVvqLGkUQff2y+POtWmSGWfnNv9PleuCVm8dXSyAAAAYPQhZIH9ysxgqzPNnk4WScr7thkgzq5/V7W7a2yrAwAAALBDR1OHcjr3SpIyz5imlrOWSZKS3z0cskS+bL6vOsVcO0+6IF/73XmKVIe23POqKt4xnTBFkVPldB8eanonmYep4hvpZAEAAMDoQ8gC23kqDw22su3rZMlZOEE7vHPkll9b73jBtjoAAAAAOxS/vVdu+dWkGGUen60pN5mQZVbj+6ourFJrTavmlL8qScr6uglZHE6H9s0x33c+9axaNppOmKrU/B7Hjp9uHqZKbidkAQAAwOhDyALbxdSbwZZngn2dLJJUcvyhweIqpgwDAADA2FL5jglIiqKmyeF0aNyp41XoPU4uBbTtjudV8NvXFa1WHXTlatqlc7vfF/8lcw09fddzchRulyS1j5/W49gpc8x1fppVqc6WznD8OgAAAEDYELLAdgmtZrqwmKn2hiwpKw49rVf0IoM/AAAAjCmtH5mpvmpTDwckpQtMgOJ6/lm1/t08iLR7+jI5nI7ufWZ/63TVK0FpVoVmbn9CkuSe1bOTJXlqijrlliRVbi4L3S8BAAAA2ICQBbayApbSOk0nS+IM+6YLk6SZXzlJlY40JaheBfe/bWstAAAAQDg5d5lOlo5JhwOStK+akGXWwZc0tdCELFFfWN7jfRHREdqSe4EkKdWqkiQlnNizk8XpdqrCZa71awqYMgwAAACjCyELbNVY0qgYtUiSUufYG7K4PC5tz7tQklT/2CpbawEAAADCKb7MdLJEzDockMz48gJVODMUr0ZlBUrUpBjNufHMXu+1lvUMXnLOzu+1T63XdK037yoNZtkAAACA7QhZYKuqj82TbPVKUEx6jM3VSBEXmwHixM3PygpYNlcDAAAAhEdWowlZkk4+HLI43U4VHnoISZIKss6VN9Hb670zbr5A/kNDy2pHipLyknvt0xRvHqhq20snCwAAAEYXQhbYqn6bGWRVeeztYuky+5bz1C6PJnbu0t4XC+0uBwAAAAi5huIGZQTMWinjzuw51ZfnksNdKp3n9+xY6ZI8NUUF8QslSSUx0/rcpz3FdLJYB4/eydJc0aw3516vj3731tGLH+WqC6v05twbtO+VnXaXAgAAgH4QssBWLbvNIKs+xt5F77vEZsZqc4qZAuHAvc/aXA0AAAAQesWvmy6WCmeGEsYn9Ng2++ZzVedIVIuiNP3WC/t6uySp7vzLJEk1U0/uc7uVYR6qcpUfvZNl43/8U4s236vAj38yoPpHs83fvFeLNv9eFVfeYncpAAAA6AchC2zVud8MsloThkcniyQ1n2We0Et6h5AFAAAAo1/tGtPBXRLXey2VmPQYVf3rXRX97T2lzc7o9xinP/Ytrbv9ec1/5vY+t7tyzUNV3tqjhyy+zdskSclNRUfdd7Tz7N4qSZpT8apaqlpsrgYAAAB9IWSBrRylZpDVmTY8OlkkKe+mZZKk2Q3vqmZntc3VAAAAAKHVucV0sjRk9j3V15TPzlT+ZfOOeAyn26kTf7xE8TnxfW6PyjPX+/FNR58uzHvA1JPqKx3z6yQmV5nPIkptKrjnNZurAQAAQF8IWWCriCozyHKMGz4hS87CCdrhnSOXAtp25wt2lwMAAACElGefuZEfmNK7kyVY4qaZzvXk9qN3sqTUmHpi1KKG4oaQ1TTcWQFLua07un9u++cqG6sBAABAfwhZYKuYejPIihg/fKYLk6SS482UYY7nmDIMAAAAo1tSpZkuLOq4vjtZgiFljnmoKs2qVGdLZ7/7+Tv8ym3f1f1zdcHRO19Gq7IPDypGh6cIm7pj1Zjv7AEAABiOCFlgq4RWM2iKmTp8OlkkKfVqE7LMKnrxiINAAAAAYCT7ZLdE2sLQhSzJU1PUoQhJUuXmsn73K1lzQF61d/9cv+3onS+jVdlb5r9LsWuCGhWrrECJtj+2weaqAAAA8GmELLCNFbCU1mkGTYkzhlcny8yvnKRKR7oS1KCC+9+2uxwAAAAgJMo2lChWzfLJpZwzJofsPE63U5WuTElSTUH/wUn5W4U9fm7ZNXZDlsb15rMoSZmjLdnnSZLKH6LTHgAAYLghZIFtGoobutvfU+cMr5DF6XZq+5QLJUkNjzKQAQAAwOjU3S0RMUmeWE9Iz1XrNd3rzbv6nwKseeOOHj93Hhi704VZheazaMmdJt8S02mfsZaxCQAAwHBDyALbdM2vXK8ExaTH2FxNbxEXm4HMxM3PMvcxAAAARqWubomKpNAtet+lKd6ELG17j9CdsqNnJ4ujdOx2skQXm8/CmT9N+TcvVUAOzWjdoNL1B22uDAAAAJ9EyALbdM2vXOUZXl0sXWbffK7a5dEE327teX673eUAAAAAQRfo6pbICd16LF3aU8x1v1Xcf3ASW2LqKfTOlSRFVI3dkCW91nwW8SfmK21WurbEnixJ2nnXKjvLAgAAwKcQssA2XfMr18cMr0Xvu8RmxmpzypmSpKL7aMsHAADA6BNdbG7kO6eHvpPFyjTX/a6K/qcAy6g39ZTlL5YkxdSPzenC2hvalePbK0nKPMMEYNWnmk5776uMTQAAAIYTQhbYpmt+5ZbE4RmySFLzWWYgk/QuAxkAAACMPum1ZkqquBNC38niyjGdLN7avrtTWqpalOM/YPZZYh52SmwZm50sxW/tkUsBNSpWGfPM55b9DTM2mVPxmlqqWuwsDwAAAJ9AyALbdM2v7EsdntOFSVLeTcskSbMb3lPNzmqbqwEAAACCp6OpQzmdPbslQikqzzxcFd/Ud3dK8epdkqRaR5Iyz50jSUr1lY7J9RGr3jMdPcVR0+RwOiRJUy+erWLXBEWpTQX3vGZneQAAAPgEQhbYJqLKDK4c44ZvJ0vOwgkq9M6VSwFtu/MFu8sBAAAAgqb4rT1yy68mxSjz+NBfk8dPN+dIbu+7O6X6PdNVUxyTr7S55kGsGLWoobgh5LUNN62bzGdRk354GjeH06HdM003S9s/6bQHAAAYLghZYJuYejO4ihg/fDtZJKn0BDOQcTzHQAYAAACjR+W7plui6BPdEqGUPMtc96dZlepo6ui1vX2zqac+fZqiU6NV50iUJFV9PPamDHPtNp9F58SeHUYxl5lO+2k7VingC4S9LgAAAPRGyALbdM2vHDN1+HaySFLq1SZkmVX0Yp+DQQAAAGAkav3I3MivTQv9oveSlDw1RR2KkCRVbSnvtd29x3Rv+PJMPdURJpRpKOx7erHRLL7MfBYRs3qGLHNuWKxGxSozUKrtj22wozQAAAB8CiELbLHpnjc1wbdbATmU8Zk8u8s5opkrTlSlI10JalDB/W/bXQ4AAAAQFM69uyVJHeOnhOd8bqcORkyUJBU9s7HX9sRyE/pEzjHBQn2MeRirZdfY62TJbjSfRfKpPQOwyPhIbck+T5JUsZJOewAAgOGAkAVh19nSqZjvXidJemfmN8Iy//OxcLqd2j7lQklS42MMZAAAADA6eKuKJUnOCblhO+eB6edLktqfXNXjdStgKafFdG+knGpClpZE08nSeWBsdbLU769TmlUhSRq3eGqv7b4lptM+Yx1jEwAAgOGAkAVh9+4Vv9PU9i2qdqRozjO/tLucAYm42AxkJhY8Kytg2VwNAAAAcOziG03IEjU1J2znjL3CXFd/ek2R6sIqJVp1kqTcs0yw4EszD2M5SsdWJ0vx66aLpcyZpfic+F7b829eqoAcmtG6UaXrisNdHgAAAD6FkAVhVbahRMc/81NJ0tarfq2kvGRb6xmo2Tefq3Z5NMG3R3ue3253OQAAAMAxS20zN+gTZoUvZJl93aI+1xQpWW2ChWLXeEUlR0mSHONMyBJRNbZClrq1h0KWuGl9bk+bla4tsadIknbe/VzY6gIAAEDfCFkQVrs//++KV6MKYk7WwoeutrucAYvNjNXHqWdJkoruoy0fAAAAI1tbXZtSrSpJUtr88IUs/a0pUr/WTBVWnnB4DZKICWa6sJj6sTVdWGeB+SwasvL73af6M6YjyPsqYxMAAAC7EbIgbDbdvVoL9z+mgBxyPXCvnO6R9cev5WwzkEl6l4EMAAAARrbyDQclSS2KUuKkpLCeu681RfzbTPdG07jD3RuxU00nS2LL2Opk8ew3n0VgSt+dLJKU/fVlkqQ5Fa+ppaolLHUBAACgbyPrLjdGrM6WTsV+79Bi97O+qRlXnmBzRYM35SYzkJnd8J5qdlbbXA0AAAAwdHVbTMhSHpEjh9MR1nP3taaI94Dp3tDUw8FCwnTTyZLmKxlT6yKmVJrPInpe/yHL1Itnq9g1QVFq0+a7Xg1XaQAAAOgDIQvC4t0rfqcp7VtV5UjVnKd/YXc5QzLu1PEq9B4nlwLaesfzdpcDAAAADFnTdhNu1MWEb6qwLj3WFLlrlSQptcZ0b8Qcf3iKrLS5JmSJVqsaihvCXKU9Ar6Actp2SpLSTut/ujCH06HdM01HUPsTdNoDAADYiZAFIVe2oUQnPPMTSdK2q/5rxCx235fSBWYg43qOgQwAAABGrs69JmRpTg5/yCJJ1aeaLnHva6vk7/Art32XJCnj9MPdG9Gp0apzJEqSqj4eG1OGlX14UDFqUafcyjl90hH3jb3CjE3yd65SwBcIR3kAAADoAyELQm73529TnJpG3GL3fUn9ihkMzip+UR1NHTZXAwAAAAyN46AJWXwZ9oQs2d8wAcGcite057ltilSH2hSp7FPG99ivOsJ0szQUloa9RjuUvWU6eoojJisiOuKI+86+bpEaFauMQJm2P/phOMoDAABAHwhZEFJmsfu/msXu//e+EbfY/afNXHGiKpwZilejCu5/2+5yAAAAgCGJrDQhi2O8PSHLJ9cUKf3RfZKkosgpcnlcPfarj8mWJLXsGhudLI0fmvVYKpP6X4+lS2R8pArGnS9JqlhJpz0AAIBdRvYdbwxrvRa7/9LxNld07JxupwrzLpQkNT7GQAYAAAAjU1zDoQXn8+wJWT65psiCLY9IkqpTeq9B0pJkQpbO/WMjZFGh6WRpye1/PZZP8i8xn2HG+lUhKwkAAABHRsiCkHn3st+O+MXu++K5xAxkJhY8Kytg2VwNAAAAMHgprSZkiZ9pT8giHV5TJFqtkqS28b27N3ypZrowR9nYmC4s+qAJWZzTj97JIkn5316igBya0bpRpeuKQ1kaAAAA+kHIgpAo21CiE1b9VJK0bcWvR/Ri9582++Zz1aZITfDt0e5V2+wuBwAAABiUzpZOpQfKJEmp8+wLWbrWFOnimtE7WHCMM50sEVVjo5MlvdZMFxa/YGAhS9qsdG2JPUWStPMuulkAAADsQMiCkOha7H5z7Cla+Iev2F1OUMWkx2hz2lmSpOL7mTIMAAAAI0vFR6VyylKHIpSSn2pbHZHxkdqSfV73z4kn954iK2KC6WSJqR/9nSztDe3K8e2TJGUtHth0YZJU/RnTERT1KmMTAAAAOxCyIOg++v3b3Yvdux+4d8Qvdt+X1rPNQCb5XQYyQDC11bVpXdoSrb7wN3aXAgDAqFXzsZlWqtw9zvZrdd+hNUUkKXtx7+6N2KmmkyWxZWidLI0ljfog6yK9+W+/H1qBYVS0erdcCqhRsUqfmzng9437pvkM51e+pP0ReT2+Vp/0nVCVCwAAgENG391v2K72T89Ikt6bfOWoWOy+L+O/eo4kaWrjh6zLAgTRtj++rxOrXtTMF++wuxQAAEatxu0mZKmJtm+qsC4z/n2ZKh1p2h41r8+umsSZJmRJ85UM6bp70w/+rpPLntbMJ35+zLWGWu3GfZKkEm+eHE7HgN835XOzVOidK7f8muDb0+Nr8brfqOLjshBVDAAAAEly210ARp+oYrNYo/+Ek22uJHSyT52ggByKUpsqt1UqbVa63SUBo0LLLvOUamqgQr42n9xe/pkCACDYOvaYkKU50f6QJSU/VbU7tysnxtPn9rS5ZrqwaLWqvrhBCeMTBnX8iJfNOiVpVoXqD9QP+v3h1LbHXAc1xI0b1PscToeyd7+jgue39Hg94oZvKr/tIxXe+ZzSH7kmaHUCAACgJzpZEHRpNWaxxrgFA59HeKTxxHpU7jRP1VWu329zNcDo0bnf3FxwylJlQbnN1QAAMEoVm5ClI93+kEWSkvKSFZsZ2+e2qOQo1TkSJUlVHw9uyrC2ujbNKX25++eDb+wYco3h4C8yv19rcvag3xuXHafZ157S46v01M9LOhw0AQAAIDQIWRBUvjafcjt2S5IyTu89p/JoUhkzQZJU/zEhCxA0ZYcXta3dOvoXuAUAwA6RFSZkceQOj5DlaKo8JnSo3za4kGXzb99QjFq6f679YHiHLM5yc+0TSM8KyvEyrlkmSZpT+rLa6tqCckwAAAD0RsiCoCp+e68i5FOLopR14sgYtA1VU9J4SVL7DkIWIFg8lYdvnjQWDm2BWwAAcGSxdSZk8eSNjOv1hmgTOrTuGdwDGK1/f7bHz50FhUGrKRQiaw519OYMvpOlL9OvmK9S5zjFqEWbf/tGUI4JAACA3ghZEFSV75qnw4q8U+V0j+4/Xh1ZppPFUXTA5kqA0SOm/nCw0r6XkAUAgFBIbjUhS9z0kRGytCSZ0KFrWtGBsAKW8rababI2Jp4pSfLsG96dLLGNJkSKnBicThaH06Gd+aab5dOBEwAAAIJndN8FR9g1bzRPh9Wkjt71WLo4J5mQxVtOJwsQLAmth59QDRxkujAAAILN3+FXht+EFSnHjYyQxZdqQgdH2cCvDXb84yON8xepRVFq/co3JUnJVcO7kyW51fx3icsPTieLJEV9YbkkKW/7KlkBK2jHBQAAwGGELAgq507zdFj7hNG9HoskRU03IUtCPSELEAxWwFJa5+EnVJ3ldLIAABBslQXlcssvn1xKn5tpdzkD4hhnQoeIqoFfG5T+wXSxbM48V5nnHSdJym3dMWyDBn+HX2mBMklS0qzghSyzbzxLLYrSOH+RdvzjoyEdwwpYenfiF/Xe+MuH7ecHAABgJ0IWBFVcqQlZ3DNHf8iSONesyZLRRsgCBENjSWOPxWmjaghZAAAItuqPzFRhFa4suTwum6sZGM9EEzp8clrRo0ldY6bH6jhvuXJOnySfXIpRi8o+PBiSGo9VzY4queVXQA6lzc4I2nGjkqO0OfNcSYeDp8EqemuvFu7/qz5T9LiqC6uCVhsAAMBoQciCoMpsMC34iSeP/unCMk82nSxJVq0aSxptrgYY+ao+7nnjJLaJ6cIAAAi2xu0mZKiOGhlThUlSzBQzXVhiy8CuDSo+LtPs5rWSpGk3XyhPrEdFEZMlSWVvDc91Wao3m+ugKme63F53UI/dfq5Zl6UreBqs4qfXd39ft6MiKDUBAACMJoQsCJqmsiZlBczgIOes0d/JEpcdp1pHkiSpfN0Bm6sBRr76beb/P/yH/mlKaaeTBQCAYGvfbTpZmhJGTsiSONN0sqT5SgY0XVXhnc9JkrZGL1DGPBPQVCaZ8Unjh8MzZGncYQKkmsjgLHr/Sfm3mJBldvNaVXxcNuj3d7z3Yff3TXsrg1YXAADAaEHIgqApes0MWCodaUqclGRzNeFR7jXdLLWbmDIMOFYtu83NhT2RMyRJqYEK+dp8dpYEAMCoYxWZkKUjfeSELGlzTfAQrVY1FNUfdX/PS6Zjo+Lk5d2vteSaTntre2EIKjx2bXvMwyWNscFbj6VLxrwsbY1eIOlwADUY8TsPhywt++lkAQAA+DRCFgRN7QcmZCmNHf1dLF3qE8y6LK3bCVmAY9W539xcqMicK59ccspSZUG5zVUBADC6RJSbkMUaN3JClqjkKNU5EiVJVZuPPGVYW12bZpe9IknK/NrhkMWZb8Yo0cXDs5PFX2Sug1qTgx+ySIcDp64AaqCsgKXJdYdDls5iQhYAAIBPI2RB0HRsNk+F1WeO/vVYurSlm06WwD6mCwOOWZm5adKZnqMKl3litXYLU4YBABBMMXUmZPFMHjkhiyRVeUz40DW9aH82//YNxahFJa4c5V82r/v1+BPNGCW9dnh2sjjLzXVQID3404VJhwOn2WWvqK2ubcDvO7B6jxKtuu6frXJCFgAAgE8jZEHQROw1T4X588ZOJ4s13oQsEaV0sgDHylN56KZJdpZqveYGQ9f85AAAIDiSmk3IEjt9ZIUsDdHm2qB1z5GvDVr/bjo1duUvk8Pp6H498wwzRsnx7VVHU0eIqhy6yBpzHeTMCU0nS/5l81TiylGMWrT5ntcH/L6Dz37Y42dnFSELAADApxGyoF+b405VsyOm19f61PPl7/D32j+p0oQs3rljJ2SJnGZClrgaQhbgWMXUm5sLngnZaoozNxja99LJAgBAsFgBS5k+E7Ikzx1ZIUtLkrk26Nx3sN99rIClvO2rJElRX1jeY1vGvCw1KlYuBVS0enfQ6jqweo92emfrzcvvO6bjxDaa8ChyUmhCFofToV35yyRJrf9YNeD3dS1636ZISZKnjpAFg/Pmpb/TTu8cFb+zz+5SAAAIGUIW9CvC36YYtfT6WlD9srY+srbHvlbAUk6Lab1PXTh2pguLn23WZElrJmQBjlVCq7m5EDM1W+3J5mnVwEE6WQAACJbqwipFqkMBOZR+XGimpQoVX5a57nYe2NfvPpUF5RrnL1JADs26bnGPbQ6nQ8VR5mGwqveCty7Lnu89qKntWzTtH7+UFbCGfJzkVvNgSdy00P13ifo3E7LkbV814Fq7Fr0vSFksSYpuImTBwAV8Ac146pea2l6gXd97yO5yAAAIGUIW9CvhrVUqenNPj681WRdJkqof6blgYmVBueLVKL+cyl2cZ0O19kg/0XSyZARK1NnSaXM1wMhlBSyldZqbC4kzshTINE9xOsvpZAEAIFiqNpkulkpnhjyxHpurGRz3TBOQxJb2H5CUvmm2FbsnKjo1utf22jRzjNaPghey5Gwy46KsQIm2P7ZhSMfwd/iVFiiTJCXNCk0niyTNvvEstShK4/xF2vGPj466/ycXvW8+Y4kkKa6NkAUDt/VP65QeKJckZX347FH2BgBg5CJkQb+yFoxT7hmTenz5P3eJJCl7Y88W85I3TBdLsXuiIuMjw16rXVJnpqtVXjllqWx9sd3lACNWY0mjYtQiSUqdkyVXrrnBEFVDyAIAQLA0bDXXq9XecTZXMniJJ5mAJLOh/4CkYb3ZVpHQ9/TFHZNMx71rV2FQajqweo+mtG/t/rn8oaHdRK7ZUSW3/ArIobTZGUGprS9RyVHanHmuJKn0waPX2rXofbs8yvrSWZKk5E5CFgxc1cOH/5zlt32s4neZAQIAMDoRsmBQZtyyRH45Na1tc48LpIYPDw1oEsfOeiySmXagLMJMXVC9gQtGYKiqPjZhSr0SFJMeI+8kM1VGbBPThQEAECxtu0zI0hg/stZjkaRxZ5pxRra/WM0VzX3u499qwpPmnL6nL46YZY4RXxacTpa9vzMPnnUoQpKUvm7ga518UvVmcx1U5UyX2+sOSm396TjPrFWT9sHRQ5auRe93R89V+vHmz0yC6tXe0B66AjGqZH3Y8+/I7nuG9ncEAIDhjpAFg5I8NUUF8QslSbvvPnxhHjg0oGnpZ0AzmtXEmZClaQshCzBU9dsO3VzwmHAlfrrpZElpp5MFAIBgCRwwIUtb2sgLWZLyklXlSJUkFb+xs899oooPhSfT+n7wK/lUM1bJbgxOJ0vsajMeeu+kmxWQQzNbPlTZhsFfuzQWmvdUR4ZuqrAu026+UJI0q3mdyjcd+WGWrkXvqyacoIQJieqUCYBqCitDWyRGhYPvH1B+20fyy6n3Tvy2JCn6DUIWAMDoRMiCQas9zTz9FPPG4ZCle0CTP7Y6WSSpJdWsy+Lbc8DmSoCRq2W3GeTXx5ibC8mzTNiSGqiQr81nW10AAIwm7jITsljZIy9kkaSSWDPWqH6v75Akrca8Hreg7we/xi2eavazKlS/v+6YamkobtCcmjclSRN+do22xJ4sSdpx5+BvIrftNddBTbGhW/S+S8a8LG2JOVGStOPu54+4b9ei944TF8jhdKjKmS5JqtvBlGE4ul2Hula2xJ2q3B9fLUmaW/W6msqa7CwLAICQIGTBoI2/zoQsc6pXq7GkUZKUVmtClrjjx17I4s8xIYurmE4WYKg695snOFsTzM2FlOlp8sklpyxVFpTbWRoAAKNGdK0JWSImjcyQpT7ThCcdBb2n+/K1+ZTbsVuSlHF632OS+Jx4lTnNtUbx68c2ZdiWO1+SR53aGzFNk86fpupTzRjJ+8rg12XxFx26DkoOfSeLJFWebGr1vNR/rZ9c9D7tghMkSfWRJmRp3kvIgqOLfs38+apZuFyTl07XfneeItWhgrtesbkyAACCj5AFgzbpgnzti5iiSHVoy92vqLOls3tAk7lo7E0X5s4zIUt0FSELMGRl5gnOzjRzc8HpdqrCZW6C1G5hyjAAAIIhqcmELDH5IzNk8U824UnEnt6dLMVv71WEfGpRlLJO7P/3K4szx6hbe2whi/9pcwN5/1wTWGR/49CDaBWvqqWqZVDHcpab66BAeug7WSQp89plkqTZZa+ora6tz30+uej95OWzJElN0SZkaTtAyIIjaypr0tyq1yVJOd9aLofToX1zzN+RzqcGH0QCADDcEbJg0D59gXTw3X3dA5rME8bZXF34xc40a7IkNxKyAEPlqTRBimPc4Sc4a73mRkPjjiPPFw4AAI7OClhK7zQhS9KckRmyeOeagCSxsndAUvmuea3IO1VOd//D3IYsc4zOLUMPWfwdfs3Ya6baSrzSBBZTL56tYtd4RalNBfe8NqjjRdaY6yBnTng6WfIvm6cSV45i1KLN97ze5z6fXPTeE+uRJLXFm5DFV0LIgiMruOsVRapDB9yTlLdshiQp7grzd2X6rucU8AXsLA8AgKAjZMGQJHzJhCzTdz+n8tXbJElF3mlHHNCMVinHm06WrM4DXCwCQxRTb24uRIw//ARnU5y50dC+l04WAACOVf3+OsXIdFikzx+ZD0alLjRd8znNO2QFrB7bmjeZ0KQm5cjTFwemmGN49vW9rstAbFm5RilWteociZr19YWSzINou2eaMVLbPwf3pH5cg7nWiZwUnpDF4XRoV7654d36975r7V70fuKC7td8ySZkUQUhC46sq1tl7yzTxSJJs791uuoVrzSrQlsfWWtneQAABN3YuyOOoJj9zdNUrwSlWZUK/OnPkqSa1LG3HoskZS7IkV9OedWu6u2VdpcDjEgJraZbJWbq4ZsL7Snm+0AxIQsAAMeqYoPpYql2pCgqOcrmaoYmZ1GeAnIoQfWq2trzRr9zhwlN2iceefri6HlmzJJcNfROlpo/mRvIW8YvUUR0RPfrMZeZkGXajlWDevgqqc1cB8VNC890YZIU9QVT65TCVb0CK0mK37lekuRYcMLhF9NMyOKuIWRB/wK+gKbvek6SFPfF5d2ve2I92pJ7gSSp6mGmDAMAjC6ELBiSiOgIbRm/RJJ00sEnJR19QDNaRURHqNxlbgZXrGPKMGCwrICltE4TpCTOPByyBDLMjQZnBdOFAQBwrOq3mJClKnJkThUmSd5Er4rdEyVJJat7hiRxpeZn98wjP/iVdpoZs+S27hhyF3rOJnOD2LF8eY/X59ywWI2KVWagVIV/2zigY/k7/EoLlEmSkmaFp5NFkubcdJaaFa1sf7EKH9/UY5tZ9H6DpMOL3kuSK8uELJENhCzo39Y/rVOaVaF6xWv2/zujxzbrQvN3JmvDKjtKAwAgZAhZMGTWhabF3CUzOHHPGpudLJJUFW3WZWnYTMgCDFZDcUP39CVpcw8/wenKNTcaomroZAEA4Fi17jIhS338yA1ZJKkiwYw5Gtb1nO4rs8H8nHjykR/8yjl9kjrlVoxaVL5x8NcYB1bv0ZT2rfLJpZm3XNBjW2R8pLZknydJKn9oYE/q1+yoklt+BeRQ2uyMQdczVN5Erwoyz5UklT3U84Z3X4veS5J3vAlZYpoJWdC/ri6VrTnnd6/n02XGLUvkl1P5bR+r+F3GzgCA0YOQBUM289Yl8snV/XPiiWM3ZGlMNuuytO/gQhEYrOoC06lSrwRFp0Z3v+6dZAKX2CY6WQAAOFaBAwclSW0pIztkac4xIYp/2+FOlqayJmUFTGCSc9aRxyQR0REqjpgsSSpdPfh1Wfb+1txA3px4uhInJfXa7ltintTPWDuwkKV6s6m7ypkut9c96HqORcd55qG5tA961tq16P2umON63CSPmWRCloR2Qhb0L+tD8+fJf+HyXtuSp6aoIP4zkqTd99DNAgAYPQhZMGRJeckqSFjY/fPRBjSjWWeWCVkcRQdsrgQYeeq3Hbq54Ok5RUb8dPNzSjudLAAAHCtXqelkCWSP7JBF08yYI6rocEBS9JoJXCodaX0GH59WmWSO0bRh8OuyxK02N5Drz+h9A1mS8m9eqoAcmtG6QaXrDx71eI2F5jqnOjJ8U4V1mXbzhZKkWc3rdGD1HjWVNamprEkdb60xNU04ocf+8VNMyJLir+hzHReg+N39ym/7WH45NePmJX3uU7vQ/N2Jfe3p7j9z/X211rSGs3wAAIaMkAXHpO40c4E00AHNaOWcZEIWbwWdLMBgtew+1MkS03Ox1+TZ5mZDaqBCvjZf2OsCAGA0iao2IYt74sgOWWKPNwFJas3hgKT2A/N9aezAHvpqyTX7Wdu2D+rcDcUNmlP7piRpwv9b1uc+abPStSX2ZEnSzruO/qR+215zHdQUG75F77tkzMvSlpgTJUnjz8xTbFacYrPitHjDXZI+tei9pOT8NEmSV+1qLGkMb7EYEfb8/nlJ0pa4U5WSn9rnPrn/z9xDOKHmle4/c/19RabEaPWy/wlb/QAADBUhC47J9J99Ufvdk7Xl+KvsLsVWUflmTZbEOkIWYLA695snOFsSez7BmZKfqk655ZSlyoJyO0oDAGDUSGgyIUv0tJEdsmQuOrRwfcfu7ocwOgpMyFKfObCQJeKk4yVJWYVvDOrcW+58SRHyaW/ENE06v/9zVZ9qbiJ7Xz36lGH+InMd1Joc/k4WSaq94roeU0B3qXSkacr1PdeciU6NVqNizfsKmTIMvVmF5u9izfTP9LvP5KXT9WHyuQM6nlOW8l66l84pAMCwR8iCY5J5fLYmdO7W4vVj++mSpHmmkyWjnZAFGCxHqbm54Evt+QSn0+1UpStTklS7hSnDAAA4FuntJmRJnD2yQ5asE3PUoih51KmD7+6TJEXsMVOH+fOOvOh9lxk3XyC/nJrWtnlQi2/7nzahyf65fU8V1iX7G2b7nIrX1FLVcsR9neWmkyWQYU/IctofVijQ2KLW6p5fyW2lyjqx95+VGreZMqxhFyELenPVV5tvUvvuYpEkh9Oh4ytf6vVn7tNftbuq1Sqvcn37tOvpLWH6DQAAGBpCFiAIMk481Mli1amhuMHmaoCRJaLK3FxwjOt9c6HWa4KXrvnKAQDA4DWWNCpB9ZKktHnjbK7m2DjdThV5p0qSKt4xT80nVZr/9c4dWCeLWXzbrC25++6BLVDv7/Brxl4zFVLil48csky9eLaKXRMUpTZtvuvVI+4bWWOucZzjwj9dWBdPrEdRyVE9vlye3t0tktTgNSFLyz5CFvQW2WhCFldG/yGLZIKWT/+Z+/RXUl6yNqefLUk6+MDA/p4CAGAXQhYgCOKy41TrMGvSlK87YHM1wMgSU29uLkRM7B2yNMWZ19r3lYa1JgAARpPKTWYB9nolKC47zuZqjl1NiglTmjcWygpYymkxnSypCwfWySJJtYfWlox5Y2A3b7c89L5SrGrVOpI0+xsLj7ivw+nQ7pnm+O1PHnldlrgGcx0UOcmeTpbBaok1IUt7ESELeotqqZIkebJSgnK8trPN2kfJ7x99fSMAAOxEyAIESbnXTBlW9xFThgGDkdBqApSYvN5PcLanmBsOgWI6WQAAGKq6AjNVWEXkyJ4qrEv7BBOyOHfuUGVBueLVKL+cyl2cN+Bj5H7L3LydU716QIu41/zJhDFbxy+R2+s+6v6xV5iQZdqOVQr4Av3ul9RmroPi8kdGyNKeYEKWQBkhC3qLazedLFE5wQlZpt5s/p7ObnxfVdsqg3JMAABCgZAFCJL6BBOytGwnZAEGygpYSus0AUrizN43FwIZJnhxVtDJAgDAULXsMCFLfezIniqsi3uW6ViJKylUyRumi6XYPVGR8ZEDPsbkpdO1352nSHWo4K6Xj7p/zkfmSXrHZ488VViX2dctUqNilRko1fbHNvS5j7/Dr7RAmSQpaaZ904UNRiDFhCyOSkIW9JbgNyFLzPjghCxZJ+ZoW9R8OWVp+53PB+WYAACEAiELECRtGSZksfYxXRgwUA3FDYqRWRA2bW7vmwuuXBO8RNXQyQIAwFD59pmQpTV5dHSyJJ5kOlkyG3ao4UOzHktF4sDWY+nicDq0b44JTHz/OvJURAdW79GU9q3yyaWZN58/oONHxkdqS/Z5praVfU9JVr29Um75FZBDabMzBlG9fRzpaZKkiFpCFvTka/Mp0aqTJMVPCk7IIknlJ5q/p64XWJcFADB8EbIAQWLljpckeUrpZAEGqrrAdKjUK0HRqdG9tnsnmeAlromQBQCAoXKWmJDFnzU6QpZxZ5pAJStwUPrQdIm0jBtcyCJJ8V8yN2+n735O/g5/v/vt/a25ubs58XQlTkoa8PF9S8zxM9b1fXO4Zou5Dqpypg9oCrLhwJ1tOlmiGglZ0FPt7pru75PykoN23PRrzN+j2QdfUntDe9COCwBAMBGyAEESOc10ssTVELIAA1W/zYQnVZ6+5yGPn25eT25nujAAAIbKW21CFueE0RGyJOUlq8qRKknKK3zOvDh94Ived5n9rdNVrwSlWZXa+sjafveLW21CkvozBjZVWJf8m5cqIIdmtG5U6briXtsbC811UHXkyFiPRZKiJpiQJbaVkAU9New1U4XVORKDGhpO/+LxKndmKk5NKrj3zaAdFwCAYCJkAYIkYa4JWVJbCFmAgWrZfaiTJabveciTZ5ubDqmBCnW2dIatLgAARpOEBnODP2rK6AhZJKkk1nSujPMXSZLijh98J0tEdIS25F4gSap+pO9uk/oD9ZpTa27sTrx+cCFL2qx0bYk9RZK0867eU5K17TXXQY1xIydkiZ1sQpbEDkIW9NR8wIQs9a7gTRUmSU63U4VTl0mSmv7KlGEAgOGJkAUIkrQFJmTJCJSqo6nD5mqAkaFzv3mCsyWx75sLKfmp6pRbTlmq2lIeztIAABg1UttNyJIwa/SELPWZPTtXMhcNvpNFkqxlJjgZt6Hvm7db7npJEfJpjydfE8+dOujjV3/GHD/q1d7H9xeZ66C2pJGx6L0kJU4zIUuyVX3EKdYw9rQWm5ClMTK4IYskRV5i/h7lbX1WVsAK+vEBADhWhCxAkKTOSFOrvHLKUtn63tMBAOjNUWpuLvjS+g5ZnG6nKl2ZkqTarUwZBgDAYLXWtCrFMjc/048fPSGLf/LhzpUWRSnzhHFDOs7MW5fIL6emtheo+J19vbYHnjEdKAfmDq6Lpcu4b5r3zal8Tc0VzT22OcvMdVAgY+R0siRPM9O0uRTosQYH0FFq/n+mNTo16Meec/M5apVXOf792vX0lqAfHwCAY0XIAgSJw+lQWcR4SVL1BqYMAwYiosoEJ47s/p/grPWabV3zlgMAgIGr2HhQktSsaCVMSLS3mCDyHne4c6XIO01O99CGtkl5ySqIXyhJ2n1Pzym9/B1+zdj7vCQp8cplQzr+lM/NUrFrgrxqV8E9r/XYFllrroOc40ZOJ4vb61a1w3Qq1O1gyjAc5i+vkiS1xwW/kyU6NVqb08+WJB18gCnDAADDDyELEEQ1cWbKsOathCzAQMTUm+AkYmL/T3A2HZqnvH0fnSwAAAxW7WbTYV0RkSOH02FzNcGT+pnDnSw1qYNfj+WTak8z3SYxb/S8ebvlofeVYlWr1pGk2d9YOKRjO5wO7Z5pjt/+RM/jxzWY66DISSOnk0WS6iLMlGGNuwlZ8AnVppPFnxD8kEWS2s42QWfKe4QsAIDhx213AcBo0pw2QaqRfHsO2F0KMOxYAUsH39vfY/7u5BazWG3s1P5vLrSnZEtlUqCYThYAAAarudCELLWxOZpkcy3BlLMoTwE55JSl9gnHFrKMv2659Px3NLf6De16eosi4rySpNr7/ypJ2jp+iRZ6hz50jr1iubT598rfuUr7X9slOUzYldJm/tvE5Y+skKUxKl3q2KbW/YQsOMxVZ0IWKzk0IcvUm5dJf/2WZjWt0bZHNyg6K+GI+2cuyFFkfGRIagEA4NMIWYAgCowbLxVKrmI6WYBPe2f6NTp958N9bkuY3v80GYGMLGmL5CotClVpAACMWp17zY38lqTRsx6LJHkTvTrgnqjxvr1yzx7aovddJl2Qr30RUzSxc5emXDS7+/UJh/7X8dmhrcfSZfZ1i9T4g1hlBMqkc6b22p40c+RMFyZJrXHpUr3UeZCQBYdFNJqQxZkWmpAl68QcbYuarxmtGzXjyhOOuv8eT74mNG6Ry+MKST0AAHwS04UBQeTOM0OxmCpCFuCTWmtadcLOv0mSGhWrBsV1f61POU85p03s971RpxwnSZq4b7WsgBWOcgEAGDUcJWZNFl/m6ApZJGnP2V/XzshZyr/+vGM6jsPpUNEV31WNI7nHNUqD4rQl5kTN/cHQ1mPpEhkfqQ/P/HfVK6HX8T/IWK7M40dWJ0tHkpkuzConZMFhUc0mZInICv7C911qrr5NVY7UXn+PPv0VkEOTOwq1ZeWakNUCAMAnEbIAQRQ7y4QsyU2ELMAnbb77NUWrVcWu8Yr1NyjeOvy1oOqlIz5hNvums9WmSOX69mn3s1vDWDUAACNfZJXpZHGOH30hy+IXv6epbQVKm51xzMc6/U/XKjlQ3eMaJd5q0KymtYrNjD32Wl//sRKsul7HP7nsmRG3Vo6VakIWZxUhCw6LbTML33vHhaaTRZIW3vtFpQYqe/09+vTX+xMulyTV/In1WwAA4UHIAgRR6gkmZMnsLFLAF7C5GmD4aPvnKknS7pnLB30jISY9RpvTzpYkFd/PQAkAgMGIrzchi3fK6AtZYA9npglZPPWELDgsvtN0skTnhi5kGSjHcjPF37hNq2yuBAAwVhCyAEGUcfw4+eWUV+2q2sqgA5DMgvdTC80AJ+YLQ5tuo/Vs877k9whZAAAYjK7F1eNnErIgODw5JmSJbmK8A8MKWEq0aiRJ8ZPsD1lm3nKBfHJpavsWFb211+5yAABjACELEEQR0REqd5k5lSvWMWUYIEnb/7pRWYGDalKMZl+/eEjHmPJtE7LMbnxfVdsqg1gdAACjV0dTh9IC5ZKk1HmELAiO6IkmZIlvI2SB0VDcoAj5JEmJefaHLImTklSQcJokac89PKQFAAg9QhYgyKqizZRhDQWELIAklT9kBjYFWefJm+gd0jGyT87V9qh5csrS9jufD2Z5AACMWhUflcopS+3yKCU/dItRY2yJyzMhS1InIQuMul1mPZZmRSsqOcrmaoy6082UYbGrCVkAAKFHyAIEWWOyCVk6dh6wuRJgeEhfawY2nRcsP6bjlC0w73e9wEAJAICBqPnYTBVW5s4ZcYurY/hKnm5ClgQ1qK2uzeZqMBw07TfrsdS57O9i6TLhejN2mFPzphqKG2yuBgAw2hGyAEHWmTVekuQ4QCcLULahRDNbPlRADk2/9cJjOlb6NWagNPvgS2pvaA9GeQAAjGpN203IUhvDVGEInvjcBHUoQpJUU8g0rpBaikzI0ugZPiHLpPOnaW/ENHnUqS13vmR3OQCAUY6QBQgy5yTTyeKtIGQBdtxpFrzfEnuy0malH9Oxpn/pBJU7MxWnJhXc+2YwygMAYFTr2GNCluZEQhYEj8PpULXTXNfV72TKMEgdpSZkafEOn5BFkvbPNQ9p+Z+mEx4AEFqELECQRU03IUtiPSEL4H3FDGiqT1l2zMdyup3aMcV0wzT9lYESAABH4zhoQpbO9HE2V4LRpi7ShCxNewhZIPnKTcjSFju81n5K/LIJWWbsfV7+Dr/N1QAARjNCFiDIkuaZkCWjnTVZMLa1VLVoTsWrkqTsbxzbeixdPJeY4+RtfVZWwArKMQEAGK08FSZkceTSyYLgao42IUt7ESELJKvSLHzfmTC8Ollmf2Ohah1JSrGqteWh9+0uBwAwihGyAEGWeZJZkyXRqmOBPYxpBb99XVFqU7FrvKZ+fk5Qjjn72+eoTZHK8e/Xrqe3BOWYAACMVrH1JmSJzCNkQXC1JZiQxVdCyALJWWs6Wayk4RWyuL1ubR2/RJJU83+rbK4GADCaEbIAQRabGasaR7IkqewDpgzD2NX2DzOl1+6Zy+VwOoJyzJj0GG1OO1uSdPABpgwDAOBIUlpNyBI3g5AFweVLOrTWXgUhCyR3gwlZHKnDK2SRJMdnTSd8zibGDgCA0CFkAUKg3GumDKv7iJAFY5MVsDR1h3laLOay4EwV1qX1HHO8lPcYKAEA0B9fm0/p/lJJUspxhCwIsnQTsrhrCFkgeZtMyOLOHF5rskjSrFsvkE8uTWnfqgOr99hdDgBglCJkAUKgPtGELK07WJcFY9P2xzYoK1CiJsVozg2Lg3rsqTcvkyTNalqjyi0M7AEA6EtlQbnc8ssnl9JmZ9hdDkYZd7YJWSIbuBaDFN1mQpbI7OHXyZIwIVGbE0+XJO39LQ9pAQBCg5AFCIH2dLMui7WXThaMTeWPvCBJKsg6T5HxkUE9dtaJOdoeNU9OWSr83UtBPTYAAKNF9UdmqrByV7ZcHpfN1WC0icxJkyTFNpfbXAmGg/gOs/B9dO7wC1kkqf4M0wkf89YLNlcCABitCFmAELAmmE4WTykhC8Ymz47NkqS2ExaG5PjlU06TJPk2FoTk+AAAjHSN203IUhPFVGEIvtgpmZKkpPYymyvBcJDoN50ssROGZ8iSsGi+JCmpkZkmAAChQcgChEDkNBOyxNUSsmBsSq7aIUmKnp8fmhNMmyZJ8hbtCM3xAQAY4Tp2m5ClKZGQBcGXPDtbkpQWKJe/w29zNbBTa02rotUqSUqYPDxDlpjxpq74zmqbKwEAjFaELEAIJMwxIUtqC0/KYOwJ+ALKbTXhR/rpoQlZYk8wx02rLgzJ8QEAGOmsIhOytKcTsiD4Umemyy+nXAqoaivrsoxldbtNcNEpt+Jz4m2upm9xE03IkmjVyApYNlcDABiNCFmAEEg7wazJkhEoVUdTh83VAOFVvrFEMWpRp9wat3BiSM6RcbrpZMnt2MXTkwAA9CGi8qD5JoeQBcHn8rhU6cyQJNUUlNhcDezUsNeELLXOFDmcDpur6VvSFBOyRMinhuIGm6sBAIxGhCxACKTOSFOLouSUpdK1RXaXA4RV6WrTXVLkyVNEdERIzpF9yni1KVIedar4nX0hOQcAACNZbK3pZPFMJmRBaNR4zZRhjTtKba4Edmrebxa9b4gYnlOFSZI30atmRUuS6vcwZRgAIPgIWYAQcDgdKvOYbpaajazLgrGlaYOZKqwyaVrIzuF0O1UUOVWSVPEO67IAAPBpSS0mZImbTsiC0GiMMyFL2x46WcaythITWjRHDt+QRZJqXamSpMa9VTZXAgAYjQhZgBCpjTUhS/M21mXB2GJtN50srTmhC1kkqTrFHL9lI+uyAADwSQFfQBk+M11Y8lxCFoRGe1KWJClQTMgylvnKTMjSGpNqcyVH1ugxIVBLEZ0sAIDgI2QBQqQ5bYIkybebThaMLdEHTWeJc2ZoFr3v0jbBHN+xk04WAAA+qbqwSpHqUEAOpR+XZXc5GKUCmaaTxVnOdGFjWaDShBYd8cO7k6UlytTXUUrIAgAIPkIWIEQCOSZkcR0kZMHYkl5rQo/4E0LbyeKeaY4fW0LIAgDAJzWX1EuSGhUXsvXRAOc4E+B5a+hkGcsc1Wb6rUDi8A5Z2mNMfb5yQhYAQPARsgAh4p5iQpaYKkIWjB3tDe3K8e2VJGWfGdpOloSTzPEzG5guDACAT2qrapIktThjba4Eo5l3sulkiW2ik2Usc9UfCi1ShnfI0plopjOzKlmTBQAQfIQsQIjEzjBrsiQ3sSYLxo7it/bIpYAaFKe02RkhPde4M00nS7a/WM0VzSE9FwAAI0l7tQlZ2lyELAiduHwTsiS30ckylkU2mZDFlT68QxYrydTnrKWTBQAQfIQsQIiknmA6WbI6DyjgC9hcDRAeVe+arpLi6Hw5nI6Qnit5aoqqHWawVPzGzpCeCwCAkaSj5lDI4iZkQegkzzLThaUFyuXv8NtcDewS1WJCC0/28F743pFqxg3uBkIWAEDwEbIAIZJx/Dj55VSkOlRZUG53OUBYtH5k1kepTQvteixdSmLMearXsC4LAABdfHUmZOmIiLG5EoxmqTPT5ZdTLgVUtbXC7nJgk7h2E1pE5QzvThZ3hqnP20TIAgAIPkIWIEQioiNU5honSapcz7osGBtcu0wnS+ek8IQs9RnmPB0fsy4LAABd/A1mGs2OSDpZEDouj0uVTjM9bE0BU4aNVYk+s8ZJ7IThHbJEZpv6otsIWQAAwUfIAoRQdbRZl6VhC+uyYGyILzcdJZ45oV30vosvz5zHvZdOFgAAuvjrTSeLj5AFIVbjNeuyNO4otbkSDFVbXZu2/t96WQFr0O/1tfmUoHpJUvyk4R2yRI8305nFd7DwPQAg+AhZgBBqTDbrsnTsoJMFY0N2o+koSTo5PJ0skXPNeZIq6GQBAKCL1XgoZIkiZEFoNcaZkKVtD50sI9WaZb/QzBUn6p2v/nHQ763dXSNJCsihxElJwS4tqOImmhAo0U8nCwAg+AhZgBDqTDHt86qstLcQIAzq9tYqzTJ/1nPPDk/IkvoZ08mS07xjSE/fAQAwKjWZkCVAyIIQa0/KkiQFiglZRqrEgrclSbFPPzro9zbsNYFFvSNRbq87qHUFW8LkQ9OFqVWtNa02VwMAGG0IWYBQSjYXcq46npbB6Hdw9U5JUqkzW7GZ4bmpk7MoTwE5lKB6VW0jzAQAQJIczSZksWIIWRBagUzTyeIsZ7qwkSqr0Uy7O7vubdXvrxvUe5sPHApZ3MN7qjBJisuOU6dMEFS3m/E5ACC4CFmAEHKmm3lfPY1cxGH0q/3ATNlVFh+e9VgkKSo5SgfdZlq+kjeYMgwAAElytJqF7xUTY28hGPWcuSZk8dbQyTISNRQ3KCNQJkmKkE9b7nhxUO9vLTLrmzR5hn/I4nA6VOs0dTbsYV0WAEBwEbIAIRSRaS7ivC2ELBj9fFvMU3CNWeGZKqxLeYI5X8P6HWE9LwAAw5W71XSyOOLoZEFoeSea6cLiGglZRqLi13teP1vPrhrU+ztKzTi3NXr4hyySVB9hHoLs6sABACBYCFmAEPKOMxebsW08KYPRL3Kf6SQJTA1vyNI8znTO+LfSyQIAgCS520zI4ownZEFoxeWbTpakdqYLG4lqPzAhS73iJUkz9z8vX5tvwO/3V5iwoj0uNfjFhUCz14zP20oIWQAAwUXIAoRQzHhzERffyUUcRr/kKjNIi5kfvunCJEnTTKgTVUQnCwAAkhTRYUIWVwIhC0IreZbpZEkLlMvf4be5GgxWZ4F5SOnjqZeo2pGiJKtWW/7w3sAPUG3Gub7EkdHJ0nao48ZXxvgcABBchCxACMVNNBdxSVaNrIBlczVA6AR8AeW2mZAjbWF4O1lijzfnS62hkwUAAEmKPBSyRCQRsiC0Umemyy+nXAqoamuF3eVgkDz7zPW7f+oMbZu0VJJU+3/PDvj9rrpDYUXyyAhZOuJNnYFKQhYAQHARsgAhlDTFXMS55VdDUb3N1QChU/bhQUWrVZ1yK+f0SWE9d8YZpnMmt2P3oKY3AABgtIr0EbIgPFwelyqcmZKkmgLWZRlpkirNQ0pR8/Ll/OwySdL4jwcesngazLTYzrSREbIEksy0Zo5qpvMGAAQXIQsQQt5Er5oUI0mq28WFHEavsrfMU3BFnjy5ve6wnjv75Fy1yiuPOnXwvf1hPTcAAMOR198sSfIkxdhcCcaCWq+ZMqyxkJBlJLEClnJbD3eiz7r5fHXKrckdhdr3ys4BHcPbYjpCIrJGxposSjFhkKueThYAQHARsgAhVucyF3KN+7iQw+jV+KF5Cq4yKbxThUmS0+1UkXeqJKnibaYMAwAgOmA6WbypdLIg9BrjsiVJbXtLba4Eg1G2oUSxapZPLuWcMVkJ4xO0OWmRJGnf7wfWzRLbZsa43nEjo5PFlW7qjGxibA4ACC5CFiDEGj3mQq61mAs5jGKF5im41twwL3p/SHWKCXdaNu2w5fwAAAwnMZYJWaLSCFkQeu3JJmQJFNPJMpJ0daIXR0ySJ9YjSWpcvFySlPDWwEKW+E4zxo0ZPzJCFk+WqTOqhbE5ACC4CFmAEGuJMhdy7aVcyGH0ii42HSTOGeHvZJGk9gkm3HHsoJMFADC2dTR1yKNOSVJ0OiELQi+QYaYLc5YTsowkjR+akKUy8fD1+6QbTcgyp+5t1e+vO+L7rYClJMuMceMmjoyQJSrH1BnXzlTeAIDgsjVkeeutt7R8+XJlZ2fL4XDoX//6V4/tTz75pM477zylpKTI4XBo06ZNvY7R1tam6667TikpKYqNjdUll1yi8vLy8PwCwAC0x5r5af3lhCwYvdLrzCAt4UR7OlncM83gMLaUThYAwNjWXN7U/X10GmuyIPScuaaTxVvDdGEjSWC7eTip+ROd6OMXT9auyJlyy68td7x4xPc3FNXLLb8kKWnKyAhZYieasXmij7E5ACC4bA1Zmpubddxxx+nee+/td/tpp52mX//61/0e4+abb9azzz6rf/zjH3rzzTdVUlKiz3/+86EqGRi0zgRzwWlV8rQMRqf2hnbl+PZJkrIW2dPJknCiOW9WPZ0sAICxraXChCxtilREdITN1WAs8E40nSxxjXSyjCTRxebhJGd+z+v34uOWSZKsZ448ZVjdbhNUNClG3kRvCCoMvoTJZmyeoHr52nw2VwMAGE3cdp58yZIlWrJkSb/bv/zlL0uS9u3b1+f2+vp6rVy5Uo899pjOOussSdLDDz+sGTNmaM2aNTrllFOCXjMwWFaSuZBz1vK0DI5Nc0WzNv74SQXqm3q87hmfqZN/dZEcToctdRWt3q0pCqhe8UqbnWFLDTlnmyfwsgIH1VTWpNhMpkcBAIxNbdXNkqQWR4xGxm1PjHRx+aaTJamdTpaRJL3WPJwUt6BnJ3ryiuXS2v/WrAPP660r7u/3/YF9BzRBUp0rRSPlyjtxUpICcsgpS7W7a5Q2K93ukgAAo4StIcux+vDDD9XZ2alzzjmn+7Xp06dr/Pjxev/99/sNWdrb29Xe3t79c0NDQ8hrxdjlSDUhS0QDIQuOzbov/1aLX/5Bn9vWx7+oBf9xfpgrMqreLdQUSQejpynBpqAnKS9ZVY5UpVpV2reqQLOvJWQHAIxN7dXmYYwWZ6ySba4FY0PKHBOypAXK5Wvzye0d0bcZxoSOpg7ldO6VJGWe0bOTZda1p6r6+hSlWNU642//76jHqvdmKCckVQafy+NSrSNRSVatGvZWE7IAAIJmRF/9lJWVyePxKDExscfrGRkZKisr6/d9v/rVr3T77beHuDrAcGeYkCWymZAFx8a9a7skqdA7VzUpUyVJ48o3aLxvr5re3ijJnpCl7WMz1UBtmj1ThXXZmb1IqQefUNWfX5AIWQAAY1RXyNLmHinPlmOkS5meJr+ccimgsq0Vyjw+2+6ScBTFb+3RZPnVpJhe/71cHpd2fW+ldvzfXyRZRzyO5XTJe8PXQ1hp8NW7U5TUWaumfUznDQAInhEdsgzV97//fd1yyy3dPzc0NCg3N9fGijCaRY4zi+vFtBKy4NhE1ZkpGCpX3KbTHjDTKa4+62ca/8ZP5Npj34Lvrt3m3J2T7Vn0vot/yXLpoSeUse5ZSQTpAICxqbOWkAXh5fK4VOrMVFagRLVbSwlZRoDKd3dosqSiqGma0Ucn+sn/+TnpPz8X/sLCoDEyVercpbaDjM8BoEtFhfnfdBr8hszWhe+PVWZmpjo6OlRXV9fj9fLycmVmZvb7vsjISMXHx/f4AkIlOtd0ssR38KQMjk18s1lMNHpyVvdrnjkm2Egos2/B965ze2bb28ky/ZalCsihGa0bVbqu2NZaAACwi6/OhCwdHkIWhE+t1wQrjYUlNleCgWj9qKsT3d6HpOzQGm3G5x2lhCwA0OX226WJE6X//V+7Kxm5RnTIcsIJJygiIkKvvfZa92uFhYU6cOCATj31VBsrAw6Lm2gu4hIDXMTh2KR2mEFr/PTDTwcmn2KCjewm+zpZsg6dO/lUewdpqTPSVBBn/r9/512rbK0FAAC7+OpNyNIZSciC8GmMMw8Bte0ttbkSDIRzl3lIqmOivQ9J2aEj1ozP/RWMzwFAkkpLpZUrpdZWadrY+2chaGydLqypqUm7du3q/nnv3r3atGmTkpOTNX78eNXU1OjAgQMqKTE3FgsLzYVAZmamMjMzlZCQoGuuuUa33HKLkpOTFR8frxtuuEGnnnpqv4veA+GWMNlcxEWpTS1VLYpOjba5IoxEbXVtSrJqJUmpcw53suScadZmSbWqVLu7Rkl54V3itm5vrdKsyh612Knm1GXSy+8p6tVnJX3T7nIAAAg7q7FZkuSLjLG5Eowl7cnZUrkUKKaTZSSILzMPSUXMHnudLL5EMz5XNSELAEjSnXdK7e3SqadKixfbXc3IZWsny/r16zV//nzNnz9fknTLLbdo/vz5+vGPfyxJeuaZZzR//nxdeOGFkqTLL79c8+fP1wMPPNB9jLvuukvLli3TJZdcojPOOEOZmZl68sknw//LAP2Iy45ThyIkSXW7uZDD0FR+bJ4KbJVXCRMSu1+PzYxVqXOcJOngG+HvZil+3Zyz1DlOsZn2PzE77pvLJUlzKl9Tc0WzzdUAABB+VqPpZPFH2f/vMsaOQIZ5CMhZTsgyEmQ3mgdYk04eg48sJ5uQxVXLdN4AUF0t3X+/+f4//kNy9F6mCwNka8iyePFiWZbV6+uRRx6RJH3lK1/pc/tPf/rT7mN4vV7de++9qqmpUXNzs5588skjrscChJvD6VCt01zINezhQg5DU7fNhCwV7mw5PrU4ZVm8GRzVfRD+dVm6ztlVg92mfG6WitwT5VW7Cu5+1e5yAAAIvyYTsgSiCVkQPs5cM52tt4bpwoa7+gP1Sg+US5Jyzhoe1/Dh5ExPlSR5GnkAEgB++1upuVmaN09autTuaka2Eb0mCzBSNESYkKWliAs5DE3TDvNUYH1UVq9tjdmmzd+3NfydLF3nbMwaHgM0h9OhPTNNN0v7k6zLAgAYexwtJmRRDCELwidqsglZ4hrpZBnuurrfy52Zis+Jt7ma8IvINGNzbwtjcwBjW0ODCVkk6Qc/oIvlWBGyAGHQ7DUXcm0HuZDD0HTsMwPW5oTsXtsCU03AEbk//CFL1zkD04bPfM6xV5iQJX/nKgV8AZurAQAgvFxdIUssIQvCJ3aqeRAouZ2QZbir/eDQdL9xw+f6PZy848zYPLaNsTmAse3++6W6Oik/X/r85+2uZuQjZAHCoC3aXMh1lnMhh6GxSszUCx0pvTtZYuabAVJKdfinC0uuMueMmTc8Olkkac71i9SgOGUEyrT90Q/tLgcAgLBytZmQxRFPyILwSZljHgRKDVTI1+azuRocSWeBuX5vGCad6OEWM96MzeM7mcobwNjV2moWvJek739fcrnsrWc0IGQBwqAjwcz7alUSsmBo3BXmqUArq3cnS/ppZoCU27YzrJ0bAV9AuW07TQ2nD58n4TyxHm0Zd74kqWLlszZXAwBAeLnbmyVJrrgYmyvBWJIyPU0+ueRSQFVbK+wuB0fg2XeoEz1vbIYs8ZPN2DzJqpEVsGyuBgDs8dBDUkWFNHGi9MUv2l3N6EDIAoRBINE8LeOo5mkZDE1UnQlZ3BN6hyzjFk5UhyIUpTaVfFAUtppK1xUrWq3qUITGLZwYtvMOhH/JMklS5npCFgDA2OLpMJ0srkQ6WRA+Lo9Llc4MSVLt1lKbq8GRJFWZkCV6/vB5SCqckqaYsblbfjUU1dtcDQCEX0eH9N//bb7/znekiAh76xktCFmAcEg5dCFXTycLhia+2QxWoyf3ni7M7XWryJMnSSp/O3zrsnSdq8iTJ7fXHbbzDsT0W5YqIIemt24Ka/AEAIDdIjtNyBJByIIwq/Wah4EaC1mXZbiyApZyW801fOpnxmYnS2R8pJpkOv3qdjM+BzD2PPqoVFwsZWVJV19tdzWjByELEAaudBOyeJq4iMPQpHaYwWr89N6dLJJUlWwGSU0fhm9dlsb1hT3OPZykzkhTQdypkqRdd6+yuRoAAMLH6zMhiyeZkAXh1RhnHgZq20PIMlyVbShRrJrlk0u5iybbXY5t6lxmfN60n/E5gLHFsqS77zbff/vbktdrZzWjCyELEAaeLHMRF93KRRwGr62uTUlWrSQp7bi+Q5bW3EPt/jvC18nSda7WnOEXskhSzWeWS5KiXiNkAYDhYudTBVrz3afsLmNUi/KbkCUyhZAF4dWebK5TAweZLmy4KnvTPCRVFDFZEdFjd36YRo8Zn7ccYDpvAGPLm29KH38sRUdLX/ua3dWMLoQsQBhEjzeL68W2E7Jg8Co/NgPVVnkVn5vQ5z6uGSboiDkYvpAl+tC5XDOH53zOOf/vs5Kk4ypf0Z4XwtfhAwDoW8AXUNS/XahT/vvzKnx8k93ljFrRAROyeFMJWRBegewcSVLEvjA+9INBady4S5JUmTQ8H5IKl5YoMz5vL2V8DmBs+e1vzf9edZWUlGRvLaMNIQsQBjHjzZMyiT6elMHg1W4xUy5UuLPlcDr63Cf+RBN0ZNSHL0zIqDPnil8wPAdpUz47U+vSlsijTtV8+UZZAcvukgBgTNv+2Abl+A9Ikipf2WRvMaOUFbAUo2ZJUlRqjM3VYKxJ+twZkqQZB16Sv8NvczXoS6DooCSpLTXX5krs1R5rxuf+ckIWAGPHvn3S00+b72+4wdZSRiVCFiAMEiabi7gENaizpdPmajDSNO8ynSz1Ub0Xve+SvdgEHeN8+9VW1xbymtob2pXj22fOfebw7GSRpPS//lbt8mhB9cta890n7S4HAMa0ipXPdn/v28qT7qHQWtMqp8xDBdHpdLIgvGZ97TOqdSQp2arRlofet7sc9MFZYcYVgYz+xxVjQWeCGZ9bVYQsAMaOe++VAgHpnHOkmTPtrmb0IWQBwiBxUpICMh0IdXtqbK4GI03HPtPJ0pzQ93oskpQ6M131SpBTlore2BXymore2CWnLNUrXqkz00N+vqGacPYUvX/6dyVJ4++6Wc0VzTZXBABjV8a6w2tkRR4gZAmF5vKm7u+jU6NtrARjkdvr1tbxSyRJNX969ih7ww7eGjOucOX2P64YC6wkE7I4a5hpAsDY0NwsPfSQ+f6mm+ytZbQiZAHCwOVxqd6RKEmq38PTMhgc66AZDHWk9j8YcjgdKo4x3SzV74f+xlXVe+YcxTH5/U5hNlyc9OT3VOSeqHH+Iq276Jd2lwMAY1Lp+oOa0bqh++fUKtbKCoXWShOyNClGTjdDPYSf47PLJUm5mwhZhqO4RtPJ4p00tjtZHKkmZIloYGwOYGz485+lujopL09autTuakYnrryBMKlzm8X1mvfztAwGx11pBkNW5pEHQ3VpJmRp+yj0N666ztF1zuEsOjVaJf9+tyTpM+//j/a8wI09AAi3nXeZLpZS5zhJUm77TgV8ATtLGpXaqkzI0uJkqjDYY9atF6hTbuV1bNP+13fbXQ4+JbndPLwVlz+2O1ncmWZsHtlMyAJg9LOswwve33CD5CQNCAk+ViBMmiLN0zKtxVzIYXCi6sxgyD3hyIOhzslmbRTXntB3snSdo3PS8A9ZJOmkX3xW69KWyqNO1V55g6yAZXdJADCmeF81T7UXnvlNdShCXrWrZM0Bm6safdqrTcjS6mTRe9gjYUKiChJPlyTt+x3dLMOJr82ntEC5JCllztgOWSKzzdg8ppWxOYDR79VXpW3bpNhY6Stfsbua0YuQBQiT1mhzIddZxoUcBieh2YQs0ZOP3MnimW0Cj8Sy0HdqJBw6h2fO8F30/pMcTofS//ZbtSlSJ9S8ojXffdLukgBgzGipatGcitckSeOuu0hFnimSpPK3WZcl2DpqzdpjbW46WWCf+kVmyrC4N1cdZU+EU9XWCjllySeXUqan2V2OraJzzdg8rpOxOYDRr6uL5eqrpYQEe2sZzQhZgDDpiDUXcv4KLuQwOCkdZrqw+OlHfuIs5TMm8MhuDv1Nq+wmc47kU0ZGJ4skTTgrT2vO+K75/q5vq7mi2eaKAGBs2HzXq4pSm4rcEzXlc7NUmWL+vWr6kOkbg62z1nSytEcQssA+E69bJkmaU/um6g/U21wNutQUmAe3Kp2ZY37NpriJZmye5GcqbwCj2+7d0nPPme+vv97eWka7sf0vKxBGviQz76uqCVkwcK01rUqyaiVJaccdOWTJOXOqJCnFqlbNztD9OavdXaNUq6rHOUeKk5/6norcE5XtL9a6z/3C7nIAYExof8JMGbRnxjI5nA615R4K6HfQyRJsvnoTsnR4CFlgn4nnTtUeT74i5NOWu16yuxwc0lhoQpZa79he9F6SEqeYsXmU2tRS1WJzNQAQOn/8o1mT5fzzpWkj5xnZEYmQBQiXZPO0jKuOp2UwcFUFZZKkVnkVn3vkvs6Y9BiVuHIkSQffCN2Nq65jlzrHKTZzZN3EiUqOUsl37pEkfWbNHdrzAk9RA0AoBXwB5e80UwbFXmGmEHLNMCO82IP8f3CwBQ6FLL7IkfXvM0afA3PN3/fA06zLMly07zPd8Y3xY3s9FkmKzYxVhyIkSXW7eQgSwOjk90uPPGK+v/ZaW0sZEwhZgDBxppmQxdPIRRwGrnaLeeKswp0th9Nx1P3L4s2Nq/p1oQtZ6tYeClkSRsZ6LJ920s+Xa236hfKoU7VX3iArYNldEgCMWtsf26CMQJkaFavZ1y2SJCWcZP79yKinkyXYAg2HQhYvIQvslXSVCVlm7ntevjafzdVAkgLFZlzRnkzI4nA6VOs04/PGfYzPAYxOL78slZRIKSnS8uV2VzP6EbIAYRKRaS7iopq5iMPANe80g6G66IENhpqyTMji2xK6p4O7jt11rpHG4XQo46/3qE2ROqHmFa359yfsLgkARq2KleYp9oJx5ysyPlKSlLXI/PuR7T+g1ppW22oblZrNemOBqBibC8FYN+trn1GtI0nJVo22PPS+3eVAkrPCdLIEMpguTJIaIsz4vPkA43MAo9Mf/2j+98orpchIe2sZCwhZgDDxjjMXcTHtXMRh4Dr2m8FQS/zABkPWNPN0cOSB0D0dHLnfHDswdWSGLJI04aw8rVn0PfP9PTerqazJ5ooAYHTKWGdCFv+Sw4/Ppc5IU50jUU5ZKnpjl12ljU5N5t+zQDSdLLCX2+vW1vFLJEm1f15lczWQJG+NeXjLlUsniyQ1e834vK2Y6bwBjD5VVdLTT5vvr77a3lrGCkIWIExiJpjF9eI7CVkwcNZBMxjqSB3YYCh6ngk+UqtC18mSUm2OHTN/ZE4X1uXkJ7+rA+5JyvYXa/3Fv7S7HAAYdUrXFWtG60YF5ND0W5Z2v+5wOlQcbf69ql7DlGHB5Gw59NBALCEL7Of4rAlXczexLstwENdoxhXeSXSySFJbjBmfd5YzPgf+P3v/HebWWeaP/28d9a6RplePZzzjnuK4pzgFQorJQkgIBBayAT50SFhY2F2ywAaW3y4hCaGEwLLs7hdYIJCEdFIdOy6J4zj2uNsztqc3jXrX0e+PW5rxeJpGc6Sjcr+uy5fHo6Ojxx7r6Jznfe7nZsXnN78BolFgzRrgggvkHk1pUMk9AMZKhaWZ7pSxJ0YhxkQIKs442dxUw3QxlKhO72Ko8jIKPhrCJ7Ly/0yMiWgInaDXurRwK1kAQG/XY+DrD6Lx3vdi0+770PnMx7D4+qVyD4sxxorGifufQg2ADvNGrF5WMekxV1U70PkGwu+kd1NA/5s9OP6pH0ARDk36vlhZjU1P/SM0Jo1Uw16wgX19OHr3I1j2wP9D1YW5ncxUBpMhi5lDFia/FV95D6IPqdASOYLtbXcioVKPP5ZYuQpX/OFzMo6u9NjDVCFvbudKFgCIWBxAH5AY5pCFMVZcEgngP/+Tvv67v5N3LKWEQxbGcqSslUIWJUS4ut2wNZfJPCJWCPQuuhhSNaV3MVS3qQkhaKFDGCefPoLWm1ZIOp7+N3tQhxAiUKNu8yJJ9y2Hdf+6FW/+/HqsHX4GZ7/1Kyy+/t/lHhJjjBUN/Yt097pz441THos1twGdgKpz7kqWhJjAwLv/Fle4Xpn64BFg17+sxMb7PrDg8Url6Ocewpbd38ern42gauf3cvraqhCFLAKHLCwPWJtseMu+BWucL+KyE7+a/OARoPOZq/kGlxyJhWKoEAcBAI5VHLIAgGij63OFk0MWxlhx2bcPOHiQ+rB86ENyj6Z0cMjCWI5oLVr4YIQJfrg7RzlkYWmx+qmSxdCS3sWQSqfC2+VXYu3Ic+h5+CnJQ5aBbcdQB6Bb04IWXXF8hASvvhH4v2egP3tU7qEwxljR8A/5sWr4JQBA3ae3Tnlcs6oNeAmwDs5dybLrrj9gk+sVBKHDnsu/BiiVAIDyN57GSv8bCL99WNrBL5BqqBcAoO47k/PXVocpZFFaOWRh+aHqiV/g1e/8FojFxr/X+tqvUB8/g6FXD3PIkiPDHYOoQQIxKOFYWjH3E0qBg0IWlYt7sjDGikuq4f373w+U8dRjzhTHDBljBcKldMAU98N7ehRAq9zDYQXAEaFKFkt7+suNBK7eCvz+OdhffxLAP0g6Ht8+uuN4xN6OFkn3LB/TxW3A/wGVzuz1sWGMsVLT8cCLWI8wulWLpg38HRvbgQeAOv/slSzePi+af3w3AGDPld/AlpfvGX/s1eu0wHNvQN2ZX8dvrZfuija4+3L+2uqoHwCgshpz/tqMTaf+0kWo/+s/TvrejsUnUN91BqE0lwtkCzd2uB81AIaFatTwstUAAGUlhSwaH1eyMMaKRzAI/Pa39DUvFZZb/OnKWA55NdRcL9jNd8uwuQWdQZQlxgAAFRekX9bf8oUbAAArvLswekzi/2vH6GI42FDY/VjOVbOF+tjURzsRDURlHg1jjBWH8J+fAgB0Lt8KhaCY8nj9FrrZxJ5wzvpZ9dZN30GN2IczqsXY8OevTXpMt5o+i8qG515yLJf0AZqwswb6c/7auihVsqjLuJKF5a9YM713lWksF8ik4T1Goe+Yjpvep2jr6NrcEOSQhTFWPB5/HHC5gMZG4Kqr5B5NaeGQhbEcCujpbplwH5/IsbkNH6DJmQD0sDRY035e/eYmHNOthhIijtz3jKRjMvbSxbByWfGELFUX1cIPA9SIoff103IPhzHGCp4YE9F+gkIW04emLhUGAMZKI3qVDQCAvlenn2g9+ZfD2Lz3AQDA0D/9CDqbbtLj5ZspJK8LHEdCTEgxdEmYInSeVx7JfSWLLk4hi8bOIQvLX5rV9N61DnLIkivh03Rd4bVwP5YUfT1dm5vCfG3OGCseqaXC7rgDEHjWP6f4n5uxHAqb6EQuNsQncmxuriN0MTSsqpn2LuDZ9K+hSS3ls09JOqYqN1WyWNa2S7pfOQkqAd16Co2GtvOyFYwxtlBHf/MWqsQBeGDGqs9fMeN2gxY69rrfnDrRmhAT8H7s81Ajhj3VN2Htt26Ysk3DlhbEIcAKD4Y7BqX7CyyQNUbneRZ44Rvw5fS19cmQRVfOIQvLX44N9N6v8/F5V66IPRT6hu0csqQYG+na3Bbja3PGWHHo7QVeopaI+PjHZR1KSeKQhbEcilrpRA4jfCLH5uY/QRdDLsP8L4bK76CQZUXPc4j4IpKMJ+QKoS5GTXxrtxRPJQsAOMvp7xN4h++oZIyxhRr6zycBAIfqroXGpJlxO28dBfaxQ1MnWnd9+fe4KNnsvu6PD0z7fK1Fix7VIgBA/7b8OH7HQrHxpT4BYORgbpcMMyY4ZGH5r/7KJQAAR2IUzhN8XZQLwiBdV4hVvFxYinUxXZtb4eYlgxljReHRR4FEAti8GVi0SO7RlB4OWRjLoUQZncgJY3wxweYWOU0XQwHL/C+Gln9sLYaEKljgRcdPX5NkPN2vnISABNywonx5pST7zBeRJgpZhON8RyVjjC1U9V4KWeLX3Tj7hkvo2Ks7Ozkg8fZ50fyTrwAA9lz1j6i/dNGMuxiypaph8uP47eoam/znw7lbMiweiUOPEADAUMkhC8tfxkoj+pT1AIDeV/IjIC12ujEKfJUNXMmSYmsugwhaLcDV6ZR5NIwxtnB/+AP9fuut8o6jVHHIwlgOKSqouZ7azY3v2dwSfXQxFCmf/8WQoBJwrIWWVvH+9klJxjO6iy6Ce4xt816+LN+pV9Ld1OYBvtBnjLGF6NvTjaXB/RChwNK7r591W8OFFJA4RicHJBPN7luw4U9fnXUfgXo6fotH8uP47emafCNN4GTuQhb/kH/8a0OFMWevy1gmBiz03p1uuUAmPbOXjkW6Zq5kSVFqlHApygAA7k6+CZIxVti6u4GdOwGFArj5ZrlHU5o4ZGEsh1RVVMmi8/NJHJubapguhhI1md1xprmZlgxrPvSkJA2BQwfoIthVUVxLhQGAbR39nWo8+XEnNGOMFaqTD1AvsA7zRpQvq5h126rLaZK1IXwS8Uicnv/EoYlm9998aEqz+yna6fit786P47fvzORzvMjZ3C0XFhiipcJiUEJr0ebsdRnLhK+W3rvTLRfIpOcI03WFuZ0rWc7lVtH1uf8sX58zxgrbn/5Ev196KVBXJ+9YShWHLIzlkLaWTuIMIT6JY3MzjNHFkKoxszvOVnzpGoSgRWOsC6eePLzg8ShP0UVwdHHxNL1Pqb+KLvSrxX54+7wyj4YxxgqX/iWqnnRu2jrntnWbmhCGBjqE0bf7LDW7//g5ze7vuW7OfZgvpuN3xVh+3A0f7D6vWrk3d5UswWEKWfwwFV3FKSs+iTY6n9SezY/3bjGLhWIoF4cAAI5VHLKcy6el6/Mpx27GGCswvFSY/DhkYSyHDA10EmeJcMjC5mYJ0N2vhpbMLoZM1SYcLL8SANDzs4UvGWYdpItgzcriq2SxNtkwrKA+Mz0v88U+Y4xlwj/kx6rhlwEA9Z+ZO2RRapTo1rYCAAa3H082u3911mb356u+IlkNEzmFWCiW2cAlFOmffI6nHsldJUtohEKWgMD9WFj+m1gukM+7sm24YxACEohBCcfS2SsMS03QQNfn0QG+PmeMFa6zZ4Fdu3ipMLlxyMJYDlkWU08WmzgqyfJNrLiVR+juV0t75msnB66mSS77zqcWPJ46H1WyODYVXyULAPSZ6WJ/bA9f7DPGWCY6HngROoRxVtWMlq3L03rOiJ2Ovb5X92LxT+4GAOy5+p9mbXZ/ruo1dQhADzVi6NneldG4pRQfoom6EGi5LoM7d5UsESeFLEEVhyws/1VeSu/9htAJiDFR5tEUt7HDFPYOC9UQVDwFdK6Ima7PU8duxhgrRI8+Sr9fdhlQw623ZMOfsIzlkHUx3SmjRwiBkYDMo2H5LOgMwpZwAQAqLsi8rL/1SzcCAFZ4d2H0WOZl8M4To3Ak6OKj/solGe8nn3mqKTyKdHDIwhhjmYj8iaomu5bfmPZyVaFGOvaue/G7qBb7qdn9o3+f9msKKgHdOpqsHX49D47fo/RZeVq/DABg8+c+ZAlxyMIKQP2lixCBGnqE0LenW+7hFDXvMToOjel45u18MRtdn6eO3YwxVoh4qbD8wCELYzlkqjYhAjUAwHWKT+TYzIYP0B1nAehhabBmvJ+6jY04prsASog4ct8zGe+n9xWauOpT1sNYacx4P/ks3kKTdOoubsDKGGPzJcZEtJ+kqknTh+ZeKixFuYyOvQYEAaTZ7P48znLah/9t+Y/fgovO70ZqVgEAHNHcLRcWc/sBABF1cX5Os+Ki1CjRrUkuF/ia/O/dYhbuopDFa+F+LFPYKWRRuvjanDFWmM6cAfbs4aXC8gGHLIzlkEJQYEygEznvaT6RYzNzHaaLoWFVzYKb1/ZfQpNdymcy78vifpNClgFL8fVjSdFfSHdTlw3nwZ3QjDGWx+KROF5d9zXsrn3f+K991dejUhyEB2as+vwVae/Lunbic2V3zd+k1ez+fOFFdPwWTsh//NZ4qGo0tpRCFgu88A34cvLaMRe9TlTDlSysMAw76L3r2yf/e7eYib0U9obtHLKcT6iga3ONd+aK/+0f/0+8eu2/5WpIjC3Ittt+im23/FjuYbCUf/1XSj5efDFrL5FaKuyKK4Dq6qy9DEuDSu4BMFZqPGoHqsIDCHRzyMJmFjg9BADw6KoWvK+Kv9sK7LgXK3qfR8QXgcakmfc+Yofp4tdXU7whS/mm5NrggWNIiIkFh1uMMVas9v3b89jy5n9M+9jBpq3YPI/PmcbrViAAPRJQoP4P92c0HtWKNmAHYO6X/254vZ/O7zRtTfA8Y4YFXowc7IepOvtLbYqeZMii45CFFYZQQxvQD+CY/O/dYiYM0s1bYhUvF3Y+dXVyOW//9Nfm8Ugc6/77s9AigjMv34qmq1pyOTzG5mXvd5/HFb//HADA1XU7bM1lMo+Iidt3QHjhr4hd/96sTcCnlgq75ZYsvQBLG1eyMJZjfh011wv1ZN4fgxW/mNMDAAjpMl8qLGXZRy/BoFANC7w4+ONtGe1De4YufhNtxdn0HgAatrQgDgFm+DB0YEDu4TDGWN4K/oEqI/c6rsVrt/98/NeOO/8Ly1740bz2ZWsuw9nfvo7+J95Mu9n9lH0kq2GqPfLfDW8M00SdrtaBUTVNaKaqU7Mt4aWQJc4hCysQyuV0Xmnsk/+9W8z0TjoGKRu4kuV8+ga6Nk8du883cngIWkQAAEOvHc3ZuBibr7AnDMe3vzD+Z3eXU8bRsJSEyw0AiJttWdn/6dPAG28AggC8//1ZeQk2D1zJwliOhYwOwA1EB7iShc0s7qaJkpjOvOB9CSoBx1tvQNXx/4Tvd08CX3/XvPfhGKWLX8OFxVvJojFpcEbVjKbYKfS/egxVF/Ldfowxdr6EmEDrMeq9kvjCF3H5v1y/4H0u/dBFC3p+/VX02VQj9sHb54W5duGfnZmyROn8zthUDpexFnAdR+BkbkIW+OjcQTRwyMIKg3VtG/BroNrFlSzZZPLRcmG6Zj63PZ+hgSpZUsfu8zkP9SO1roB//3EAN+RmYIzN064P3Ict0RPjfw70ueQbDBuncLsAAAnLwm+enc4f/0i/81Jh+YErWRjLsYiFTuQSIxyysJklPF4AQEwvzUSJ5v03AgCaDz+FhJiY13PFmIiGEJ2wVV5WvJUsADBURhN1nr18RyVjjE3n+B/fQW28B34YsOpLV8k9HABUDTOsqAAA9LxyYo6tsychJlAm0vmdpdmBgJUmNCNn+3Py+go/hSwJI4csrDDUXEHnXbXxswg6gzKPpng5whT0mtu5kuV8lma6NrcnRiHGxCmPe49NhOT50PeLsen0vH4G6164FwAQgxIAEBp0yzkklqRw088hWyFLqh/LrbdmZfdsnjhkYSzHRBudyCmcHLKwWXgpZBEN0tyNu/KudyEELRpjXTj15OF5PbdvTzf0CCECNeo2NUkynnwVqKcQSTzKd1Qyxth0+h+hpcI6qq+BzqaTeTQT+sx0/B7bI98kmKfHAzViAABbiwPR8uSEZm9uKlmEoJ++MBpz8nqMLVT5sgq4FDYISKBn2ym5h1OUYqEYykXq9ehYxSHL+cpa6dpcCRGe7qmT0qHTEyG5uY+vD1h+6rnlLhgQxH7rFThiWgsACA9xyJIXPMmfg80m+a4HB2mpMAC46SbJd88ywCELY7nmoBM5lZtDFjYzhY9CloRJmpDFWGnEwQq647jnZ0/O67mDr9EFRbemFSpdca8yqWinOyoN3XynGmOMTadiD32GRN69VeaRTOapouN35KB8k2DuTjq3C0APvV0P1NGEpnokNyGLMkiVLAozV7KwwqAQFOgx0Ht3ZCdPYGfDcMcgBCQQgxKOpRVyDyfvaC1a+EDBdOoYfi6xe+L4nQ99vxg73957n8OG/scQgxLG//oxQnpqdh8ddsk7MAZEIlAEqUozG5Uszz5Lv198MVDDq0HmBQ5ZGMsxVTU119N6ufE9m5kyQCELzNKtKx+8mibE7DvnF7L49tEFxYi9ePuxpJgvoTuhK8b4Qp8xxs43uL8fK/xvAgDa7sqvdenjLfQZpe6SbxLMd4Ym6FxKuqFG00hXvAZ3bpYLU4UpZBEsHLKwwuGqonOv8AGewM6GsUMUEgwL1RBUPP0zHZeSrs+9p6eGLMLARMhSI/bCN+DL2bgYm0vYE0b5d6jZ/Y41X8KS961EVE+T+eIYV7LIzn3Oz8BikXz3zzxDv9+QX6fkJY0/ZRnLMU0NXXgbglzJwmamDCXvRrVKF7K0fpn6sqz07sLIkeH0n3iMAodgQ/GHLNWX09+xIdqJaCAq82gYYyy/HH+AruYOGdei6sL8umVOfyFN1JYNyxeSB7rp3M6joQk7QytVstj8ualk0SRDFqWNQxZWOGLNdO6lOsU3uGSD9ziFvGO6/Dpm5xOvhq7Pgz1Tr8+1Y5NDcjn7fjF2vl03/wCLoicxINTg4sf/BQAQM1LIkhhzyTgyBmA8ZIkbTIBK2hVBolHg+efpaw5Z8geHLIzlmL6eTuJMEQ5Z2MzUIapkUUp4N2rt+gYc1V8IAQkc/eEzaT/P2Ed3FiqXF3fTewCoXlMHPwxQIY6e7V1yD4cxxvKK5nmqhBxen19LhQGAYyNN1NYHjiMhJmQZQ7iXqpQDOjrXsy2nkMURzU0liyZKIYuaQxZWQLSr6fzSOsiVLNkQ7qKQ12vhfiwzCejpmJ06hp/L7J0ckjt3cRjI8kPPjtNY9+J3AQCnPv0DWOqpUkK02AAACg9XssjO5QIAxE3SLxW2cyfg8QDl5cAll0i+e5YhDlkYyzFjI53EWWMcsrCZacMUsqjKpKtkAYCBS2hiTPls+kuGVbnpotdySfFXsigEBbr19Pcc3sEXUYwxlhJyhbBy4AUAQM2n8i9kadjSgjgEWODF0IEBWcYQG6Rzu5CJzvXKV9Gd4xZ44e3zZv31dTEKWTR2DllY4bBvoPOuOj+fd2WD2EMhQdjOIctMwsljdmxo6vV5WYhC8mO61QCASAeHgSw/9Nw60ex+00MfmnjAShP6go9DFtmlKllMNsl3/fTT9Pt11wFKpeS7ZxnikIWxHLO10hISVnh4OSI2I12UJmM0DmlDlso7aWJsZe/ziPgic24fdAZRFzsDAKi9svgrWQDAWU4X+4H9fBHFGGMpBx98GUYE0KtsQNstF8g9nCm0Fi16VIsAAP3b5Dl+J0Zogi5mSVYtV5vgAX2OjxzMfjWLLu4HAGjKjFl/Lcak0nDVEgCAPeGE8wTfhCY1YYiOPWIVLxc2k6iVrs8xMvn/XzwSR6VIof1A+xYAgLqTw0Amvze/8yw29D+OGJQw/fdPoBAU448JdhsAQO1zyTM4NiGLlSypkOX66yXfNVsADlkYyzFrkw0i6ENw7CRfSLDp6WPZCVmW3r4Gg0I1zPDh4I+3zbl9z7ZTEJCAG1aUL6uQdCz5KrKIwiThJF9EMcZYSvAPVAF5aumNky7m88lQGR2/PW/Kc/xWjNF5nVjmGP/eqJomNt1Hsx+yGESqZNE6uJKFFQ5DuQG9ygYAQO8rfIOL1PROqmRRNnAly0wSdjpmC2OTr81HDg9BCRFxCNBcfRkAoGyY/48yeYVcIVT+60Sz+9abVkx6XGmnCX1NiCtZZDdeySJtyHL6NHD4MCAIwLXXSrprtkAcsjCWY0qNEi5FGQDA08UhC5uePjlRoquQNmQRVAKOt1JnNN/v5l4ybGQnTVR1G9vzdlJNauoVVMli6eeLKMYYA4CEmEDrsacAAPpbbpR5NDML1NHxWzwqz/Fb7abzOkVF+fj3XEaa2Ayc7Jv2OVJJiAkYE3TuoK/gkIUVlkELvXfdb/ANLlIz+Sjg1TVzJctMFOUUsqg9k6/NnYfo325EqETFFcsBAHUy9v1iDAB2f+AHaIqdmtTs/lyaCprQ14U5ZJFdKmQx2yTd7TPJ9rqbNgFlZZLumi0QhyyMycCtohM5/1kOWdj0TAmqZMnGRInmZloybPHhJ+e8SAgfoIkqV2Xx92NJKdtAd0LXePlCnzHGAOD4H99BbbwHfhiw6ktXyT2cmbXTZ5W+R56QReejpsmqqolKloCVQpbI6eyGLBFfBGrEAACGSg5ZWGHx1tG5V+ww3+AiNUeYjj3mdq5kmUnqmJ06hqd4j9G/nVNbO973ywoPhjsGcz5GxgBqdr/+JWp23/nZ+8ab3Z9LW2UDABgjrhyOjE0rS8uFpUKWG26QdLdMAhyyMCYDn5ZO5II9HLKwqSK+CLSgfinGamkrWQBg5ZevQQhaNMRO4+QTh2bdVnWKgoZYc+mELHVbaG3wKnEAnh6PzKNhjDH59T9ClY8d1e+CzqaTeTQzM6+hidpKpzwhuSFE53WamomQJVqevHu8P7vLhfkHfeNfGyu5JwsrMEvoPFN3hm9wkVIsFEO5OAQAcKzikGUm2lo6ZqeO4Smh03Tc9ppr86LvF2M9t94FPUJ427YFGx+8bdpt9NU0oW+McyWL7JKVLDEJK1mCQeDll+lrDlnyD4csjMkgaKBlJCL9I3NsyUqRr987/rWpRvqQxVhpxMGKqwEAvQ/PvmSYdZAuIjSrS6PpPUB9k4YVlQCAnpf5IooxVlr2fONxvGO9DAfNm8Z/rX7lAQBA5Nqt8g5uDtWX00RtfbQT0UA0569vjtAEnaFhImRBHU1sqkeyW8kSGKKQJQgdVDpVVl+LMakZL6bzTMcon3dJabhjEAISiEEJx9LS6K2YCWMTXZtbIpNDFrGbjtshO4Xlqb5fbpn6frHStvfe57Ch/3FEoYL51z+ecSlvYy2FLNaEi5e2k1sWerK88goFLfX1wMqVku2WSYRDFsZkEDHTxbc4xJUsbKrAIIUs2ZwoCV5DE2WOnTOHLEFnEC2+/QCAyi0rZtyuGPWZaaLOtfekzCNhjLHcsj3wL7jAswOrfLvGf9kTTgSgx9K/z99+LABQvaYOfhigRgw927ty/vq2OJ3XmZsnerJoGmlyzuDObiVLaNQPAAgouIqFFZ6Kja0AgLrwKZ4UlJDr6AAA6ikiqHjqZybmRXRtbhNHJ/3/EwYoZBGrkr21Un2/jnAYyHIv/pOHAQA7L/zclGb35zI32AAAasQQdAZzMTQ2kywsF3buUmGK0miZW1D4k5YxGcRsyTscRzlkYVMFh+luVJ9C+iqWlCV30UTZCt9ujBwZnnabjh+9DAOC6FU2oGXr8qyNJR/57E0AgMjJszKPhDHGcifoDKIlRMtI7vh//4M933h8/NfA0/tQsbJK5hHOTlAJ6NHRko/Dr+d2EizoDMKIAADAuniiksXQSpNzNn92K1nCo8lKFoH7sbDCU3EBvU8MCPJSrRIKdNO1pkdTPseWpS11zNYjhMBIYPz72jEKx4X65FJrqb5f3VzJwnIr5Aph5cALAICqr31s1m1N1SbEk1O93h5eMkxW45UsNkl2l0gATz9NX19/vSS7ZBLjkIUxOdjpRE7p5pCFTRUaTlayKLM3UVKzth5H9BdBQAJHf/jMtNsE/0BVLieXbZ2xHLlYRWspZFF0n5F5JIwxljun/vwOVIhjWFGJzT/9CNZ/76bxX4uvXyr38NIyWkHLuQTezu0kmOsUndNFoZrUiNa2nCbnyqNZbnzvTIYsKg5ZWOExlBvgBt3pO9qR3aqvUhLqoaWp/TrHHFuWNlO1CRGoAUwcywHA7KXjtq6ZKhJTfb8qxriSheXWwQdfhhEB9Cnr0f7BC2fdViEo4FXQeYivx5X9wbGZSVzJcvQocPo0oNEAV18tyS6ZxDhkYUwGQgWd6Gq8HLKwqSKjyZBFlb1KFgAYvISqWZTPTl0yLCEmsOTYUwAAwy35vTxMNgiLGgEA+iGuZGGMlY7Rv74FADhdvqZgw/VIE91pLJzM7SSYp4vO6VwK+6R/u/JVyck5+ODt8077XCmkQpYwhyysQI1oKJB0H8luIFlKYoN0XAoZOWSZjUJQYEygfyPv6Ynrc3uI/i+a2+n/ZqrvV0PkFGKhWI5HyUpZ8I90XX6y/ca0zs+8Shs9b4ArWWSVqmSRqPF9qoplyxbAyKvD5iUOWRiTgbqWSrb1fm58z6aKOGkSJqzObshSeSf1ZVnZ+zzCnvCkx47+7m3UiL3wwYhVX7wyq+PIR4ZlVMli83AlC2OsdAj7KWTxL71E5pFkTrWCJsHMA7kNWcaX5VFPnsw0VZvgAX2ejxzM3h36MReFLBENhyysMLmNFEgGTnEli1QSI8kKOwsvFzYXj5r+jVLH8ngkjgpxEABQtpz+b8rd94uVpoSYQMtRCln0t25N6zkBFVVOhAY5ZJGVxI3vX6AV43DddZLsjmUBhyyMyUBfRxfgpjBXsrCp4mPJkEWb3ZBl6e1rMChUwwwfOn6ybdJjg7+k6paOmndBZ9NldRz5qOxCClmqQhyyMMZKR1X3XgCA/tI1Mo8kc2XraTmXGk9ulwsL9dI5nU83dTJz/A79o9mbPI57qfF9VMshCytMARu9T6JnuJJFKgonHZfEMq5kmUtqSbXUsXzk8BCUEBGHgPLllQDk7fvFStfxP76Dung3/DBg1ZeuSus5Qa0NABAZcmVvYGx2iYSky4VFIsCOHfQ1LxWWvzhkYUwGhgY6ibNEOWRhU8XddDdqTJfdkEVQCTi2hJYC8/1u8pJhlW/Qn6PXpne3TLGpXkfLhVnhgfuMS97BMMZYDgSdQSwOHQYANL6vcEOW+quokqVa7M/q8lzni/ZTdXJwmmV53IbkHfonszd5LHqS5w5aXj+CFaZYBYUsin4OWaSi8iSvNcs5ZJlLakm11LHceYhC8WGhCiqdany7VN8vf477frHS1f9I8ubH6mvSvvkxrKdJ/dgoV7LIJhAA4nEA0iwX9sYbtMvycmDFigXvjmUJhyyMycDSTCdxZQknxJgo82hYvkl4aFIops/+3ajamylEWXzkKSTEBABgYF8flgdoyZilX7kh62PIR8ZKI0YV9D4dfJP7sjDGit+5Te+r19TJPZyMWZtsGFbQXcc9L+fuTmNxOLksj3nqZGbASpPHkdNZnDz2UsgSz8G5A2PZoKilMFI9wsuFSUXnpcBAVckhy1wiFvo3Si2x5j1Gx+sxbc3k7VJ9v05wJQvLjYo9FLJE3p3+zY9RA4UsotOVjSGxdCSXCksolRD1C78B5pVX6PctWwCBZ/LzFv9oGJNBWSudxCkh8l3ybCovhSyiIbuVLACw6q5rEIQODbHTOPnEIQDA8Qeoo1qHcR0qVlZlfQz5akhHS4a53uElwxhjxW+i6f0lBdv0PqXPTJNgY3tyNwmWWpYnbps6mRktT07S9Wdx8thHIYto5JCFFSb1IgojjW6uZJGKIUjHJW0d92SZi5g8dqeO5aFO+n/oNddO2m6871c/V7Kw7Bvc348V/jcBAG13pX/zY9xkoy/cXMkim+RSYbBYAMXCz6tTIctV6a0Yx2TCIQtjMtBatPCCLoLdnbxkGJtM4aOQJWHKfshiKDfgYCUt6tn7MN0lo/0r/T6yoTSXCktx2yhkCR7lkIUxVvwmmt4X7lJhKZ4qmgSLHMzdJJjSnVqWZ5rJzDqapFOPZG/yWBGgkAUcsrACZWyhMNIW4JBFKuYIHZf09VzJMqfksVuVPJaLvRSKh+yTQ5ZU369qD1eysOw7fj/d/HjIuBZVF9bMsfWEhIUqWRReDllkk6pksdoWvKtQCNi5k76+8soF745lEYcsjMnEraSTXd8ZDlnYZMpAcg15c/ZDFgAIXUNhimPnkwg6g1g1+CIAoOZTpR2yhKuoL0viNIcsjLHiVwxN71PirTQJpj6du0kwrZfO55TTLMujaUreoe/K3uSxMhWymDhkYYXJtpzeJ+Wx/vElbNnCWON0XDI1ccgyF1UV/Rtpk0usCQN0vBarJk9sp/p+1Yh9Oe37xUqT5q9PAQCG18/zutxKIYvK65J4RCxtqSoiy8Kb3u/aBYTDQHU10N6+4N2xLOKQhTGZeDV0Ihfs4ZCFTaYK0gm7wpqbkGXJl6n0eIVvN/b+/f/BgCB6lQ1o+8DqnLx+vko0USWLZpB7sjDGiluxNL1P0V9Ak2D2odxVsugDNDGnqZk6mWlI3qFvDWRvuTBl2A8AUJi58T0rTBWr6X1iRACeHo/Moyl8YU8YZlD4al3MIctcUsfu8SXWxuh4LdRPrmSZ1PfrlRM5HCErNSFXCCsHXgAw/5sflQ4bAEAd4EoW2SSXC0vYbAveVWqpsCuvlGTlMZZFHLIwJpOAnk7kwn0csrDJVGG6IFJacnM3as3aehzRXwQBCSz99dcBACeXbS34NfkXStdGIYvFyZUsjLHilmp6PyRUFXTT+5TyzXSbX33weM7uiDeHZ16WZ/wO/Wj2KlnUodyeOzAmNUO5AW7QHb+jHVnsX1Qixk4m+0RBgLXJJu9gCkDq2G1KLrFm9tLxWre4dsq2cvT9YqXn4IMvw4gA+pT1aLvlgnk9V+WgY6k2xCGLbFLLhUlQycL9WAoHhyyMySRkpnVfY4MjMo+E5RttmCpZVGW5qWQBgMG1dHdMRWIIAGC45cacvXa+sq6mkKUiyCELY6y4pZren3GsKYqAvf7yxYhDgBk+DB0YyMlrppblMTZODVnKV9Ed+mb4sra8jCZCIYvKxiELK1wjGprQdh/hviwL5emiY9KYwg5BxdM+czEtomtza4z+3ewh+j9obpvaB8NTTUF+Lvt+sdIT/AP1ST3ZfuO8z800lTYAgD7iknhULG3jje8XFrL4/cCePfQ192PJf/xpy5hMYpbkRfgIV7KwyXRRmoDROHIXslTeOVGC7IMRq77In+AVa6gnS5U4gJArJPNoGGMse4S3qR9LMTS9BwCtRYseVTMAoP/V7E+CxUIx2BIuAIC1ZWrje1O1CR7QZ/rIwezcoa+NUsiiLuOQhRUut5FClsBJDlkWKtBN15geNS8Vlo7UkmpWeBByhVAhDgIA7CunVrLEW6iSRd3FlSwsOxJiAq3HqB+L/tb590nVVdHEviHKlSyykajx/euvA9Eo0NAALF4swbhYVnHIwphMEnY6kRPGOGRhk+ljuQ9Zln74YgwIdKdWR827oLPpcvba+crRXo4A9ACAwbd6ZB4NY4xlT1UPVbIUQ9P7lKEymgTz7M3+JJira2z8a1tz2bTbZPsOfV2MQhaNnUMWVrgCNjoXjZ6dPozc9x8v4aB5E4794Z0Fv9app47gHetlOPDTHfN6XiwUw56am/Dqlm8teAzZFOyla0yflkOWdFibbBBB1QJnnj8KJUTEIaB8eeWUbVN9v8qGuZKFZcfxP76D2ngP/DBg1Zfmv0aUvppCFnPcJfHIWNpSje+tC6tkOXepMO7Hkv84ZGFMJopyOuFVezhkYZMZRApZdBW5C1kElYCj6z8OAFB8/OM5e918phAU6NfQkmGj+3jJMMZYcZrU9P79l8g8GukE6mgSTDya/Ukw9yla+tWlsEGlU027jctYDwDwdZyW/PUTYgL2GN11bWywS75/xnIlVkFhpKJ/+jAy/KOfY5VvF/r//X8X/Frd//ILXODZgdg/f2tezzv+h/1YP/AXbNj2fcQj8QWPI1uifXRcCho4ZEmHUqOES0Eh+fArB+l3oQpKjXLKtvZ1rQCA6mBX7gbISsrwSwcAAMfKNmR086O5wUa/wwsxJko5NJauVOP7BS4Xdm7Te5b/OGRhTCaqKjrh1fk5ZGGTGRN0N6q+Ird3o1726r+i/41urP/eTTl93Xw2ZqaQxX+YQxbGWHGa1PT+4qnLohQqxVJaM9/Qnf1KFv9ZOpdzK2eezPTVUugTOyz9eAb398MMH2JQov5yXkuCFS5FLVWyqEemr2Sxj9D7R997YsGvZeihfa0a2wb32fSX1PEeSzZERxh9u88ueBzZIg7TcSlimbqEIZueW0XH8Ng+Clmcuuk/E8tX0/ftCSfCnnBuBsdKSnzUBQAImTJ7/5rraWJfQCJrveDYHFLLhdlsGe/C4wH20oq+HLIUCA5ZGJOJrp4+MI0hbnzPJkR8EWgRAQAYq3NXyQLQHVw1a+tz+pr5LlBBfVninRyyMMaK0+jzdPVWLE3vU0wXU6hRMZb9SpZgD01merUzT4Yk2ij00Z6VPmQZeI322aNuhsakkXz/jOWKehFNXhvdUytZxJiIhhD9X69wLvx9XZk8NqgRw+EH/pr288JdE2Mb3J7HPTmcdFyKW7mSJV2+5DHc2EUhi880tek9QMtChqAFAAwfyE6fLVbaEmMuAEDMmFkVhM6mQxh0PuDtdkk0KjYvqeXCFlDJsn07EI9TL5bGRonGxbKKQxbGZGJooBNec4QrWdgEX//EnSammtyGLGwqsZ4qWZR9+XunImOMLYSwn/qxFEvT+5SaLRRqNEQ7EQ1Es/pakX46l5ttWR7DhRT6OEaln5RN9Z0ZtrVJvm/Gcsm0hEIWW2BqyDLwVi8MCAIAGiKnEAvFMn6diC+C+ujEUk/xJ55M+7li78Skuv/t/A1ZVK7kNaaDQ5Z0pY7h9U4KWUL26StZFIICwyoKYMYOc8jCssBDE/SiKfMJeo/CBgAI9KdfqccklFoubAGN78/tx8IKA4csjMnEvIhO4srEUSTEhMyjYfkiMEghSxC6Gdd1Z7mjbqWQxTTClSyMseI03vT+suLpxwIAVRfVwg8DVIijZ3t2182PD1JVctg882Rm1eXJ0Cd0QvL10VN9ZwL1HLKwwmZdShPX5bH+KddHA9smqlfUiC3ofd3zWidUmOinsqzrmbT7qwiD5wRAx/O38bnGSyGLUMkhS7oiyWN4jdgLABCrZ15Cc0xPj/lOTN8/iLGFUHqTwcgClpryqSigCQ5wyCILCRrfcz+WwsMhC2MysS5O9mRBGIGRgMyjYfkiFbL4FFzFkg9MKyhksfs4ZGGMFZ/ASGCi6f37iquSRVAJ6NZT6DC8I8sToaNzL8tTt6kJEaihRwh9e7olfflU35lUHxrGClXFagpZjAjA0+OZ9Jh33+SqkeHXM68iST33mG41xhRlcCRGceiXu9J6rt45Malu6s3fShZ9gMJfTQ33ZElXzDb5GC7UTb9cGAD4LfRY5DRXsjDpqfwuAIDClvkEfUBjAwCEB10LHxCbvwU2vnc6gbffpq85ZCkcHLIwJhNTtQkRqAEAYye4Lwsj4VFqeh9QcsiSDxwX0eKnNbFuye88ZowxuRVr0/sUZzmFLIH92Z0IVSaX5UnYZw5ZlBolujWtAIDB16QNfVJ9Z8xruJKFFTZDuQGu5BI3IwfOqxA4Ovl943878/dRcD89d6RqBQ43XgcAcP53ekuGmXwTk+pV7vytZDGF6bikr+dKlrSddwzXLZ75czHioMcSvVzJwqSnCVIVhKrclvE+Qlqa3I+OcCVLzsXjgJduns10ubDXXgMSCWDpUqBm5ryX5RkOWRiTiUJQwCnQnUXe09yXhZHIKH0Yh1QmmUfCAKB6TR1iUEKDKIYODMg9HMYYk5TzBVoqrNia3qdEmih0EE5mdyJUPb4sz+x3jA87qNLEt0+60CcaiKIh2gkAqL6CK1lY4RtV02yS59jkCgFDsmpkSKgCAAgnMn8fCafoudFFbVC8dysAoGF/eiGLIzwxqV4fP4ugM5jxOLLJGqPjkrGRQ5Z0nX8MN7fPHLIkaugx1RCHLEx6ujAFI+ryzCtZInp6bmzEJcWQ2Hx4J/rsZrpc2Guv0e9XXCHBeFjOcMjCmIy8ajrpDXRzyMJIxEkfyGE1V7LkA5VOhQFlHQBgeC8vGcYYKy7jTe+XFVc/lhT1SgodLP3ZrWTR++k8Tl09+2RmqCFZaXJMutCnexv1lvDBWJTVSKz0uI30/zhwcvLkdaUrucRX640AAHN/5u8ja/K56hVtWPGV9yAGJVoiR3Dm5VOzPi8WiqFcHAKA8RUJul8+kfE4siUeicOWGAMAWJo5ZEmXumbyv5V9xcy3j6sa6DGdi5cLY9IzRFwAAG1l5iFLzGgDACRcXMmSc8mlwqDV0q8MbN9Ov19+uTRDYrnBIQtjMvLr6EQu3MchCyPxsWTIouWQJV+MGqkvi7eDQxbGWHEZb3p/aXH1Y0mxraNQo8ab3UoWU4iWfdXVzT6ZqVxOoY+xT7rQZ2Qn7atb31aU1Uis9ARsNHkdPTsxeR32hFEfOw0A0NxMlSfVnszfRzU+eq59YzusTTYctF0GADj90OzVLMMdgxCQQAxKHDdeBAAY3ZV/fVlcXWMQkAAA2BbbZR5N4dCfcwyPQ0D58sqZt22hMNDq40oWJj1TjIIRfY0t433EzcmAxs0hS86l/s1tNgwMAC++SCuIpcvrBfbto68vu0z64bHs4ZCFMRmFjHQiFx3gkIWRuItClpiOQ5Z84bNTX5bIybMyj4QxxqQTGAmgJXQIQPE1vU+pv4pClipxYEoTbSlZonQeZ2iYPWSxrk2Oxy3dpGyq38xYOfdjYcUhVkGT14r+icnr7ldPQQkRHpjR/km6rbdG7INvwDfv/bvPulEpDgIA6rYsoe9dTsGNedvsIcvYIRrTsFANV9VSAED4QP71ZXF30jHJDQs0Jo3Moykc5x7Dh4UqKDXKGbe1tFMY6IhwyMKkZ07QJL2hJvNKFiQbrgtelwQjYvOSClmsVnzta8DXvw785S/pP33XLkAUgUWLgIaGrIyQZQmHLIzJKGKhE7nEMDe+ZyThpYvFmJ5DlnwRraVKFkU3V7IwxorHqT+/AyXEom16DwDWJhuGFXQncs/L2bnbPCEmYEs4Acy9LE/tlVTJUhc7I1kfh1S/mcgiDllYcVDU0fFIPTIxeT3yOv0/7zG0w9ZchmFFBQCg+6X5v697X6HnDAg1sNRbAACLPk8hy6qx1+A+O/Nd397jVF0zpqtBrIXez6rO/Ktk8Z9NhiwqXipsPqwtEz1ZnLrZPxfLV9Pj9oQTYU84q+NipSXkCkEH+j9lrs88ZFGU2QAAKj9XsuRcarkwmw2HD9OXBw6k//RUPxauYik8HLIwJiOxjE7kFE6uZGFJySZpooEb3+cLoZlCFv0QhyyMseKRanp/uvySol5mqs9ME6Fje7IzEerp8UCNGADA1jL7hKajvRwuhQ0CEujZNnvvh3Sl+s2k+s8wVujUTVQhYHRPLBcWOpCs2KqgMLHfRL9n8r5OPWfAPBFMLnrXEnRq2qFGDIfuf37G54a7KPjxWmqhXUXPtw3mXyVLsIeuLX0aDlnmo6x14t/La549ZLE1lyEE6rUwfID7sjDpeHsoFBGhgLnOkvF+lHYKaDQBDllyLlnJkrBacSY5hXBqHqd93I+lcHHIwpicHHQip3JzyMKIwkchS8LElSz5wrCMQpYyN4csjLHikWp6H1hanEuFpXiqaSI0eig7IUtqWR4/DNDb9bNuqxAU6DHQeEZ2SjMxm+o3U7aeK1lYcTAtocltW2CikkV5iv6fRxdTmOiupt8jB+f/Pop20HM8NZODybOrqZpFfGLmJcPEHhpT2F4LxyZ6fn3gGBJiYt7jyKZIPx2XAnoOWeZDY9LAC7rRLVw2c9N7gI7nwyraZuwwhyxMOt5uF/0OMwRV5lO26nIKWXQhlwSjYvOSDFnCWisCAfrWyZPpPTUcBvbsoa+5kqXwcMjCmIxUVXTiq/VxyMKIMkAhC8wcsuSLsguoJ0tlmHuyMMaKR3X3XgDF2/Q+Jd5C4YOmKzt3m3u7aMlXlzK9yUxXFU3Mhg8sPPTx9HhQJQ4AAOqu5JCFFQfrUpq4roj1jYcX1gF6v2hW0v/z1Pta3TX/95HmND1HbJ38nin7WwpZlp9+BrFQbNrnCkM0mS5W1aDhylYAgC3hgvNEfl3LxQbouBQ2l8+xJTufO3ksF6vnXkZzTE/b+E5wXxYmneAATdB7lbYF7UdbRc/XR7mSJeeSy4W5Bdv4t06dAhJp5PFvvklBS2Ul0MandgWHQxbGZKSpoZM4QzC/TsyZfFRBClkUVg5Z8kX1OgpZrPDAfcYl72AYY0wCgZEAFodpkehibXqfor+QQo0NZ38Pv8I4668BZS2O/H9vzWv//k5qoO1Nc1meWDNdMatOLTz0SfWZGRKqYG1cQHNcxvJIxWoKWQwIwtPjAQDU+Oj/eqpiS7eafi8bnv/7yD5CzzFcOHn2asUnN2FMUQZ7wolDv9w17XP1TppMVzbUQm/Xo0dJ54i9L+fZkmGjdG0Zs3Ily3yljuVCw9whi99C20S6OGRh0gkNUigSUC/sc11XRc83xjhkyYaRI8PoMK3Hq+/+3tQHk5UsY/GJn6HPBwwOzr3fc/uxKIp3Nd+ixSELYzLSN9DdReYIN75nRB2ikEVp45AlXxgrjRhR0Ht1YA8vGcYYK3yppveDQnXRNr1PWfzhDXDDAgEJGBGY9Ve12I/h7/487X0nxATUP/4hAGCkZnVaz9GuptDHOrjwSpZUb4lUfwrGioGh3ACXwgYAGDnQB1fXGCoSwwCAhqvp/3r55tRSXcfntVRXQkygIUjvm4pLJy8XptKpcKzmSgDA2It7p32+yUeVLLrFdNwctCaXL3szO8sRZkpwUciSsHPIMl9DSy9HBGrUvG/jnNtGHBQIJvp4uTAmnciQCwAQ1CwsZDHW2QAAFtG1sAGxaR36x99gpf8NLH3px1MfTFayDIUn/wxPnJh7v9yPpbCp5B4AY6XM1EQnvtYYV7Iwoon4AAAqKze+zydD+iaUB0bgeucMcOsFcg+HMcYWJNX0/kz5GlQVcdN7AKhYWQVffy+6jw/Put3Z/9uJzT/7CNqOPwUxJqa1DvquL/0fNrleRRA6LPrvb6c1HvsGmiSu9S98UjbVZ8Zdw03vWXEZVdfAFnHBc6wfwUEPbAD6hVrUVNP5ccOWFsQhwAIvhjoGUbm6Oq39DuzrQw0CiEKF+suapzweWrQU6AOEE9O/Px1hqlgwt9Hkuq+uDXC+gPjh/Kpk0Xjo2lJRziHLfF2+94cIjNyLJZXGObdN1NQCBwDVEFeyMOnERpP9PHS2Be3HVEcT/AYEEfFFoDFpFjo0dg7zNurfVS32w9vnhbn2nJtkk5UsvX7bpOecODF7n5V4HHj9dfqa+7EUJq5kYUxG1sV04muBFxFfRObRsHygi1Ili8bBlSz5xGOl5SBCx7kvC2Os8Cnfpru0i73pfYqp2oSGy5tn/bXmezfDByOqxX4c/e2+Offp6fFg8U+/AgDYc/U/of7SRWmNpeGqJQAAR2J0wX0cUn1mxBauZGHFxW2kSpHAyT649tD/8wHLRJiotWjRo1oEAOh7Jf2AY2AbbdujXgy1QT3lcdVyei+Z+qeGLLFQDOXiEADAsSpZAdhGY9Kdza9KFp2fji3qag5Z5kshKGBMI2ABAFUDhW36MQ5ZmHTiTpqgjxoWVslirrOMf+3p5iXDpOQ+68aqsdfG/9zzynklKsmQ5aybfoam5P2zc1WyvPMO4PUCFguwOr0CaZZnOGRhTEbWJhtE0B2krk6nzKNh+UAf45AlH4WrmwAAidO8XBhjrPBV9VAlS7E3vZ8PnU2Hjpp3AwCGfvXUnNvv+5vvoFrsx2l1KzY8+vdpv46h3IBeZQMAoPeVhU3Mlg3T81N9ZxgrFoEyCjGiZ/oQO0z/z701k8PEIRv92fNW+u8jb3Lb4bLpg0nbenov1binBjfDHYMQkEAMSjiWVgAAjBclly9z5lclizFES1Hr6rnxfTbpW+j/qcXPy4UxCSWXmoqZFhayqHQqeEGz+/4+DlmkdOj+56FGbPzPY7vP+wxI/gw7nTYAwNq19O25QpbUUmGbNwNKpQQDZTnHIQtjMlJqlHApygAA7lPcl4UBBpFCFl0Fhyx5pYlCFu0AhyyMscJ2btP7ppsvkXk0+SX6nq0AgKo3npx1uxOPdeDStx4AAIzc8xB0Nt28Xmcg1cfhjcwnZhNiAvWp3hKbuZKFFZdYOVUIKAb6oT2drNhqmxwmBurpz+I8lupKHKVtAw3TB5N1V9J7qUbshW/AN+mxsUNUrTAsVI8vJ1h1GW3fED6JeCSe9jiyzRKlShZDA1eyZJN1GYUsjghXsjDpKDwUiCQstgXvyydQUBPo55BFSuITk88TIx3nhf3JSpaTw/Tvv2EDffv4HPcEpJrecz+WwsUhC2Myc6voDiP/We7LwgBTgkIWQxWHLPlE20Yhi3mMQxbGWGErpab387X0KzdAhALLgvvQv7d32m0SYgL+Oz4PFeLYXfM3uOSf3zPv1/HV0sRs6g79TAzu74cZPsSgRP3lizPeD2P5SFFHxyb1SB/so/Q+MV54XpjYTn/W96T/PjIktxWWTh9MlrXYMaKga7Pzl3/xHqdqBad+4rhZu6ERIWihRQS9O/PjHDEhJlAm0nWleRGHLNnkWElhoD3hRNgTlnk0rFgofS76wrqwShYA8KtpH8F+14L3xUgsFMPy088AAN6ovAEAoO46L+xPhiyjcSvUamBNsnD85ElAFKffbyIxUcnC/VgKF4csjMnMp6WT31AvhyylLuKLQIMoAMBQyY3v84l1FfVkqQhyTxbGWGE7t+k9m6xiRSUOmdYDAE7cP/2SYTu/8Dtc6N6GAPSo/8P9mb3QEprg1Z3JvJKl/9VUb4lmbmbLio66iSavTa5eNIQo7Di/Yst8Mf25ch5LdVWO0baWtTMvsddnov06d08Ob8JdVK3gM9eMf0+pUaJb2woAGNqRH31ZfAO+8esJWwuHLNlkay5DCFoAwPABXjKMSUMdoAl6wW5b8L4CGtpHZJgrWaRy6Je7YE84MaYoQ/xv7wAwsXzruORyYS7Y0NAA1NcDKhUQDAJ9MxS+HTsGDA8DOh1wCReaFywOWRiTWdBAJ7+RAQ5ZSp2v3zv+tamGK1nySeVaqmSpEgcQcoVkHg1jjGWu1Jrez9foRloyTPfi1CXDPD0etD5Mze7fuCb9ZvfnM15ME7yO0cwnZcd7S9h4qTBWfExLqFqkxfs2DAgiChXqL2uetE31FfQ+qo92IhqIzrnPiC+C+lgXAKDmipnfN+5q2m/k4OTwRuyhmbGwfXIF4KiDtvfvy4++LK6TtAR1EDoYyg0yj6a4KQQFhlUUuqWWk2NsobRBCkRUjoVXsoR1tI/oCIcsUhn7X7oJ53DT9ai8YjkAoCFwDAkxQRtEIkCI5gvcsKKxkQKWRYvo4Zn6sqSqWNavB7TabI2eZRuHLIzJLGKmkEUc4pCl1AUGKWQJQgeVTiXzaNi57Esc8IMuVAfe7JZ5NIwxlrlU03vD5Xyb3HRq/x+FLKuGXkJgJDDpsX1/821UiQM4rW7Fxj+l3+z+fJWXpvo4nIAYm2HdiDmIxyhk8c/QW4KxQmZbTkGGEfQe7Na0TDk3rl5ThwD0UCOG3tdPz7nPntc6oYQIL0yoXF0943bxxfT+VHdNDkGFIapUEKsnhyyhxmRgcyI/Klm8p+ma0iU4oBAUMo+m+I0ll4/zneRKFiYNfdgFANBULDxkiRhsAIC407XgfTHSsJ9uwlFsvRH1ly9GHALM8GHowABt4J4ItDywjIcrLS30+0whS6ofCy8VVtg4ZGFMZjFbsox7hBvfl7pUyOJTcBVLvlEICgxoqJrF+XZ+rLnNGGPzdW7T+8b3cSXLdJa8byV6lE3QI4SOB18a/z41u38QADW711oyv82wblMTwtBAhzD6dme2DKWhm+6aF9q5koUVn4rVNZP+PGyfGiYKKgHdOvr/P7R97iqS4R20TbehfdbwQbea9mk7b/kXvZMqFZT1k8emXEbbm/ryI2QJdFPI4tHwUmG54LdQyBLp4koWJg1DjCbpddW2Be8rbkwGNS6uZJHCmZdPoSVyBFGosOIr74HWokWPahEAoH9b8jMguVRYUG2GCGXaIUuqkoWb3hc2DlkYk5uDmisq3VzJUurCIxSyBJQcsuSjMTP1ZfEf4b4sjLHCxE3v56YQFDi1nKpZQo/S3YrU7P5zyWb378uo2f25zu3jMLg9s4nZijF6nvkSrmRhxUdv18OlsI3/OVg/fZjoLKfvB96Z+30UTG4zVjF7MFm+ObkMmf+c5V8AmHxUqaBbPPnYaVtP21e782O5sHAfXVMGdByy5ELEQaFbopdDFiYNU5wCEX31witZRDPtQ+F2LXhfDDj9EJ0Xdtgug7XJBgAYKqPPAM+byc+AZCWLV0H/9k10nyZa6bRv2pDlzBn6pVQCGzdmZ+wsNzhkYUxmQgWdAGu8HLKUuojTBwAIqbjpfT4KVNAZUryTK1kYY4XJ+Vfqx8JN72dn+hCFLG3Hn4IYE7Hz87/Fhe7XqNn9HzNsdn+ekeSd+b635j8xG/FF0BDtBABUX86VLKw4jWgmwgzl8unDxPAi+r5wfO73kfIkbRNtnj2YrL+iBSIUsMKDkcND4993hGkS3bJ0cshSu4Xeg3Xx7ilLDMohNkjXlCEjhyy5kKih/w+qYV4ujC1cQkzAkqBJemPtwkMW2GwAAMHHlSxSMG+jkMV9xdbx7wXq6DNAPDq5ksWZsAFAWpUszz9Pv69fD5h4KqigccjCmMzUNXQCrA9wyFLqIk6qZAmruZIlH4kNFLKoejlkYYwVJuV+6scSWMb9WGaz8nNXwAsTqsV+vPPgq2j9OfVfeeNd/4z6zU2SvMZ4H4fj869k6dneBRXi8MHIFUmsaHkME8tyWS6ZPkxUraDvmwfmfh9ZkttoVs4eTOpsuvHlX/peoWAmFoqhXKTAxb5i8nJhjvZyOBV2AED3yzOsA5NDiWFagjpqLZd5JKVB1UD/H/RjXMnCFs434IMS1KvN0mhb8P6EMgpq1H4OWRbKfdaNVWPUOKX5CxMhi2IpBfepZVxTlSwjUfq3b6TFMMYrWU6eBOLxyft+9ln6/brrsjBwllMcsjAmM30dhSymMIcspS4+lgxZtByy5CN1K02sGUd5uTDGWGEab3p/GVeyzEZr0eJQ7bsBAPVfvQ1V4gC61Euw8dGvSPYa430ceudfyTLeW0Lfxo2tWdEKlE0EiDVXTB+M2NbS92s8c7+Par20TdmGuZfYG7LSfj17KZgZ7hiEgARiUMKxtGLK9r1G2t65W/6+LIoxuqYUy7iSJRf0LfT/1OLnSha2cN5uFwAgChX0dv2C96e000S/Nuha8L5K3aH7n4caMZzSLEXT1a3j3zddTMf/1DKuqZDFDSv0eqCqir7d0ABoNEAkAnR3T+w3EgFefJG+5pCl8HHIwpjMDA10AmyNcuP7Uhd3UcgS03HIko9My+k2FLuPK1kYY4WHm97PT+w6ukuxIjEMABi950cLanZ/Pus6muitcs9/Una8t0Q5LxXGilesnCoE3LCgYmXVtNvUX0XvgWqxH94+74z7cp9xoSJBlSj1Vy6Z87X99fT+jB9JvtcOUZXCsFANQTV1CsVdSeMIH5h/aJoQE5N6vyyUOtXns5xDllywLqOQxRHhSha2cP6+5AS9wibJTRSaShsAQBcunEoWMSbKPYRpiU/QUmHdF2yd9P2aLck+XtFORAPR8eXCXLBh0SJAkfwxKpXA4sX09blLhu3YAfh8QGUlcNFF2fwbsFzgkIUxmVlbqJTblhjL2w8UlhsJTzJk0XPIko/K11AlS02sm9+rjLGCw03v56f9rushgq6Md9e+f8HN7s+X6uNQGz877z4OQrK3RGSO3hKMFTJFHR2neg0zV2zZmsswrKDKku4XZw44Uo8NCDUw16Zxnt1G7099cvkX7zGaQHfqpz92xlrovajqnF/IEo/EccS8Dgdtl0oWtGh9FLKoKjlkyQXHSgoD7QknQq6QzKNhhS44QGGIXylBPxYA2krajyFaGCHLcMcgRrS12Lbqc3IPZZJ4JI7lp58BAJT97eSQpeqiWvhhgBox9GzvmlTJ0tw8eT9Lkhn/uSFLaqmw97wHEHiGvuDxj5AxmZW10gmwEiLcZ1zyDobJy0eN70UDdzvLR1UX1SIGJTSIYnA/LwnAGCssrtcPAQC6yy6QeSSFoWJFJXa2/C26VYvQ8Kg0ze7P5WgvR5+yHgISOPTTbfN6bqq3hHoFV7Kw4lVz+1VwKuwY2nLrrNuddlBl3tDvX5lxm5E/0mNnyy9O67VTy7+UO+m9Fj5N530+8/QhS2pJWYNrftUMg2/3YXlgL1Z7d0p2HWgI0uoI2jruyZILtuYyhEBVjiMdAzKPhhW68KALABBQSxOy6KtpP6a4S5L9ZVvnb3ejUhzEkiN/kXsok/TtPgt7wokwNFjxiY2THhNUAnp0lJ4Mv3581pAlmd9PG7LwUmHFgUMWxmSmMWngBU2quzu5L0spU/iokiVh4kqWfKTSqTCgrAcAjOzjviyMscKSWvYmtQwOm9ulJ3+NhmgX6jY2Sr5vhaDAyfYbAQDBPzw5r+fWeOlnmU5vCcYKVdvNq1AWG8GWp78663aBK+l9VLZj5veRfSc9Frr6xrReu/oKem81RE4hFopB7KHwJGyvmXZ7bS3dNGcMzu9aztkxEcpIdR1ojtB+9PVcyZILCkGBIRWFb6ll5RjLVGSYJuiDOpsk+zPV034sCbekyxJmS7iL3kOV8f68Wjli8LVkLzxtK1Q61ZTHRyvoMyPw9rEpy4Wd6/xKlu5u4NAhqmB597uzMXKWaxyyMJYH3Eo6CfZ2cV+WUqYMJNeSNnPIkq9GjTTR5u3gviyMscKSWvYGS3liPl/ob6UlJ1qOPpX25Ienx4Mqke6Wrtsyd28JxgpZOj0JWr5EwclKz+twnpgaVIwcGcZK7y4AwJK70gtZatbWIwA9NIii9/XTEIaokkWsnr6SJdVj0xydX1DiOz4xKS/VdaAtTmMwL+KQJVdcegrfzv15MpaJuJNClohOmkoWUx3tR43YvJcmlUMq0FYhjtGjwzKPZoL/bbq5ZcQ+/Tl0pIlKVISTs1eynB+ypKpY1q8H7HZpx8zkwSELY3nAo6Vy7mAPV7KUMlWQQhaFlUOWfOV10HIQkRMcsjDGCktq2RvzxbzEVL5Y9aWr4IcBdfFuHP/jO2k9p+dl+jkOCVWwNkozCcNYIavf3ITjulVQQsSRHz475fGjP3wGAhI4or8INWvr09qnoBLQnVz+ZWj7MeidNPGnbJg+ZDE1UaCRCjjSFT4zsfysFNeBYU8YJvgBANbFHLLkit9C/y8iZ3g5YbYwotMFAIgaJQpZqk2IJ6d9vT3535dFOTTxHnIeyqP30wk69wo1Tn8OrV5J4Yulf3Ily0whS2cnEIvxUmHFiEMWxvJAQE8nwZF+DllKmTpEIYvSxiFLvorVUsgidHPIwhgrHLFQDA2RUwCAqss4ZMkXOpsOHdXXAAD6H0lvybCx3VSR1GfmiiTGUvoupqowxdNT30fKZ+l7g5ekV8WS4nTQsdK//zjMPgpZdM3TLxeWCjQMCM7rbvFEz0TlQ7hv4deBYydpH3EIsDRwCJsrEQf9v0j0ciULW6BkFYRotkmyO4WggEdBxwJ/X/6HLLqxifeQ52j+vJ9MvXTupVw+/bmXbR19XlR7j0Mcm7mSpa4O0OkoYDlxAnjxRfo+hyzFg0MWxvJA2EQn5rEhDllKmSZCje9VVm58n6+ExRSy6Ia5JwtjrHD0vn4aGkQRgD7tO7lZbkTeTZPDFXvSC1mih+huSk81h2WMpZTfQe+jFd3PIeKLjH8/7AljZe/zAIDKO7fOa5/hRTSZJpw4DnuY7qi2LJ2+ksVSb0EUtE6/61T613Pn3rUtxXWgp5OWHHMqHBBUPNWTK4ka+n+hGs6jO+9ZQRK8NEGfsEgXkvqUtK9An0uyfWaL2TfxHgp15c/7qcpN517WtdOfe9VflQxZxH7Ez/YAAOJGK8rKJm8nCEBrK339618DPh9QWQlcfHFWhs1kwJ+8jOWBmCVZzj3CIUsp00WpkkXj4EqWfGVop54sZW6uZGGMFY6h7cmGnbolPPGWZ9ruugEAsML/Jgb3zz2hoOmin6XYypUsjKUs//g6DCsqYYUHHT/bPv79jp9sgxk+DArVWHr7mnntU7WcJs2sPYdQLg4BAOwrpw9ZFIICY0Kyx+bp9K/nzr1rW4rrQP9Z2odHzUuF5ZKqkf5f6Mfy5857VphUPhcAQFFmk2yffjXtKzyU/5UsjtDEeyjenR/vp8BIAPVxusGy7qrpz72sTTYMKyoBAOox6iVjqrdNu21qybBf/IJ+v/ZaCl9YceAfJWN5IGGnE2HByY3vS5k+xiFLvrNfRJUsVeEzaTcpZowxufn30x14znKemM83VRfW4JBxLQDg+APPzLl92Qj9LPUXcCULYymCSsDRVgosvb97avz7vv+jr48tuXHeAXNq+Zd2zxsQkEAUKjjay2fcPhVspIKOdFh8E5OIUlwHhnrptf1aDllySb+Ylguz+PNjUpgVLnWQghChTLpKlpCG9hUZzu+QJRqIoiIxNP5nYSA/3k89r54EAIwpymBfMvOxtc88+bysbNH0P8NUyDI2Rr/zUmHFhUMWxvKAooJO2NVermQpZQaRQhZdBYcs+ap6HVWyWOCF+4xL3sEwxliahONU/RBu4on5fDS8npYx0jw/+5JhCTGBhiCFLBWXcmDG2LnUf0M9VxYdfBIJMYGEmMDiw/Se0t48v6XCAKDuSjpe6hAGAAwrq2cNalLBRqgn/bAktQwZAKg9C78OjA7QPoJGDllyybqMKlkckfxZ3ogVJl3QBQBQl0sXsoT1tK/YiEuyfWbDyKHBSX/WOvPj/TS6k86hew1tUAiKGbfzVE8+L6tonT1kAaiC5d3vXvgYWf7gkIWxPKCuphNhnZ9DllJmSlDIYqjikCVfGcoNGFZUAAAG3+S+LIyxwmDup4n51PI3LL/UfIomgFcOvICQKzTjdgP7+mCCHzEoUX9Z84zbMVaKVt79boShQVPsFDqfOYqTTxxCQ+w0gtBh1V3XzHt/ZS12jCgmKlfGdNM3vU9JBRvRwfSu5yK+CCoSw+N/luI6UBymfUTMM1fcMOk5VtL/DXvCOesxnLG56KNUbaKtskm2z6iB9pVqyJ6vnB2TK1dM3vyoZAkfpHNoV9XsN7fEWybOsWNQoq7NOO1254Ys69YBDs7EiwqHLIzlAW0tHVmNIQ5ZSlXYE4YGUQCAsZpDlnw2rKdqFtc73JeFMVYYqj10gWhbz9UP+ajtlgvQq2yAEQEcfPDlGbcbeI1+jj3qZmhMmlwNj7GCYKo24aDjSgBA90+fRO/DVMVysPJqGMoNGe2zzzRxzPSZp+/HkhKxULCRGE7vem744MCkPxukuA4cpSqauI1n7XLJ1lyGELQAgOED+XH3PStMxmTIoquSrpIlbkruy+WSbJ/Z4DtB750w6PymLJQf7yVVJ517xRbPfqOS/sKJzws3rGhePH3VS9s5u3nPexY+PpZfOGRhLA8YGuhE2BzhkKVU+Qd9418bq0wyjoTNxWOjviyhYxyyMMbyn2/AhxqxFwBQfxVXsuQjhaDAqaW01FHwDzMvGebdS0tWDJVxWMbYdPxXUVVY2etPwrGT3kuha+a/VFiKu3rimBl2zB6yiMlgQ+FM73pu7PDkCUSLBNeBKldyH3xrdE4pBAWGVPT/w3UkPyaGWWEyiy4AgKFGupAlYbUBABTe/K5kCXdR5copw2oAQGW8H2JMlHNIAADbIJ17aVfPfu5Vvmni88IFGxYtmn676mrAbqevb7hBihGyfMIhC2N5wLyIToTt4gg30y5RgUFaKiwIHVQ6lcyjYbMJVVPIkjjNIQtjLP/1vHICADCsqICtuUzm0bCZ6G+hkKX12FMznguKx+huykA9h2WMTaflS/Q+WunZiRW+3QCAJV/OfBYr3jIxqSZWzb5cWCrYULrTC0t8x2lCcVCoBgCUSXAdqPHRaysrOWTJNZee/n+kfq6MzVcsFIMJfgCAqd4m3Y6tFNiofPkdsog99N4ZabwIIhRQIY7Ro8NzPCu7EmIC9QEKWRwbZz/3atjSgnhyit0N64whi0IB/OEPwK9/DVxyiYSDZXmBQxbG8oCtlcrLtYjAP+SXeTRMDqmQxafgpcLynaKJQhbtIPdkYYzlP+cuujjsN/HEfD5b9aWr4IcBtfEeHPv9/mm3MXbTz1JYypUsjE2nfnMTjutWQQkRAhI4or8INWvrM96fbvXEcVPZMHslSyrY0HrTa3yfumu7x7aKXgthBEYCmQxznD5AIUuq3yfLHb+F/n9EznAlC8uMt9cz/rWlQbpKFqWd9qUOuCTbZzYoh+i9I9Y2YESoBAA4D8n7fho9NgJbwgUAaLhqyazbakwa9KioX15AbYVplsVJrr4a+NjHpBolyyccsjCWB4yVxvG1J12neMmwUhQeoZAloOSQJd9pl1BPFvMYV7IwxvJfpIOqH85d9oblH51Nh47qdwEABn4x/ZJhFS76WZrX8M+SsZn0XTyxPNjg2syXCgMmL/+iWzx7yKKppZvmDMH0ruUSfTR56KtdggjUABZ+HWgOU8Cjb+DG97kWKaf/H4lermRhmfF2uwAAfhigNqgl26+q3AYA0Ibyu5JFN0bvHWVDLUa19H7yHJX3/dT3arIXnrIRert+zu2HyugzI2ayZXNYLI9xyMJYHlAICowJdMeR9zSHLKUoFbKEVByy5DvraqpkqQxyyMIYy3/qTqp+OHfZG5afItfShHDFG09NfcwXQX20CwBQs4V/lozNpPyOiWCl8s6FhSwNV7ZCBDUvtrTPvlyYvp6u5Uzh9K7llEM0eZioqYNToFBkIdeBCTGBsigtrWNs5EqWXEtU0/8P1RCHLCwzgX4KQbyCdFUsAKCpoP0Zw05J9ys1s4+CZ93iWnjNFLKEOuV9P7nfoHPoQWt6N7cE6un8TGGV9mfICgeHLIzlCa+aToYDZ9MrMWfFJeqixvdhNTe9z3dV65IhiziIkCsk82gYY2x2ZcN0F965y96w/NR+N/WOWOF/E4P7Jy+R0fNaJ1SIwwcjqi6cozcEYyVs+cfXYVfdzdhVfwuWfvjiBe1La9Fix9JP4h3LpWi+Yfms25qa6FrOFksvKNGN0XtcWV8zfh3oP5P5deCJPx+EFW4EoUPdpc0Z74dlRtVIk8J6Fy8XxjIT7HcBAPwqaSfoa69eBgBYHD6CkSPy9jiZjSNEgYqlvQahMjrPiffI+36KH6FzaF9deje3OD77QXSpl0D74ZuzOSyWxzhkYSxP+HV0ch3u40qWUhQfo0qWsJYrWfJdWYsdPhgBAANvdss8GsYYm9m5DTvLN3P1Q76rXF2NDuM6AMDx+5+e9Njw63Sh361vg0JQ5HxsjBUKQSVgY8+j2Nj9BwiqhU93XH7k57jAvR0ak2bW7SzNdC1nhRvRQHTO/Vp8NKGob6mV5Dqw7+e0zODBymvSWtaGSUu/mCaFLX6uZGGZiQxTJUtAY5N0vzVr63FUfyEEJHD0h89Ium+pRANRVCSGAAD2lbUQqyi0FAbkfT/pztK5F5akd6PSyk9sQHPkODZ8d2FVlKxwccjCWJ4ImqhMPDrAIUspirsoZInpOGTJdwpBgUEN9WVxvs1LhjHG8tdwxyAs8EKEAg1bWuQeDkvDyAa6MNf8dXJfluB+CsvGKjgsYywf2ZrLxr92dc69LI8jfM5d20YKWRZyHVi+i44ZoXfx5J4crMtoUrg8wiELy0x0hEKWsFb6paYGLqHjgvLZ6Xu+yW3k0CAAIAoVHO3lEOootNQ65a1kKXfSuZfxYj73YunhkIWxPBE108l1YoRDllKU8CRDFj2HLIXAaaElw/yHOWRhjOWv/m3Jhp2qRdBatDKPhqWj5pM3AgBWDbyAoDM4/n3hFP0sI4t42TfG8pFKp8KYgoIWd+fs13MRXwTlCVoazLGqFhHLwq4DhzsGsdz/BgBgyZdvyGgfbGHKV1PIUpYY4+WEWUbioy4AQMQgfchScQedW6zsfR5hT1jy/S+Us4PCyWFlNQSVAG0zvZ9MXvlCy3gkjobwSQBA1WV87sXSwyELY3lCLKOTa4WTQ5aS5KWQRTRyyFIIghUUssS7zso8EsYYm5n7zWTDThvfgVco2m65AL3KBhgQRMePXh7/vrWffpbqlfyzZCxfuVXJ3ipnZ7+eGz44AACIQA37EgfEMlrRINPrwKP3PQ0BCRzRX4yaS+oy2gdbGGuTDSHQzQzDB7gvC5u/hIsqWWJGm+T7XvbRSzAoVMMMHzp++prk+18o3wl6zzh1FK6Y2+l3e1C+kKV35xloEUEIWtRuaJRtHKywcMjCWL5w0Em5ys2N70uRwk+N7xNGbnxfCMQGCllUvVzJwhjLX2KyYWegju/AKxQKQYFTS+mO0+AfJpb1qPHRz7JsPf8sGctXPg1dz4V6Zw9Lxg7RxOGQsoZ6LKWuA12ZXQeqn38KADC4jpcKk4tCUGBIRRPDriMcsrAMeChkEc3SV7IIKgHHW6nKzfe7/FsyLNxFx0S/mZYJK1tOv1eIAxBjoixjGtqR7IWnbYVSo8x4P2o1UFNDv7PixyELY3lCVU13MGl9XMlSipQBqmSBmStZCoG6he5mMY5yyMIYy1/6bqp+wFKufigk+ltponTJsaeQEBNwn3WjUqT1yuuv4pCFsXwVNFBYEumbPSxJ3bU9pqdJeVUVPS+T68CQK4SV/X8FAFR9gkMWObn0NDHsO859Wdj8KT0u+sJmy8r+NTfT8WHx4SeREBNZeY1MiT30ngk76JhYsbIKIhRQIY7Ro8OyjMm/j86hR+0LO+9Sq4HaWg5ZSgWHLIzlCU0NnVwbghyylCJVkEIWhZVDlkJgXkmVLA4fhyyMsfxVMUZ34Zkv5on5QrLqi1fCByNqxF4c+/1+9L5CP8dBoRqWeovMo2OMzSSc7LEZH5r9eu78u7YXch3Y8eNXYYIf/UItln744nk/n0nHb6EJ4shpDlnY/KkCVMmisElfyQIAK798DULQoiF2GiefOJSV18iUcoiCZ7E6GTzrVBgRKgEAzkMyVYadoHOvUBPfqMTSp8rkSQcOHJj2+wqFAjqdDo2NjdBqubkmY/Ohr6eTa3OEQ5ZSpA5RyKK0cchSCMrXUMhSHetBPBJfUAkxY4xlQzQQRUPkFABu2FlodDYddte8Cxv6H8fAL56EemkLAKDf3IYqmcfGGJtZzEYrE2B09uu5RG/yru1ymlDUN9DzTBlcB/p/T0v/nGi7ETWCYt7PZ9KJlNcCvUCij5cLY/OnDbgAACpHdkIWY6URb1ZcjbXDz6D34Sex5H0rs/I6mdCN0TFRWV8z/r1RbS0qg4PwHO0DcGHOx2Tqo5BFuYzPoVn6MgpZLrzwQigUM3+Aq9VqfPCDH8TPf/5z6HS6jAfHWCkxNVHIYotxT5ZSpIlQyKIu45ClEFRdVIsYlNAgiv4DA9xklDGWd3pfP41FiCEAPWrW1ss9HDZP0Wu3Ar9+HJV7nsRQ7DoAgKeG76ZkLK/Z6XpO6Zo9LFEO0yR8InnXdqbXgQkxgdYjFLLobuGlwuSWqK4B3gFUQ1zJwuZPF6ZKFnWFLWuvEbxmK/C7Z+DY+SSAb2TtdebL7KNjom5x7fj3vOZaIPg2Qp3yvJ+q3bRcmG09n3ux9GW0XNhjjz2GJUuW4JFHHsH+/fuxf/9+PPLII2hvb8dvf/tb/Od//idefvll/PM//7PU42WsaFkXJytZ4EPEF5F5NCzXdFFqfK8u48b3hUCpUWJASZOWI2/xkmGMsfwztJ0uDrt1SyCoeIXgQrP0K9SgdnlgL8reeRUAILbw3ZSM5TOhgq7nNN7ZQxa9c/Jd26nrQAu887oOPP7oAdTFuxGAHqu+fHUmQ2YSUjUmK5NcXMnC5k8fpZBFW5mdShYAaP0SnVus8O3G8KGhrL3OfDlCdEy0LJ0IWUJldHyM9+T+/RQYCaAu3g0AqN3C514sfRldcX33u9/Fgw8+iDvvvBOrVq3CqlWrcOedd+L+++/Hfffdh9tvvx0PPfQQHnvsManHy1jRsjbZEE++JcdO8pJhpUYfo0oWjYMrWQrFiImWDPN2cMjCGMs/gXdomQNnOd+BV4gqVlahw7gOAHCBZzsAwHAR/ywZy2fqagpL9P7ZK1LMfpo01LfQhKK1yQYRtFKIq9OZ9uv1P0JVLB2VV0Nv1897vExahlb6eVr8XMnC5s8UcwEA9NXZC1lq1zfgqP5CCEjg2APPZu115iMaiKIiQYGPfcXEcmFiFb2fhIHcv5+6Xz4BAHAq7HC0l+f89VnhyihkOXjwIJqamqZ8v6mpCQcPHgRAS4r193OCz1i6lBolXIoyAICni0OWUmMQKWTRVXDIUih8DvocjJw8K/NIGGNsKiHZsDPcxHfgFaqRDZOX/ynfxD9LxvKZrp4m44zh2a/lHOHkXdvtNKGY6XVg+e6nAAChd/FSYfkg9fMsj3DIwubPkqBKFmOdLauvM3AJHS+Uzz6Z1ddJ18ihQQBAFKpJgYZQTyGL1pn795NzN51D9xr5vIvNT0Yhy9KlS/H9738fkchEKWs0GsX3v/99LF26FADQ29uLqipuzcjYfHhUdPeT/yyHLKXGlKCQxVDFIUuhiNVSyCJ0cyULYyz/mPtpuTDVcr5ALFQ1n5qYOI1BifrLmmUcDWNsLsbG5LJf0Zmv5SK+CMoTVOniWDWxNI5bRZOL6V4HDncMYrn/DQBA2903ZjReJq3y1fTzLEuMIeQKyTwaVkhCrhC0oPlVU132KlkAoPJOOrdY2fs8wp5wVl8rHc4OClGGlDWTlrfVLqLQ0uTN/c374QN0Du2u5HNoNj8ZNb7/yU9+gve+972or6/H6tWrAVB1Szwex1NP0d0UnZ2d+OxnPyvdSBkrAT6tA4gCwZ75NT1khS3sCUOLKADAWM0hS6EQmhuBHYB+iEMWxpi8vH1enH7yIBJiYvx7dZ4jALhhZyFr+8Bq9CobUBfvRrd6MZpNGrmHxBibhXkRhSxlCSfEmDhtP6zhgwOoAxCBGvYljvHvj18Hdqd3HXj0vqdxGRI4bFiD5RfXzv0ElnXWJhtC0EKHMIYP9KPhcg7Gi4X7rBtiNI6yFntW9u8564IOgAgFzLXZnQ9YevsaDP5dNarEAbz1k21Y8413S/4a8UgcPTtOo+mqljm39Z2gEGVMV4O6c75vbqfjmj2Y+0oWVRdVssRa+ByazU9GIcumTZvQ1dWF3/zmNzh+nP7z3XLLLfjwhz8Ms5kOCB/96EelGyVjJSJocAA+INrPlSylxD/ogzb5tbGKG98XCuMyqmSxeThkYYzJJxqIoq/lMqwKvTPt4/VX8V14hUohKHBy2VbUdfwUw2Vt4Ok6xvJbWSuFJirE4ep2w9ZcNmWbsUN9qAPdtV0vKMa/n7oOjAzMfh3oPuPC25/4CVa9dD8AYGjdViyX7q/AFkAhKDCkqkVjrAtjh/o4ZCkSYkyEs3UddHE/fL1HYaqW/nrd1+tGJQAvLLBOE85KSVAJOLbkRlQd+yV8v3sSyELIsv29/4Etz38Dr77n+9jy7D/Mum24i0IUn2VyWFy2nCpZKsSBGUPrbLEPHAYAaFfxOTSbn4xCFgAwm8349Kc/LeVYGCt5YUs5MASIwxyylJLAkA92gO580mV8WGY5Vr6e7sypD5/K+YkfY4ylvP6hh7Al9A6C0GFQXT/psTPLr8cV00zyscLR/NBXsO/9x6D6+7vkHgpjbA46mw5+GGBEAO7O0WlDFt9xmlAc09fi3CN2xOyg68Ch6a8DhzsGcegT9+PiPT/FFtAyw13qNiy7/1OS/z1Y5lz6WjR6u+A/yf2Ji0Xfnm40R+nm8rd/8wYu+spVkr9GoM8FAPAqrcjuYmFEe/NW4Hu/RMvhJ5EQfwTFOYGvFBpe+R8AwPrnvoXu126dNXAUe+iYGLHXTPp+xcoqiFBAhTiGjw6jYmVu2lGMHBnG0sA+AEDTretz8pqseGQ8m3fixAm88sorGBoagiiKkx675557FjwwxkpR3JosGR/lkKWUhEb9AICAwgidzGNh6au/dBEiUEOPEHr2dKN+c5PcQ2KMlZiBfX24+C/fAgDs/duHcNl/f2LS44tyPiImtcYti9HofFHuYTDG0jSmLIcxfhbe06MAWqc8Hj5Nk+9+8+QJxZgt2fB5muvAff/xEpZ97UZsAfX5OKFdiaE7v4H1990KFd+glVf8lhrAC0RO536JI5Ydg9uPjwei7md3AlkIWcJD1PTer7ZJvu/prPzS1Qh9T4v6+Bkcf6wDbTevkmzfZ14+hZYILVmrRwh9H7wLDf2Pz7i9coiOiWL15EoWlU6FQaEKVeIARg/25SxkOfrDZ3ApEjiqvxBL1zfk5DVZ8cjotttf/OIXWLZsGe655x48+uijeOyxx8Z/Pf744xIPkbES4qCQRenmkKWURMYoZAkKRplHwuZDqVGiW0MXz4Pbj8s8GsZYKTr1/q/CAi86jOuw+T//Tu7hMMZYyfNq6Hou2DP99Vyilybfw+Xn9VGZ5TrQ9+tHoUcIJ7Qrsecfn0CL7x1s/smHOWDJQ5HkzzXRx5UsxcL31rHxr40HdmblNSLDFLKENLmoYwGMlUYcrLgaAND3yFOS7vv0Q08CADo17YhChfUDT+DNbz094/a6MTomKhum9pZyaimM9h7P3ftJ+SyNf+CSrTl7TVY8MgpZ7r33Xnz3u9/FwMAA9u/fj7fffnv81759+6QeI2MlQ6igk2uthxvfl5JUyBJScshSaIYd1Azv3JNvxhjLhf0PvIrNZ34LEQooH/4pL1nIGGN5IKCn67nwDD02lUM0oZg4767t1HWgZprrQEsv3RU++PGvYf1338vH+zyWqKZJYdUQV7IUjeMTN9O1juyGGBNn2Tgz0REXACCsy03IAgDBayhEcOx8UtL9mrfR/s5e9//w+iVfBgBUfveLCLlC02/vowBF11wz5TGvmY6Toc7cvJ/CnjBW9j4PAKi8k0MWNn8ZfTqPjY3hlltukXosjJU8TS2ViesDXMlSSqIuClnCKg5ZCk2oIdkM7zhXsjDGcicaiML49c8DAHas+DSWfWSNzCNijDEGAGEjhSWxgelvmtOP0YSisn7yhKK6hp433XVgnYeaMDsu5Rb3+U7VSJPCeheHLMXC2DtxM11ZYgxdz0l/c53opEqWiNEm+b5nsuSuGwEAK3y7MXxoSJJ9us+6sWrsNQBA8xe2Ys0T96BfqEVTrBO73//v0z7HEaL3imXp1EqWUBkdJ+PduXk/dfxkG8zwYVCoxtLb+dyazV9GIcstt9yCv/71r1KPhbGSp6ujk2tTmEOWUhJ1U8gSUXPIUmiUyyhkOffkmzHGsu31Dz2EJeFDGFGUY9UT98o9HMYYY0nRVI/Nkemv5yx+mizUt0yeUNTPcB3oPDGKisQwAKDx3UulHCrLAkMr/Vwtfl4urFhUuelmOi9MAIC+R7OwZJibQpa4KXeVLDVr63FEfxEEJHDs/mck2eeh+5+HGjF0atrRdHUrzLVmdH3uPgDA+lf+Dd2vdU3aPhqIoiJBAY9j1dSQRayi7wmDuXk/+f6Plk473noDVwyyjGS0iGdrayu++c1vYvfu3Vi1ahXUavWkx7/4xS9KMjjGSo2xkU6uLTEOWUpJPBmyRDUcshQa67p24L8nTr4ZYyzbBvb1Yc1f/gUAcORvv4/LWuwyj4gxxlhKwk4rEwhj01/P2cM0WXj+XdvGJnqeJTr5eT0vHIEdQI+yCfWVfK2Q7yztdOd9eYQrWYpB0BlEXewMAGD/kltx2YlfAbt2AbhT0tdRuF0AgITFJul+5zK4diuWvfY2VM8+CeDjC96f+ERyqbDVW7E4+b2ND3wQb//vI7jI9Qr6PvhlNPQ/Mb79yKFB1ACIQgX7EseU/Qn1dJzUOrP/fkqICSw+TOPX3MxLhbHMZBSyPPLIIzCZTNi2bRu2bds26TGFQsEhC2MZsjTTB0tZwol4JA6lRinziFguiF4KWWIcshScmiuokqUudgZBZxB6u17mETHGit2p938Vm+FDh3E9Nv/yDrmHwxhj7ByKcrqeU3umhixhTxjlCVpGzLFy8nJh514HijFx/C5q105aKqy/bBnqszZqJpXy1TQpXJYY42uDItCz7RSWIAGXwgbNLTcB3/sVak9LX8mi9FMlC6y5q2QBkn1HXvsOVvT9FWFPGFqLNuN9xUIxLD9NFTFlfzsRUigEBcz//WNEb7oA6wf+gjfueQrrvkNLlTk7+lADYEhZg7ppKke0i+g4afJmv5Ll5BOHsCR2GiFosfLL12T99Vhxyqj+qaura8ZfnZ2dUo+RsZJR1kon1wIScJ9xyTsYljMJH4UscR2HLIWmfFkFXAobBCTQs+2U3MNhjBW5Sc3uf87N7hljLN+oquh6Tueb2pNl+OAAACAC9ZS7tlPXgUqIk64DE4ep6b2/cVk2hsskZm2yIQSaqB7pGJB5NGyhRnfRagU9hja0fGQjAKAlcgSurjFJX0cdoJBFKMttyLL0wxdjUKiGGT4cfOjVBe3r0C93wZ5wYkxRhhWf3DTpsdb3Lsfra+8CAFT/2xcRdAYBAL4TFJ6M6aYuFQYA5nb6vj2Y/UqW3oepiuVgxdUwctUgyxBfmTGWRzQmDTwwAwDcnbxkWMnwJ0MWPX+YFxqFoECPgapZUifhjDGWDdFAFKavfw4AsH3lZ7Ds9otlHhFjjLHzaWspLDGEpl7LuY7QhOKQsgYKQTHpMY1JM97z4dzrQONZClmUK7npfSFQCAoMqWhieOwQLxlW6ELvUN9NV2UbypdVoEu9BABw4n93S/o62qALAKCqsEm637kIKgHHllBVif/3Ty1oX2P/QyHF4abrodJNXTRpzePfRL9Qi8ZYF/bc/O8AgHAXvUd8lpop2wOAfSW9lyrEAcQj8QWNby6OnTT+4DW8VBjLXNrLhd19993413/9VxiNRtx9992zbvvDH/5wwQNjrFS5VQ5YYl74znDIUjICFLIkOGQpSK6qdqDzjfGTcMYYy4bXP/QQtoQPY0RRjgv+ws3uGWMsHxkak71VIlOv5XzHaUJxTF877dJfbqUD5rgveR1Ik7k1LlouzLqBK1kKhUtfi0ZvF/wnc9Osm2WPspNuoostbgcA9DZuQvOpE/C/sBO45zrJXkcfpkoWTXluK1kAQHvzVuB7v0TL4SeREH80JQBOV8M7FFIo3jt9SGGuNePg53+Imh/dhvWvfh9nX/0oxB46JoYd01eylC+vhAgFVIhj+PgIKlZWZTS2uQwfGsIKHwVnS+66MSuvwUpD2iHL22+/jWg0Ov71TBSKzN6QjDHi1TiA2GkEezhkKRVCMmSBkUOWQhRrbgM6J07CGWNMapOa3X/s/4fLmstkHhFjjLHpmBdRJYtNnKYnS/Kubb9l+glFj7YcCJwZvw70DfhQF+8GADS8m0OWQuG31ABeIHKaK1kKnW2AbqLTrKKVC8T1G4FT/w3LoV2Svo4x6gIA6KpyH7KsuusaBL+nQ338DI4/1oG2m1fNex9nXjqJlshRRKHCiruvnXG7jfffin3/+wguHnsZ/bd9GUprJQAgUTV9JYtKp8KgUIUqcQCjB/uyFrIcu/8ZXIoEjugvwrK13P2KZS7t5cJeeeUV2Gy28a9n+vXyyy+n/eKvvfYatm7ditraWigUCjz++OOTHk8kErjnnntQU1MDvV6Pa665BidOnJi0jdPpxO233w6LxQKbzYY777wTPp8v7TEwlm8Cejoxj/RNXceXFSchxCFLIUuddKdOwhljTGqn3v/3tF62aQM2/+Ljcg+HMcbYDKyL6VpOjxACI4FJjyX6qLIh7Jh+QjF1HRjupevAs389CgAYEqpQ1mLPyniZ9CLlFKIlejlkKXS1frqJzrGRKlmq30+9RpaM7UEsFJPsdUwiVbIYam2S7TNdhnIDDlZeDQDo+/mTGe3j9I9pqbEO22WwNtlm3E4hKGD9nx8jChXWDz6JZSeeAAAoG6YPngHAqaXjpfd49irDlM/R+AfX8lJhbGFk7cni9/txwQUX4Cc/+cm0j//7v/87fvSjH+Hhhx/Gnj17YDQace211yIUCo1vc/vtt+PQoUN44YUX8NRTT+G1117Dpz71qVz9FRiTXNhEJ9exQa5kKRWqZMgimDlkKUSpk+7USThjjEmJmt3/DnEIUD38E252zxhjecxca0Y0uWDI2InJN80ph2jSPVE9/YTi+HXgEF0HOnfQUmG9Fq5iKSSJGvr5qoZ5ubBC5jwxCkeC3ov1W1oBAC1bl8MNC8zw4dQTHZK8jhgTYU54AADG2txXsgBAKNmHxLErs5DFvI2e575i7pCi5cZleH3tXQCA8gQdI/UtM4csXjM9FurMTmgZ9oSxsvd5AEDlnRyysIVJe7mw97///Wnv9M9//nNa21133XW47rrp1zFMJBJ44IEH8M///M+46aabAAD/8z//g6qqKjz++OO47bbbcOTIETz33HN48803cckllwAAHnroIVx//fX4wQ9+gNramd+ojOWrmJXW8cUohyylQhXhkKWQpU66HYlROE+Mwr7EIfOIGGNzOfb7/ai/cgmMlfl93D232f2OlZ/GFdzsnjHG8ppCUGBMcKBSHIT39CiwsXH8Mf0YTRIq66evZIlZkueQI3QdGDtITe899dz0vpCoGujnq3dxJUsh633lOOwAepUNqEueLyo1Spy0r8ca5wsYfHwX2j944YJfxzfggwUiAMBcL0/IsuSuG4HfAit8ezB8aAgVKypn3PbEYx0Y3TVxc6EYjWHt2GsAgOYvpBdSrHn8m+hv+C1qxF4AgLlt+mMiAITstcAQEO/Ozvup4yfbsAY+DAg1WPphPs9mC5P2rXBWq3X8l8ViwUsvvYS9e/eOP/7WW2/hpZdegtUqzUGhq6sLAwMDuOaaayaNYf369di1i9Y/3LVrF2w223jAAgDXXHMNBEHAnj17Ztx3OByGx+OZ9IuxfJGw08m1MMYhS6nQJEMWpTW/J/vY9IyVRvQqGwDQyThjLL+9cc9TaL/tIuy95h/kHsqc3vynx9DKze4ZY6yguNV001yge/L1nN17BsDMd20nHPS81HWg/jRVsmApV7IUEkMr/Xytfg5ZCpn7TbquG7S0Tfq+dxUtGSbs2SnJ6/h6aamwCNTQ2/WS7HO+ai6pwxH9RRCQwNH7np5xu/43e9D4/jXY8B83j//a9MAHoUYMpzRL0XR1a1qvZ641o+uLPxz/c/kFdTNuK1ZSACMMZqcyzPsnqmI5vuQGrhZnC5Z2Jct//dd/jX/9D//wD7j11lvx8MMPQ6lUAgDi8Tg++9nPwmKxSDKwgYEBAEBV1eTGRlVVVeOPDQwMoLJycsKqUqlgt9vHt5nOv/3bv+Hb3/62JONkTGqKcgpZ1F4OWUqFJkYhi5pDloI1aGlD3Vg3nYx/aqPcw2GMzSL4OF1MVZ/YLvNI5hY5cRYAcHTRe3ApN7tnjLGC4Nc5gDAQ6p24nut5/QwWR44hDgHNH1gz7fPGrwM9tIRO5ShVspjXcchSSCztNCnsiPByYYUsdoj6bXrr2id933ztJmAb0NAtTcji76OQxaOwolxQSLLPTAyu3Yplr70N9fNPAbhj2m2O/8cTuAIRjCjK0Wea+HcRBRUiX/gKWubxehvvuwWvvn0YUCqxpb18xu0UlRUAALV7eB57T5/pNC37ptiwISv7Z6Ulo5juV7/6Ff7+7/9+PGABAKVSibvvvhu/+tWvJBtctnzjG9+A2+0e/9Xd3S33kBgbp65ONkv0ceP7UqFNhSw2DlkKla+W7nBKnYwzxvKXvestAEBD6ATEmCjzaObg8wEARINZ5oEwxhhLV8hA13PR/onruVMPJhtDWzbBMcOEYuo6UOcfRdgTRmP0FACg7l28XFghKV9NlSxliTEEnUGZR8MypT2bXKFgyeRKltbb10OEAk2xTgx3DC74dYL9LgCAT2Vb8L4WItWPZEXfXxH2hKfdxvgy9V7peM9XsdqzY/zXha5Xse5f59fPRCEosOXVb2HLS9+cdTt1DR0vdf7s3IRc5aafs3Vd+xxbMja3jEKWWCyGo0ePTvn+0aNHIYrSXKxWV1cDAAYHJx+0BgcHxx+rrq7G0NDQlLE5nc7xbaaj1WphsVgm/WIsX2hr6eTaGOJKllKhi1PIoinjkKVQJdropGz8ZJwxlpdioRhafPsBAAYEMfBWr7wDmovPCwAQjRyyMMZYoYgke6skRiau51KTk2ObbpzxeedeB5554TiUEOGGFZWrZ57bYPnH2mRDEDoAwEjHzCussPxWPkI3zxkunByyWButOKVdAQDo/M2uBb9OeIgqWQJqefqxpCz98MUYEGpghg8HH3p1yuO+AR9Wjb4CAKj/9MzHMallc34s5AqhLkbLONZc0TbH1ozNLaOQ5Y477sCdd96JH/7wh9ixYwd27NiB++67D5/4xCdwxx3Tl5XNV3NzM6qrq/HSSy+Nf8/j8WDPnj3YuJGWYtm4cSNcLhfeeuut8W1efvlliKKI9evXSzIOxnLN0EhJvTnKIUupMIgUsmjtHLIUqtTJd+pknDGWnzqfPgIDJu4qHdiW3+9ZwU8hC0wmeQfCGGMsbaKNJgUVTrqe8/Z5JyYnPzPz3d6GBnqeOTKKkR20VNhZ0zIoZFxCiM2fQlBgWEVLho0d4r4shUiMiWgInwAAVF0+tcKhv5nmJIMvLXzJsMiQCwAQ0sobsggqAcfbKDzx//7JKY933P8CtIjgjGoxWm7M3RKG5x4Xpdb9ykkISMClsKF8WYXk+2elJ+2eLOf6wQ9+gOrqatx3333o76d1JmtqavDVr34VX/nKV9Lej8/nw8mTJ8f/3NXVhf3798Nut6OxsRFf/vKXce+992LJkiVobm7GN7/5TdTW1uJv/uZvAADLli3De97zHnzyk5/Eww8/jGg0is9//vO47bbbUFs7fTM5xvKdeRF9iJSJo0iICT6pLgEGUMiiL+eQpVClTr4bwrT8EDfNYyw/DT37Fs69T8277ziAa+QazpxUAQpZFBauZGGMsYJRTjfNqdw0KXjowRexIY3JSXMzPa9MHMWxt6npvauGlworRC59LRq9XfCf4JClEPXtPot6hBGGBnWbmqY8LmzeBBz9BcqOLbySJeZMNr7X2xa8r4XSfWArcO8v0HL4SSTEhybNRUUfo+Dl9MqtaMrhHFU258dGdx3HEgA9hjbYeN6NSSCjWSBBEPC1r30Nvb29cLlccLlc6O3txde+9rVJfVrmsnfvXlx00UW46KKLAAB33303LrroItxzzz0AgK997Wv4whe+gE996lNYu3YtfD4fnnvuOeh0uvF9/OY3v8HSpUtx9dVX4/rrr8ell16KRx55JJO/FmN5wdZCHyJaROAb8Mk8GpZtEV8EasQAcMhSyOo2NSEMDXQIo28P9/liLF/F36DqZxHJC6mj+V3JogpRyCJYOWRhjLFCoayk6zmNj0KWcycnZ5sgTF0H6hCG4cheAEC8jZveFyK/hSpZImf6ZR4Jy8TgdloCulvbCqVm6hxn3S2bAADtnjcR8UUW9FqJMQpZokZ5K1kAYOWXrkYQOtTHz+LEnw+Of1+MiVh68mkAgPnD8+u9slDnHhf9Q35J9x16h64DXFXcj4VJY8G32i6kp8mWLVuQSCSm/Pr1r38NAFAoFPjOd76DgYEB/SL42QAAoVVJREFUhEIhvPjii2hrm7xOnt1ux29/+1t4vV643W786le/gomXVGAFzFhpRBgaAIC7k5cMK3aB4YkTBUMFhyyFSqlRolvbCgAYfC2/J20ZK2X2Lpq0ese2BQBg6M3vPkqaMN1soSzjkIUxxgqFpibZQyAwMq/JyXOvA9uGX6fvreVKlkIUKaeVVRK9XMlSiHxv0fXciH36Ph2L3rUEowoHdAjjxB/3L+zFXC4AgGiSP2QxlBtwsPJqAEDfzyeWDDv86zdQkRiCGxas/MxlOR2TsdKIELQAANcpaefHlJ10HRBr5n4sTBoZhyyPPvoobr31VmzYsAEXX3zxpF+MscwpBAWcApWKe09zyFLsgiMUskShgsakkXk0bCFSJ+G+ffk9actYqaKm9+8AALxbPwQAqHLldyiqjVAli5pDFsYYKxj6egpZTJHReU1OKgQFxgR6ri3hAgBUX8mVLIUoUUMhi2qYQ5aCdJyu50KN01c4KAQFTlVQX5aRvyysL4vgpUqWhNW2oP1IJXQNhcGO3U+Nf2/kvyhwOdTwnpzPWZx7XJR6fsw2QNcBmlUcsjBpZBSy/OhHP8Idd9yBqqoqvP3221i3bh0cDgc6Oztx3XXXST1GxkqOV0MfIoFuDlmKXSpkCYCrWApdqCF5cnYsvydtGStVqab3HpjR9uUbAAD1sdMIe8Iyj2xmuhiFLBo7V2kzxlihMC2iG+assdF5T056NOXjXwegn7YfBMt/qgZaLkzv4uXCCpGxj0IW5bKZJ98DF9KSYZq9CwtZVH4KWRQ2+StZAGDJXTcCAFb49mD40BAAoGYfBS6JG3K7VFhKtubHav30c3Zs5OXCmDQyCll++tOf4pFHHsFDDz0EjUaDr33ta3jhhRfwxS9+EW63W+oxMlZy/Dr6EAn3cchS7MLOZMgicMhS6JTL6eQsdVLOGMsvQ89SP5ZO68WourAGblggIIHuV07KPLKZGeIUsugquJKFMcYKhXUxXctZ4UHD3scApD85mboOBIAz+qUQVAte4Z3JwNBKlSxWP1eyFKLqZKWzdd3Mk++266iSpal/14JeSx1wAQCUDtuC9iOVmkvqcER/MQQkcPS+p9Hz+hm0hw4gDgHL7pbnpvpszI85T4zCkaD91W9plWy/rLRl9Il99uxZbNpEqa1er4fXSxeAH/3oR/G73/1OutExVqJCRvoQifaPyDwSlm2RMQpZQkoOWQqddS3d6VSd58sPMVaq4m9QPxZX6xooBAV6DfSeHdmZv8GoUeSQhTHGCo2tuQwiqMF9S+TIvCYnU9eBAOCs5KXCCpVlKYUsjghXshSaoDOI2vhZAEDtlpkrWZZ8eC1iUKI23oO+Pd0Zv54uRDeqqxz5UckCAIPrKBRWP/ckTj1IVSwdls2wL3HM9rSsycb8WO8rdP7fq2yAsZLnYpg0MgpZqqur4XQ6AQCNjY3YvXs3AKCrqwuJREK60TFWoqJm+hBJjHAlS7GLuihkCav4g73Q1V5JdzrVxs8i6AzKPBrG2PnsXVTJol6/BgAwVknv2dCB/AxZxJgIE+gzwlDFIQtjjBUKpUYJt8I2/ucOy6a0JydT14EAEG3lkKVQla+i5cLKEmN8XVBgul85CQEJjCnK4Ggvn3E7Y6URxw0XAgBO/zbzJcMMERcAQFuZPyFL1ScoZFnZ/1dYXngUADC2+UbZxhO10M9Byvkx95t0/j9o4X4sTDoZhSxXXXUV/vKXvwAA7rjjDtx1111417vehQ9+8IN43/veJ+kAGStFop0+RBRODlmKXdRNE2gRDlkKnqO9HC6FDQIS6Nl2Su7hMMbOcW7T+5obKWSJNtNFlfJUflaf+Yf841+bajhkYYyxQuJWTYQlY5vT72Mglk08T3fxcknHxHLH2mRDEDoAwPABrmYpJKO7kxUOhjYoBMWs2w630JJh0dcyXzLMEKNKFl21LeN9SK39toswINTABD8ucr0KAGj4rDz9WICJ46KU82OxQ3T+763jfixMOhmFLI888gj+6Z/+CQDwuc99Dr/61a+wbNkyfOc738HPfvYzSQfIWEkqpw8RlYdDlmIXT4YsUbVB5pGwhVIICvSMLz+Un5O2jJWqc5veL3rXEgCAZiW9X60D+VnJ4h+gpcJiUEJn08k8GsYYY/Ph1U7cAT+vycmKiedVXM6VLIVKISgwrKJqFtcRDlkKSfgduo5zVc1d4aC+gtoolJ/IvJLFLFLIYqjJn0oWQSXgeNtE5coZVQsWX79UvgGl5sfc0s2Pac8mz/+XcCULk44qkycJggBBmMhnbrvtNtx2222SDYqxUqeqpA8RrY9DlmIn+gIAgKiWK1mKgauqHeh8A/jd7/Baz9D491UVZVj37x+ASpfRxy4rIPFIHHu//TRWfOEqmKpNcg+HJQ0+vRdtoKb3FyabCNs3tgMPAbW+/AxFA4MUsvhhgnWOOykZY4zll6DBAfjmPzmZug6MQoXGq7gZcyFz6WvR6O2C/0Sf3ENh86DqpMn32OK5Kxwab9sE/Bho87+NoDMIvV0/r9eKBqLjS8Oa6vInZAEA3Qe2Avf+AgBwetVWNMl4LjoxPyZdT5byETr/N17MlSxMOhlVsgDA9u3b8ZGPfAQbN25Eb28vAOB///d/sWPHDskGx1ip0tTQh4gxwI3vi53opZOqOIcsRSGWXDt7Y++fcPn/fXb816aHPoTdX/iNzKNjubD9fT/E+u/dhL03fkvuobBziHupH4urdc349+qvpIqW8sQIxk45ZRnXbELDyZBFyUuFMcZYoQmVURXD6VVb51xy6Fy6pip6nrYdaoM6K2NjueG31gIAwp09Mo+EpSvsCaPxzGsAAO3quSff6zY2YkCogRoxHP/t3nm/nrfXM/61pSG/QpaVX7oaAVBoZLldvqXCgIn5MUNQmpuQxZiIhvAJAEDlpVzJwqSTUcjypz/9Cddeey30ej3efvtthMNhAIDb7cb3vvc9SQfIWClKrcdpiLrlHQjLPn8yZNFxyFIMVtz3d9jedid21d08/uuEdiUAQNzONyGUgspX/0C/H3lV3oGwSc5veg8ApmoT+oU6AEDvK/m3ZFjE6QMABDlkYYyxgtPw4Ffx6pq7sfqP35zX81Z/+Sq8uuYr8Hzr/iyNjOVKuL4FAKA4dVLmkbB07frAfWiMdWFQqMbKr1w75/YKQYGuGloybOzp+S8Z5uul+R4/DHkXqhrKDTjw1f8Pr177b7jwrivlHUsjLaNojkgTsvTtPgsdwghDg7pNTZLskzEgw5Dl3nvvxcMPP4xf/OIXUKsnDgSbN2/Gvn37JBscY6VKX2MDAJjiLlnHwXIgGbKIBg5ZikHFyipcduyX2Njz6Piv0S9+mx47+5bMo2PZNrCvD8sDdBdbS+AgIr6IzCNiwOSm97XvvWTSYwMWunvN9UYehiyjVMkSVHPIwhhjhab52jZs2Xsfylrs83qexqTBlr0/wJqvvytLI2O5olxG5ximvvw7x2BT9bx+ButeuBcAcPLT98Fcm975V3gNhSz6/bvm/Zr+XhcAwCPY5v3cXNjw7+/Hlue+Pq9qvGwwNVElizUmTcgyuJ3ek93aVig1Skn2yRiQYchy7NgxXH755VO+b7Va4XK5FjomxkqesZZKRS0JNxJiQubRsGxSBClkAYcsRav+JrpzviXYgZArJPNoWDadePCZ8a+1iODUEx0yjoalnNv0vunqyevbe2tpKYjY4fybAIk6KWSJaDhkYYwxxgqNbT2dY1S787P3G5us55a7YEAQ+61XYNNDH0r7eY4bNgIAFg/unPfcTWiQKlkCqvxaKizfWBdTyGKBV5Kb2Hz76Lx/xM5LhTFpZRSyVFdX4+TJqSWPO3bswOLFixc8KMZKnbnBBgBQI4agMyjvYFhWCamQxcghS7Gq29iIUYUDGkTR+cRBuYfDskjz1ycn/Xn42fmvzcykN/g0/Rw6rRdDUE0+9RWX0MWV9nT+TYDEXRSyRLUmmUfCGGOMsfmq3ULnGHXxbgRGAjKPhs1m773PYUP/Y4hBCdN//2RelRttt12MMDSoSAzj7Cun5vW64UEXACCg4ZBlNtYmG+LJ6euxkxJUsxyj8/5QIze9Z9LKKGT55Cc/iS996UvYs2cPFAoF+vr68Jvf/AZf+cpX8JnPfEbqMTJWckzVpvEPEc9Zl7yDYVmlClHIojBxyFKsFIICXXaqZhl5npcMK1ZBZxCrBl4AALxZ/h765lv8884HE03vL5nymPFCmgCxj+ZfJYvoToYseq5kYYwxxgqNfYkDY4oyAED3yydkHg2bSdgTRvl3vgAA2LHmS2i9acW8nq+1aHHMTOeY3X+c35JhsVGqZAnpbPN6XqkRVAJcyfeSp2vhIYsxuYRfakk/xqSSUcjy9a9/HR/+8Idx9dVXw+fz4fLLL8cnPvEJfOYzn8EnPvEJqcfIWMlRCAp4FRYAgL/PLfNoWDapwhSyCGYOWYqZry3ZbHsfT7oXq44fvQwDguhVNiD20b8DAJRzH568kGp6r9m4ZspjlZfRHWwNoRMQY2JOxzUnL4UsooFDFsYYY6zQKAQFeox0nuHcnX83czCy6+YfYFH0JAaEGlz8+L9ktA9nGy0ZJm7fOa/nxZ001xPVcyXLXNzqcgCA/+zCQ5ZqF1WyWNdxJQuTVkYhi0KhwD/90z/B6XSio6MDu3fvxvDwMKxWK5qbm6UeI2Mlyau0AQCCAxyyFDN1hEIWpYVDlmKmu5TubqrgSfeiFfwDLRV2aumNqP8b+nm3Bg4g7AnLOaySFwvF0OrbDwCouXFqyFK3eREiUMOAIPrf7Mnx6Obg9wEARCOHLIwxxlghclfSnfLhA/m3LCkDenacxroXvwsA6PzsfbDUWzLaj+6qTQCAqs75hSyJMRcAIGbkkGUuPi31ZQn1LixkCTqDqI2fBTCxpB9jUplXyBIOh/GNb3wDl1xyCTZv3oxnnnkGy5cvx6FDh9De3o4HH3wQd911V7bGylhJSTU/Cw245B0IyypNlEIWlZVDlmJWfxNN7rYGDyLkCsk8Gia1hJjAkmNPAQD0t25F/aWLMKYooz48f+mQeXSlrfOpw9AjNG3TewBQ6VTo1rQAAAa25dcEiOCnShaYOWRhjDHGClGshe6UV3VxJUs+6rmVmt2/bduCjQ/elvF+mj9MlSytoQ54ejzpP9FDN9SKFlvGr10qggYKWSIDCwtZul85CQEJuBQ2ONrLpRgaY+PmFbLcc889+NnPfoZFixahq6sLt9xyCz71qU/h/vvvx3333Yeuri78wz/8Q7bGylhJCWopZIkMcyVLMdPGKGRR2zhkKWZ1GxsxqnBAjRg6nzgo93CYxI7+7m3UiL3wwYhVX7wSCkGBzjKqZhl+jquX5DT4DP37n7KtmdL0PmXETnex+fbl1wSIKkAhi8LMje8ZY4yxQqRdRecYtsH8OsdgwJvfeRYb+h9HFCqYf/3jeTW7P1/VhTXoVi2CEiJO/vaNtJ+n9CbneqxcyTKXiJlCFnFwZEH7GU0u3ddjaF/Qz5yx6cwrZPnjH/+I//mf/8Gjjz6Kv/71r4jH44jFYnjnnXdw2223QalUZmucjJWcsN4GYKIZGitO2jiFLJoyDlmKmUJQoMtO1Swjz/Oke7EZ/CUtFdZR8y7obDoAgDfVh+ct/nnLKdX03t0ydamwlGB9cqmAY/lVyaIKUcgiWLmShTHGGCtEjk1UyVIfOIaEmJB5NCwl5Aqh8l+p2f3rGTS7n87ZOloyzPNc+kuGqf0uAIDCblvw6xe7uC1ZdTK6sEqW8AEKWVxVvFQYk968Qpaenh6sWUMXqStXroRWq8Vdd90FhYLTP8akFjXQ3Qyi0yXvQFhW6UUKWbR2DlmKna+dKhuwjyfdi03lG7RUWPTarePf026i86Vy7sMjq9ma3qcol9MEiLE3v+4y1YQpZFGWccjCGGOMFaKGK2mpUlvChdFjC7sDn0ln9wd+gKbYKfQLtVjzl8ya3Z8vto5CFuPBXWk/RxOkG2pVdq5kmZODKlmU7oWFLKpTdFNVbDE3vWfSm1fIEo/HodFoxv+sUqlgMvESBoxlQ9xkoy/cXMlSzAwJCll0Dg5Zip1uM03yVp7dK/NImJQG9vVheYB+pu13XT/+/fE+PIEDCHvCsoyt1M3V9D7FcgndyVbpzq+QRRuhxvdqDlkYY4yxgqS369GjbAQA9L2SXxWzpapnx2msf4ma3Xd97j6Ya6U5z6q8ifqytI3sghgT03qOLkxzPepyDlnmIlRSyKLxLixksSaX7kst5ceYlFTz2TiRSODjH/84tFotACAUCuHTn/40jMbJk4N//vOfpRshYyUqYaEPWoXHJe9AWNbEI3HoQU3QOWQpfvU3rQH+A2gJdiDkCo0vK8UK2/EHnkY1gA7jOqxcXT3+/fpLF2FMUYayxBiO/KUDyz4y8yQ/y47Opw6jDSG4YZm26X1K7ZXJpTxip/PqvamLUSWLtpxDFsYYY6xQDVrbUe88C/ebxwFcKvdwSl7vLV9GPUJ423YlNj7wQcn2u+Tm1fB/xAAr3Dj5zFG0vnf5nM8xRF0AAF21TbJxFCtNNYUsBv/CKsLq/BR2ppbyY0xK86pk+djHPobKykpYrVZYrVZ85CMfQW1t7fifU78YYxJIvpdUPq5kKVaBkcD414YKDlmKXd3GRowqHFAjhs4nDso9HCYR7V+pH8vIhq2Tvq8QFOgsoyXihp/jJcPkkGp632m7eMam9wBQvrwSblggIIGebadyNbw5GeLJkMXBVeOMMcZYofLV0R3z8cNcySK3N7/9DNYPPJFsdv+QpI3PVToVjtvWAQD6/5ReXxZjjOZ6dFU8jzoXXR2FLKZw5pUszhOjsCecAID6LTPfgMVYpuZVyfJf//Vf2RoHY+w8SocNAKAOcMhSrIIjfpgBiFBAb9fLPRyWZQpBgS77JXCMPo+R598CPrZW7iGxedr73efhe2HyOsvrBl8EANR8auuU7b1ta4DdLwBvZTdkOf6ng+j7yWOAmN7SBFIp/+h1WHnn+py+5nyk0/QeoPdmr6EN1sBeDH7539Bz/8RFl6p1ETY/8jFJL8LTZRQpZNFVcCULY4wxVrDa2oGDgK47v5YlLTUhVwiV934RAPD6JV/GFgma3Z/PvXwTsPNVYNdOAJ+YdduEmIA14QIAGGs5ZJmLaRE1vrfEMg9Zel8+BjuAXmUD6soNEo2MsQnzClkYY7mjctAHrTbkkncgLGuCI9SPJQADTDJM4LHc87WvAXY+D8Vb3Jel0IwcGcYF/3wj1IhNeaxH2Yi2D6ye8n3tpjXAbqDiTHZ/3rG/vQNbArmvlhnY/ghwZ1/OXzddjk76d5+t6X3KaO1K4ORebD79G+D0OQ9sAzo2LMXKT2zIziBnIMZEmECfEYYqDlkYY4yxQmW8qA34E1AxypUsctr/b89iQ+wUBoQarHninqy8hvFdm4CdQO2ZXXNuG3KFoEcUAGBusGVlPMXE0kyVLLbEGMSYOGuV+kw8+zsBAIOWJaiTdHSMEQ5ZGMtTmgoKWfQRrmQpVmEnTaAFFUbwYjClQbd5DbATqOjm5aMKzdH7nsaliKFX2YCTy86pWlEIKPvMbaifJiitv2kN8EOgJXgQYU8YWotW8nHFI3EsDnQAALYvuQOiNvtVcYpEApcf+hmqxX6MHhuBo7086685X7FQDC3+dwAAte+9ZM7tF/3nPXj1bjsU4dDE944+h6ZYJ5yvHQRyHLL4h6jSEQBMNRyyMMYYY4Wq+grq/dAQOYl4JA6lRinziEpT+PgZAEBn3eXYJFGz+/O13L4B+DbQEjlKS1Mtccy4rbfHDT1oVQtTNc8GzMW22A4AUELE2BkXylrs895HbMwDAIjobVIOjbFxHLIwlqdSzc8MUQ5ZitV4yKLkfiylov6mNcB/AC3BjrxqsM3mpnzuKQDAic13YMu2b6f1nPpLF8GpsMOecOLIXzqw7CNzV1TMV9/us2hAGCFosanjFzm7cO9RPY36+Fn0vXo8L0OWc5veN17ZMuf2DZc3o2HvfZO+t+2iL6Np/4MQZVhD3T/ghRlADEo+TjDGGGMFrGZdA0LQQocwzu48g8Yti+UeUklK9FL1daSiNmuvYV/iQKemHYsjx3DqN7th/9YNM27r63GhEoBHYYUtg6qMUqMxaeCBGRZ44To5klHIkvDS/EtMx/MvLDv4ncxYntJXUyWLOe6SdyAsa6Iu+pAPc8hSMuo2NmJU4YAaMXQ+cVDu4bA0hT1hrOx9HgBQ+Xc3pv08haBAVxkFK8PPZad6aXA7re/drW3N6Z2Rg1Zq4up+Mz/XF0+36f2s2unvqO/J/d8xMEj9WPwwydIPhjHGGGPSUGqU6NYuAQAMvsZLhslFNdJPX9RkL2QBgN6mTQAA/4uzLxkW6KebaX0C92NJl1tFlUG+Mxn2ZfHT/IvIIQvLEg5ZGMtTqXU5zfBCjOW2mTHLjfGQRcUf8qVCISjQZaeli0ae474shaLjJ9tghg+DQjWW3j6/ahRvW3L7LPXh8e+ji/VRe1tW9j8TXy29XuxQfk4WiG/Sv/dcTe9nY76Y/o6Vztz/HUPDyZBFyUuFMcYYY4Vu1EHnFIH9+XlzSikwuKiSRd1Yk9XXSWzYCACwHto563bhIQpZ/GoOWdLl1VD1fLBngSGLnudfWHZwyMJYnjLX04etgAS8fV6ZR8OyIeamD/mIhj/kS4mvnSZ9Ffu4L0uh8P3uSQDAsSU3zrsqQruJft4VZ7L08z5BF+uhpvbs7H8mbfR6urP5OVng6KJ/b82mufuxzCS1hnp9tBPRQFSScaUrPEKf+0EOWRhjjLGCF2qkkEVxPD9vTikFVj9Vshhas1vJUnszVbK0ufYgForNuF14yAUACGptWR1PMQnoqZIl0p9ZyCIEaf4FRp5/YdnBIQtjeUpn0yEMDQDA2+2SdzAsK+LJNUGjHLKUFN3m5KR7N4cshSAhJtBymEIW7c1b59h6qob30SR/S/Agwp6wpGMDAFMvXawrl+W2ksV4Eb2eYzT/JgsmNb3fmnklS/WaOgSghxox9Gzvkmp4aYmO+QAAQTWHLIwxxlihU62gGzdMffl5c0opKI9QJYt1aXYrWRbfsAxuWGFEACcfm3l56NgoVbKEdVzJkq6wiUKW2BCHLCw/ccjCWB7zKGwAJtbrZMUl1XgtruUP+VJSfxNN+rYEOxByhWQeDZvLicc6UB8/gyB0WHXXNfN+ft2mJjgVdmgQRedfOiQfX5WbLtZt63NbyVJ1Ob1eQ/gk4pF4Tl97Lp1PHYZ+Hk3vZyKoBHTrKEwafj23kyJRJ1WyRDQcsjDGGGOFzrqWzieqPfl3c0opCIwEYAXNqZSvzm4li6AScMKxAQAw+NjMS4aJoy4AQNTAIUu6YlYKWTA8ktHzlWGaf1GYeP6FZQeHLIzlMZ+KPnCD/S55B8KyIuFLhizceK2k1G1sxIiiHGrE0PnEzHc3sfzQ93OqYjlYeTUM5YZ5P18hKNBVRsHa8LPS9mUJjARQHz8LAKjdkttKltoNjQhDAx3C6Nt9NqevPZfBp+nfeUFN75Oc5ck11N/JbcgSd1HIEtWacvq6jDHGGJNe3VV0c0ptvAf+Ib/Moyk9wwdoqTAfjDDXZv8GFt9qWjJM9cYsfVncFPrETbasj6dYJOwUsghjmVWyqJIhi9LC8y8sOzhkYSyPBZNN0FJN0ViR4cZrJUkhKHDaTpPuI89lpxk6k45j11MAgNA1818qLMXbllyySuI+PD2vngQAOBV2ONrLJd33XJQaJbq1rQCAwe35tfSFuJf+nd2tmfdjSQkvokkRIcdrqIvuZMii50oWxhhjrNDZlzjgVNgBTJy/sdxxHaalwkbUNVAIiqy/nuU9FLI09O6acRuFh+Z4EhauZPn/s3fn8XHV9f7H37NPJvu+d29TukBZS0tZVJQLwkWuV7zg9Xq9P0UFF9SrV1T0uuCCCwhyXa+4IahXQGRHVoHashToQvfSJs2+JzOZTGbm/P74JimhSZNMZjJLXs/HgwfpzDnf821y0jnn+z6f73eqbKXmfsfVF1vI4g4RsiCxCFmAFDbgLZAkDbUTsmQiW8B8yFs+PuTnmv46M+hui/OgO+KrbXurVvb/XZK09Oq3x9yOZ4MZ7C89GN+fd8dGE24czp7dKpYR7UUmgPBvSa2QZXTR+3Wxr8cywrnSfG9zm2f579hnQpaoj5AFAIBMcDjbXDd1bGTKsNnm32NClm5fYqcKG7Hk8tMUlU3zwgfU+krzuNs4+rvNFwUFs9KnTOCqMJUsXn+MIcuQGX9x5jP+gsQgZAFSWCjLPNUQbu9ObkeQECy8Nnd5zzCDv6X1hCypbNcN98suS69mnajKU2tibqd2dB2erRrsHYxX9zT4irlJ7ymf3fVYRgTnDYc7s1zlcSxDgaG4LHo/onB4rZvK2Z5D3W8Wvo9mE7IAAJAJesrNdVNoa2o9nDIXDB0y04UF8hK76P2IvJo87fGuliTtv238ahZXwDxIay+ikmWqPFUmZMkOxhayeCJm/MVVwPgLEoOQBUhh4ewCSZLVTSVLJnIEWXhtrqq9xFQ2LB7YpmB3MMm9wUScD5j1WFpOjX2qMEmqXj9fnbYiuTWkfXfHbx0e535zkx5elJxKFscKE0DkHE6dwYJ4LXo/ovqcpZKkimiT+hr7ZtzeVNn9w8fKJWQBACATjFyvOfenzsMpc4V12FSyhEpnp5JFkloWmSnDgo+Nvy6LJ2jGeJzFhCxT5as1IUteKLaF773DIYu7kPEXJAYhC5DCIrnDH7g9hCyZyDG88Jotlw/5uaZqba3abSVyKax9d72S7O5gHIO9g1rZ+LAkqez/zSxksdltOlA4vA7PQ/GrXipoMTfpntXJCVnyTzXHLe9JncGC1gfM93d/wckzXvRekgoWFqrNVipJanhs9sIkZ8CELLZcFr4HACATeE4wD6cUtKbOwylzhbPdVLKocvZCFvsZ6yRJRbvGD1myBrslSZ6yglnqUfrLXWBClsJoh6yoNe39s6Jm/MVTxPgLEoOQBUhlw4ug2fu6k9sPJIRrZOE1QpY5x2a36bUiM+je8TBThqWirTc/oVz1q9leqeWXnzTj9vrqhhdhj9M6PFbUUk3AhBvF65MzXVjVOSZkqYkc0kDnQFL68EZHFr2f+VRhIxpzzfe3a9MshixBE7LY86lkAQAgExSfbq6bav27YhogRux83aaSxTVvdqYLk6Tad5tKlmV9L4w7XXD2kHmQ1lNGJctUFS41C997FJK/1T/t/X2W2cdbzPgLEoOQBUhhtsICSZLTTyVLJnKHWHhtLuuvM4PAtjgNumN8T3/gl3r+uoemvZ//9/dKknYvuzAuFRGekXV4Dsbn592xq10FVreisqn2TUvi0uZ0FdeVqMtWKEmqf2xPUvrwRvFc9H5E78gc6ttmL2RxD5qQxVFIyAIAQCaofdMSRWVTvnrU/mrbrBzTilp66rIf6eWbn5qV48Wbv9WvJ879uhqefm1G7eT7TcjiWzJ7lSzz3rRYbbZSeTWoPX/YctT7uZFu06dKQpap8pX4FJRHktS9b3rrsoSDYXkUkiRllTD+gsQgZAFSmGN4ETR3gJAlE3nCLLw2l3lHBt3rCVkS5dXfvqAN//t+rfjiJQq0B6a8nxW1tHiHWY/F808XxqUvtRebn/figa3jPs02XY1PmAH/Rsc8ZRVlzbi9WNjsNh32mQCiY2Pyp77wt/q11G9uYqsvPiVu7UaWmEoW14HZmxbNEzIhi4uQBQCAjJBVlKVGxzxJUuPjs3NNseW7j+qsO65U9SfeqXAwPCvHjKfnLv2Oznn0WjW+82MzaqckZKYLy18+e5UsNrtN+8tOlyR1PPjcmPei4ahy1StJyqkpmLU+pTub3aYuu5kyrO/A9NZleX3li6+U8RckBiELkMJcJSZk8Qa7k9sRJIQnQsgyl9VeYgaBFw9sU7A7mOTeZKaWn/5ZkuTTgLbe8Ncp77fnrm2qiRzUgLxa/clz49KX6vXz1WkrkltD2nf31hm317PZ3Jy35CdnPZYR3eUmgBjcmvyQZdsNj8ijkA46F8Vl0fsRWSeY73Fh2+z9Hb3hfkmSp4SQBQCATNFcYK6bep+fnWuKvt+aa+ESq13bf75xVo4ZTxWbTf9Xt/51Wg9MvZ6/1a98mYdWS46fvUoWSRpYsMJ8sXvsz7u/uV92mSnjcmuoZJmOPrcJWQL106tkGWg3Yy8R2eXJ88S9X4BEyAKkNE95gSQpa4hKlkyUFWHhtbmsam2t2m0lcimsfXe9kuzuZKSK5/8y+vXgn/5yjC3HavyJ2XZr2VvkK/HFpS82u037i0yw1v7QzKuXIq+am7X+6uSsxzIivMgEEM59s1flMZHQ8M/4tVUXyWa3xa3dkjPM97g2MHtzqPsippKFkAUAgMzhrzLXTSPXcYn0+spsSer69dSvhVNB46Z6LR94SZKUpeC0Hph6vfatpoqlX9nKrZrd6yrHCnMNmXN47HVyX323JGlQbnkLvLPap3Tn95p1WQYbpxeyBDvM2Itf2XG9TwBej5AFSGHecvNUQ064O7kdQUJkWYQsc5nNbtNrRWYKqY6HmTIs3pqeaxi9MZOkuj33KhqOTmnf4o3mJjR47kVx7VP/suF1QuKwDo/30PDN+bLkVrJ4jjc3j/mtya1kiYajqtt3nyQp97L4TPE2ouasRYrIrlz1q/WV5ri2PZHsqAlZvCU5s3I8AAAwC+rMdVPWocQ/nDJSmT2i9uX0Cln2/uC+MX8evPPemNrpftWELO2uylkfXM8/1Vynl/eMvU72N5qHaHtt+Qz4T1Mw21SyDDVPL2QZ7DRjLwN2xl6QOIQsQArLri6QJOVGqWTJNFbUkk+m5JmF1+au/joz6G6Lw6A7xtpzg7kR2+E7WX3KUXm0WTt/9+Kk+7Vtb9XK/k2SpKWfjO9gvWdkHZ6Dz8+4rZJOc3Oec3JyK1mK15mbxxr/7FV5jGfHr55TWbRFPcrTqivPimvbnjyPGpwLJElNTyR+UCQajipH5kbQV04lCwAAmSLnJHPdVNKZ+IdTGn9qroVfztugITm1OLRTBx/dm/DjxkvWX00otKXgTZKkZbun/sDU6/n3mEXvu32zO1WYJFW/2VynV0UOaaBzYPT1YIsZ3/E7mSpsuobyTMhitccWsgQJWZBAhCxACsupNh+6Pg0o1B9Kcm8QTwOdA6PzsBKyzF3eDWb6qLJDMx90x1gjN2atG96pbdXnma//d/In+HZ+7z7ZZenVrJNUeUp1XPtUe7EJWRYPbNNg72DM7URCEdUOmpvk8jOTW8lSc84SSVKh1aXOPdO72Ymn9lvNz3ZHzXly57jj3n5r4ezNod7f3D/6dU4lIQsAAJli5LqtNrQ34QvRFz9rro163v4ebS00D6C89sPYqkFmm7/Vr9Vtj0qSvD/8rvqUo4po05QemHqjoUOmkiWQN3uL3o8oWlqsLluh7LJU//iRgCvY3G365CqY9T6lu2ihCVlsHdNb+H6oezhkcTL2gsQhZAFSWG513ujXvfVUs2SSQJt/9Ot4rfmA9FP7DjPovii4XcHuYJJ7kzlef2NW/eGLFDnfTPtV/tzkIYvrIXPz2XJafKcKk6Tq9fPVYSuWW0Pad/fWmNs5/OxBeRRSUB5VnlYbxx5On6/EpwbHPNOvx5K3LkvlC+ZnG3l7/H9ukhSoNoMi0Z2JD1kCrSZkCcvBPN0AAGSQqtPnKSiP3BrS4WcPTr5DjExl9t8lmcrsvrPN9VHuk+kxZdi2G/8qrwZV71yg5ZedOK0Hpt7IOmwqWUKls1/JYrPbdNhnriE7nj1ynTzUbsZ2gh4qWaatxIQszt7pPdw1ErKECFmQQIQsQApzep3qk5mPfWTeTmSGkYXXBuSVw+1Icm+QLFVra9VuK5FLYe2765VkdydjvP7GbMnFK7X8UxcoKpuOG9iipucaJtxvsHdQKxsfliSV/Ud8pwqTzI3WgeF1eNofin2KuNanzUB/vWdpSvz70ZJvbh57nkvOuiwNzxxUXfAVRWTXik9fkJBj2JabShZffeKDpECLWY+l35bLPN0AAGQQu9Oues9SSVLr3xJ3TbHrhvuHK7NPVOWpNVrwMROyrO56Sj2HUn9cIfQnE6bsX3GRbHbbtB6YeiNXmwlZVDn7IYskdZeba8jBrUeuk8Od5mcQyiJkmS5nuVn43tM/vZAl0jscsrgJWZA4hCxAiuu3mw/eQFPqXwxh6kZCloCND/m5zGa36bXhQfeOh1mXJV7eeGNWclyptuecLunIWi3j2XrzE8pVv5rtlVp++UkJ6Vv/MvPz1guxTxHnf9HclHcUJ3eqsBH91ebmMbIjOZUs+35gfqbb8taraGlxQo4xMod6aVfig6RgmwlZAnYWvQcAINO0l5jrpsBLibumcD5groVbTjXhxPw3L9Y+93FyKazt33swYceNh2g4qrq95tou5zLT/7qrz5/SA1Pjyeox04W55s3+dGGSFF5kriGd+45cJ1ud3ZKkoeyCJPQovXmqzLW+byC2kCVMyIIEImQBUpzfZUKWgabu5HYEcTWy8NoAC6/Nef3LzbosthkMuuOIaDiqZXvvk3TkxkySOtabr0fWahmP//fmvd3LLpTdmZhLJM8ZJmQpPTSDUG2PuSkPzk/uovejlpqbR++h5FSyZD9mfm5dZyRmqjBJqjzHfK9rhvZrKDCUsONI0mC7CVkGHKzHAgBAphmcZ66bbHsSc900UWV2/Qnma+ue1J4ybOdtL6gs2qI+5WjVlWYtmdKVZVN6YGo8+X5TyeJbkpxKFs/x5hoyv/V1P+8e8wBtJJdKlunKqjEhS25oeiFLtH84ZPEw/oLEIWQBUlzAXSBJCrVRyZJJQl3mQ37QwYf8XOcdHnQvq6eSJR523vaCyqPNY27MJLM2iyStbntU/lb/UftZUUuLd5ibTu8/J26wvvZi8/NePLBNg72DMbWRe9g8CedckRqVLNknmn4Ud85+yNLX2KfVHY9LkmqvTNzPrfzEKvnlk0thNfztQMKOI0mhjuGQxUXIAgBApnGuNIPuOY2JqQAeqcxusVdo+XtOHn298N/MddKKg/crHAwn5NjxMLLuyrbq8+TJ84y+PvLAlPfR6YUsJSETsuQvT04lS/E6c51c7T9ynWzv7TZf5BfMfofSXM58E7IUhKe38L2GQ5ZIFuMvSBxCFiDFDXrN0w0ji6MhM4wsvDbIwmtzXu07zM3PouB2BbuDSe5N+pvoxmzJxStV71wgrwa17ca/HrXfnju3qiZySAPyatUn3pKw/lWvn68OW7HcGtK+u7fG1EZ5r7lJyz8tNSpZys8y/agd3KtIKDKrx97+g7/Ko5AOOhdr0QXLE3Ycu9Ou+ixzk9z2TGLDpHC3Wfg+5CZkAQAg0+Sfaq4nKnoTcz0xUpm9a+nYyuyVH1inTluRCq0ubf/Zswk5djxUPG/6P7IOy4jRB6ZaH1WgPTCltvytfuWrV5JUcnxyKllqzlkiSSqyOtWxywQDTr8Z27EVUMkyXfmLhitZ1K9Qf2jqO/rN+ItFyIIEImQBUlzIVyBJigzP24nMEO4ZXnjNxYf8XFe1tlbtthK5FNa+u15JdnfS3kQ3Zja7TftXmNcG7zz6CbjGn5rXtpadK1+JL2H9s9ltOjC8Dk/7g9OfIi7QHlB1pF6SVP2m1KhkqTp9noLyyKtBNf790Kwee+gu8/N+bdWFCV8kvrPEfL8DWxK79kyk21SyhLyELAAAZJqat5iHU6oiDeNWV8+Eqcw217Sed469FnZ6ndqx4AJJUtdvplcNMlsaN9Vr+cBLisqm5Z+6YMx7Iw9MZSmorTcc/cDUeNq3mvVY+pWt3KrkXFf5SnxqcMyTJDU+YYI114AJWRxFhCzTlT+/QJHhoeyuvVOfMswWGA5ZfIy/IHEIWYAUF8ke/uDtppIlk4wsvDbEwmtzns1u02sjg+4PsS7LTBzrxkx63eKZe+5VNBwd817xRjNYH3xr4qacGtG/bHjqhhenP0Vc/WN7JEkdtuKELfI+XQ63Q/Ue85Rey1OJDSBeLxqOavnw+ju5lyf+5xaab0IW+97EVrJEe0zIEvay8D0AAJmmcHGROmzmGq7h8T1xbXvPXdtUEzmoAXm1+pPnHvW+/WJzvVT7cmquy7L3RhP+bMtdp5LjSse8N+aBqT9Nrf/dr5qQpd1VmfCHcY6lJd9cQ3ZvMtfJ3mC3JMlVWpCkHqUvu9OuLluRJKn3wNRDFntwuPopm/EXJA4hC5DiosOLodl6upPbEcRVtI+F13BE//JTJEn2GAbdccSxbswkadWVZ6lPOSqPNmvnbUe+123bW7Wyf5MkaenVb094Pz3D6/CUHpr+z7vz72aAvzE7NapYRnQUmf74t8zeuiw7frlZpVarepSnVR85M+HHc60yT57mNSU4SOozIUvURyULAACZaOQ6ruPZ+F5TNP7EhA9by94ybmX2yk+epyE5tTi0Uwcf3RvXY8dD1qOm/53rx394JudfLpQ0/gNT4/HvMeuxdPuSM1XYiP5qcw0ZedVcJ/tC5gFadymVLLHodZmQ0n9w6uuyOIJm/MWWw/gLEseZ7A4AmERBgSTJ3k8lSyaxhhdeC3v5kIfkPeNk6RmprJ6QJRwM6+lz/1vZbztDp37p/GntO9mNmSfPoxerz9O6w3+S48Mf1N+vWShJyu5rUaksvZp1ko47pXpmf4EpqH3HKdJ3pSUDW/X3qkumtW9x1z5JUk95aoUswXnLpCZJu2c+WBDqD2nj+k/L095wzO0Ku/ZLkrbX/oPW57hnfNzJFJy2TPqxVNGX4CCpfzhkySZkAQAgE3VX1El7Nyq0Lb7XFKOV2eeOfy2cPy9fLxaerZO6HtWBm/+i+W/5ZFyPPxP+Vr9Wtz0mSar+0IXjbrPqqrPV93nzwNSO217Qivedesw2QwdNyBLIS86i96OWLpO2St6D5jrZFzZjO95yQpZY9HuKpZA0cHjqlSzOQTP+Ys9l/AWJQ8gCpDh7ofngdfkJWTLK8MJrURZeg6SafzxJul5aFNyuocCQXD5XsruUNJuvuVPnPHOd2p8tUeRzzXK4HVPa7/U3ZjUfmXjqKOuSd0o//JPqgi9LTS+Pea9lwzt1XOxdn7LqdfN02FGr6ki9Tm+6O6Y2IiecFN9OzZBzzUppk1Ry4LkZt7XlGw/o7K0/nPoO73znjI85FTVvHl6oNtqk3oZe5dXkJeQ49oBZ+F65hCwAAGSiyKJl0l7JeSB+IUuwO6gV/ZslSYs/OvGDSr1nnC/d+6i8m5+SlDohy7Yb/6q1GlS9c4GWXLxy3G08eR69UHuB1tf/Qb2f/5b0vj8du9FGM11YqDS5lSzZJ9VJd0rFnebnnRftNq9XFySvU2lswFcs9UlDLZ1T3scVMuMvjjzGX5A4hCxAihtZDM0z0J3cjiC+RhZeI2SBpKq1tQooSz4N6LVnXtOCty5NdpeSxrr7HklSidWurbdu0uoPrZ/SfiM3ZoecC7X4ohUTbnf6De/WRq9bQ01jn3xy5Ofo9Ov+KfaOT4PNbtPgXx7RU7c9GdP+zqI8nf716VXAJNrSD58r/URa6X9Ora80q+z4ipjbGnjxVUnSK7nr1f2P7zvmtu6qEq371ux8L/LnF6jNVqZSq1WHn9ijvH89OSHHcQZMJYstj5AFAIBM5D2hTnpYKmyN33Rh9Y/v1VJF1aM8Va2tnXC73PWrpXul0o7ZW0dvKkLD66zsX3GRao+xfkrpD65V+J/+pNMb79Tz1z2kU75w3oTbutpMJYsqkxuylJ9pHtSpHdyrYHdQ2TLrg+RUU8kSi6HsAklStHPqDyK7hsz4izOf8RckDiELkOLcZQWSJO8glSyZxD4csrDwGiSzgF+9d5nqgi+r9W+75mzIEg6GteLg/aN/7vjlX6QphiwjN2YHVl6kece4MbM77Vr3ndmpfDiWRefXadH5dcnuRtyUr6nU9uxTtdL/nHZ9/z6V/fL/xdyWY795yq/zlPN0zm+viFcX46Ixt06lva3q2rRbSlTIEjQhiz2Phe8BAMhExevMoHuNf7esqBWXRdk7Nu7WUkkN2XVaeYz2ys8y15+1ob2KhCJTrhpPpGg4qrq9Zm3FnMsmrkiXpKWXrNITJ31c57x4g4q/8jENfmyrPHmecbf1dZuQxTUvudOFVZ0+T0F55NWgdvx5q0YeB8urJWSJRSR7+PvW3T3lfTxhM/7iKmD8BYnDwvdAivOUmQ8Q3xAhSyYZWXiNkAUjOkvMzVbg5dlbODzVbP/5RhVaXaN/rt5y75T2G3Nj9i/jz+GMxGtba26K3Q/9ZUbt5Deb3wH3qtRad0aSeitMn0JbE/f0p3vQhCyOQipZAADIRLVvWqKobMpXj9p3tMalzeAr5vqpu/TY109Va2s1IK/cGtLhZw/G5dgz9epvnldZtEW9ytXqj5496fYn/fm/1WKv0MKhPdr4z9+bcLu8gJkuzLckuZUsDrdD9Z4lkqS2B8zUuv3KltPLc++xsPLMGJmtd+pjZN4IIQsSj5AFSHG+qgJJUk6kO6n9QHw5WHgNbzC4wDxVZo/DwuHpquvXZnB+c9nbFZZDSwe3qeHp1ybdb7o3ZkiMig+YgGtV8yMKdgdjbqeq3/wOFK5NvZAlstj0yfVa4sJQT8iELC5CFgAAMpK3wKvDzvmSpMYn4nNN4dhnrp+GFh27UtpU0Juq+ZanUuO+o+0X5h5ge/V5cue4J90+ryZPez9swpXTHvm6Gp4ZPywqCZlKlvzlSV74XlJHkbmGdDxv1s3ps1PFErOCAkmSo797yruMhCyeIsZfkDiELECKy64yH755Vo+sqJXk3iBenCEzD6udhdcwzLnSXHjnNs/dSpbal80NVvjyf9O2/DMkSftunLwqYro3ZkiMunevUaOjRtkKaOsPHoupja59nSqx2iVJtW9JvZAla40ZuCiK4xzqRx0jbEIWTwkhCwAAmaol31zn9D4Xn2uK/JapVwJ3FA9X0L+UGvcdlc+ba/nIBceeKuz11t98mV7KP1s+Dajh0k8d9b6/1a989UqSSo5PbiWLJAXnm2vIynoTsvhdBUnsTXqzD69b7ApMvZLFZ5mQxVvM+AsSh5AFSHEji6G5FNZA50CSe4N4cYfMh7wj15fkniBVFJxqbnYqe1PjibLZdvDRvVoc2qkhObXyk+epe4O5ycp5fPKQpeIFM1XYdG7MEH82u01760w1y8AfYpsy7PDj5ma/yV6lnIrUW5OkZP3wHOoDuxP24ENWpF8SIQsAAJnMX20G3SOvxifoqB6uBC5eP/maf4PDA/62FKigb9xUr7rgy4rKpuWfPH/K+9nsNmXf+kOF5dDpjXfq+a8/OOb99q1mqrB+ZSu3KvnXVI7jzDXkwtBOSdKAi0qWWLlKCiRJnuDUQpZoOKpsmYdcCVmQSIQsQIrLqchRZPhXtfdQd3I7g7hxjyy8ls+HPIyaN5sL74pok/oa+5Lcm9l34GYzKL+18Gzlz8vXvKtMYLK68wn1NvROuF/jpnotH3hJEdl13KcvmJW+YmJZl5qf25Jd98YUQnRvNgMNzXmTDxAkQ+05ixWRXbnqV8tLTQk5RnbU/P57S1IvZAIAAHGyzFz7Z9XPPOjo3NOhYqtDklR99pJJt3euMMfOaUx+JcveG83DUtty16nkuNJp7bv0klV6+uRPSJJKvvoxDfYOjr7XvcNMFdbuqpTNbotTb2NXsHZ4amiZ6+Ogl5AlVu5S873LGuye0vavf1jZV8r4CxKHkAVIcTa7Tb028yHib5x6OSRSmyfMwmsYq2Bhodps5sai4bHk3/DMtvwnTcjSd7aphFh0fp0OuJbKrSFtv+HhCfcbuTHbnrtOxXUlie8ojmn1J94sv3yqijRo9x9fnvb+4R3m3O+rTL2pwiTJneNWg3OhJKn5qfj/nkbDUeXIfD74ypP/1CUAAEiMnJPNoHtJ58yvJ45UAldPqRI4f7iCviIFKuizHjX3AJ3rY6tIP+nuL6vZXqkFQ3u18Z3fHX3dv9c8DNPtS/5UYZJUdc7Ya9shX0FyOpIBPGVmfCx7aGrjY4E2/+jXWUVZCekTIBGyAGmh32E+RAKN3cntCOJmZOE1dyEhC45ozDU3W12b5lbI0nOwW6u6/yZJWvCxIzdYB483X0funnjqqdEbszOYKiwVeAu82lZxriSp6afTnzLM85q52Y8uS81KFklqLTR9630+/r+n/c39o1/nVBKyAACQqcrPNIPutaF9CgfDM2qr57nhkCV/atdPNW8x21VFGuRv9U+ydeL4W/1a3WbW8av5SGzX8nk1edr3YROunPbX69TwzEFJUuigqWQJ5CV/0XtJKlparC5b4eifw9lUssTKV1UgScqJTi1kCXaYc9wvn+xOhsGROJxdQBoYWRRtsJVKlkzhi5oPek8RIQuO6C03N1uhbXMrZNn+/YfkUlj73Mdp/psXj76ef7mpall+4H5FQpGj9ovHjRniL/Q287Mo3TT9kKWow5z72WtSs5JFkgI1pm/RnfF/+tPfbKYKC8shb4E37u0DAIDUULW2VgPyyq0hHX7mtRm1Fd5urkn6p1gJXLi4SB22YklSwxN7Z3Tsmdh2wyPyalCHnAu1+KIVMbez/ubL9FL+2fJpQA3v+qR58bAJWUKlqVHJYrPb1JB9JASL5hUkrzNpbmTd4jyrR9FwdNLtR0KWgI2xFyQWIQuQBoJu8yESaiNkyRS+4elgskr4oMcRkSXmwtt1IPml+7PJuscMxtevGRuUrPrwBvUoXyVWu3bcuumo/UZuzA46F2nxhcfNSl8xuWWffLskaaX/uWmtWxINR1Ub3CNJKjszdStZbMtN33z18Q9DB9pMJUu/LTcl5g8HAACJYXfaVe9dKklqfXpm1xSeQ2Z/axqVwIdzzLYdG5N33xH6k7kHOLDyohld99jsNuX86haF5dDpTXfpua8+IFf78DVoZWqELJLUU/a6ECyfSpZY5daY751d1pgq8IkMdpqxl6CDsRckFiELkAYGs8yHSLi9O7kdQVyE+kNyyZSEE7Lg9bJOMBfehW1zp5IlHAxrxcH7JUlF7xsbsrh8Lm2fd74kqeOXR1dFhO4067G8tvJCBqRTSPmaSm3PPlWStPuG+6a8X9NzDfJpQENyqvqMBQnq3czlnmx+T0u74j8oEWwzlSwBO4veAwCQ6TqKTdDh3zKza4ri4Upg3zQqgXtGKui3Jue+IxqOqm6fuU7MvXzmFelLLl6pp0++WpJU+vWPK7fjgCTJNS81pguTpPDiIyGYrZCQJVbeAq8G5ZYk9dV3T7r9UDchC2YHIQuQBkYWRYt2UcmSCV6/8JqvlA96HFG8bnhu5sAuWVEryb2ZHdt/9qwKrS512Iq18gPrjnrfutDcdFVvGRuyRMNR1e01IUs8bswQX21rzc/E/fDUpwxr+Zu5ya93L5bT60xIv+Kh4qzh39Oh/RoKDMW17cF2E7IMOFiPBQCATDc431xT2PfEHnTEWgkcGR7wd+5PTiXLq795XmXRFvUqV6uuPCsubZ58z5fVbK/UgqG9Or7vWUmSb0nqVLJ4Vh8JwZzFBcnrSJqz2W3qtZmQyt84+RjZSMgScvoS2i+AkAVIA5Gc4acceghZMsFAu/mQH5JT7hx3knuDVFJ7zmJFZFeu+tX6SnOyuzMrun5tBuFfXXiBHG7HUe+v/M/zFZZDSwe3q/6pA6Ovj9yY9SgvbjdmiJ+KD5j1dFY3P6KBzoEp7dP3vLnJbytK3anCJKni5Gr55ZNTETX87cDkO0xDqGM4ZHERsgAAkOmcK8yge25j7EFH46Z6ZSmokFyqXj9/yvt5jzfHLmhNTiVL2y/MPcD26vPidk+cW5Wr/Vd+b8xr+ctTp5Jl5IE6SXKXUskyE/3OAklSsGXyMbJwz3DI4uIBVyRW6j4mCGCUlV8gSbL1difsGNt+/nf1f/k7qr79u6o9a2HCjoMjIUtA2eLSCq/nyfPooHOB5of3q+mJXSpfk/ybgiffeZOKHr4jpn1D7hzl33qjlvzjxAtZznvF3GDZ//HCcd8vWFiol/I3aE3Pkwqf+w/a6jGLdOYFWyRJO2rO0zrCypRT9+41anxvjaoiDdp846M67avj/3zH2G1u8gdqUnfRe8k8PVeftUzLB15S29O7tPC8+PU33GVClpCbkAUAgExXsLZO+rlU0Rt70NHy1C7VyFQCL55GJfBoBb3fVNAncurdjZ/6o3z/e5Ps0cjoa2v8r0qSIhfEtyJ93Q/+RVt++1Od2P2EJKnk+NSpZKl989LRrz1ljATMxIArXxqSgs3dk24b6R1+yNVNyILEImQB0sHwomjO/sRVsnR/4xZtaLxTT3xljWofvTZhx8GRhdcCdkIWHK21sE7z2/ar9/ndks5Jal96G3q17s7/lFuxT4n0t09/R0v+8dZx33vtkT1aFNqlITm18pPnTdyP898t3fGkFg7t1lFdufTSmPuGxLHZbdqz4h2q2vpD+b7/dUW/dIHszmMXUGc3mKc4HStSu5JFkjpL6qT6lxR4Kb5Pf0Z6zOKdIS8hCwAAma72rcsVlU2V0cNq3FSvqrW1026j/0VzLdJeVKfF0zn2m5YoKpvy1aO2V9tUurJs2seeCitqaf5Nn1JVpOGo9/qVreM+fUFcj2ez25T7yx9q4B2nqNVZpXlVqXNNlVWUpZ1Za7RkYKvKTl+U7O6ktaAnXwpIQ+2Tj5FF+8z4S9hDyILEImQB0oCjyAzFuwKJC1myeszURPamwwk7BoxQFwuvYWKB6mVS2wOK7kxO6f7rbb/hYa3TkA45F6rpMzdMa9+BV/bonPs+o+X77lMkFBl3KrDXbrlXCyRtLTxbJ82bOHI841dXaMspdaNTKY3wVhXp9Cs3TKtfmD11v7xGfSf/Uqv8m/S3D9yqM3/5/465fVmPOefzTkntShZJCi1YJtVL9r3xncc82mPO8bCXhe8BAMh0+fML9EruOh3f96z23nivqm7/yPQb2WWuRQZqp3f95C3wqt45X7Xh19T05O6EhSy7fv+Slkca5JdP2z53m2Q7UjFTdvZxWlhXEvdjLrl4pQ49vl3egqyEVujEovi5h/TavnYtOSl1KmzS0aCvQOqSwp2Tj5FZ/Wb8JeJl/AWJRcgCpAFnSYEkyRPsTtgxcgJt5hidjQk7BoyRhdcGnXzI42i25XXSS5KvPjmLUL5e5M9mYfn9J1yic75x8bT2HQoMqSf76yq12rT1l5u1+oqjF7XPf9JMFdZ3zrGnCXC4HTrx02+e1vGRfBUnVemJf/yKzrnn01rx6/9S17WXqHBx0bjbDvYOqib8miSp6k2pX8niWlUn/U3Ka4pzGNpnQpaoL3WeugQAAInTuf4i6aFnlfXoXyRNP2TJbjTXIrFUArfk16m24zX1bN4lJejBpeaf/UXLJW2reKvWfvMdCTnGeOadk5qVIqUryxIWaM0lYZ95QM/q7J58Y78Zf4kSsiDBWPgeSAMji6JlhRJXyZIfapUk5fY1JewYMIZGFl4jZME4ck4yT6GVdiW3kiUSimj5/vskSQX/Ov25kl0+l7bX/oMkqeOXfznq/Z6D3VrV/TdJ0sKPx3cuZqSOM27/mPZ4VqrY6tDWf/zChNvVP75XdlnqUZ5KVqT+jWfhWvN7WtkX5zC0fzhkySZkAQBgLqj5iLkOXt32mPyt/mnvXz6DSmB/tdkn8mri7jtKN5uHtkLncb2P+InkDs+C0DP5GJktYH6vLB/jL0gsQhYgDXjLzQdI9lB3QtqPhqMqjppKlsIglSyJFhkJWVh4DeOoPMc8hVYztF9DgdjXQpmpHbduUonVrh7la+UVZ8TUhnWhuZmq2nLvUe9t/96DcimsvZ4VKfukGWbO5XPJ/+1bJEkbdvxEr/72hXG3a3/W3Nwf9i1LuWkdxlP9JjMoUR5tVm9Db9zatfuHp8TLJWQBAGAuWHzRCtU7F8irQW274ZFp7TvQOaDq8EFJMVYC15l9sg4lpoK+5aUmrfQ/J0ladnV8117BHJdfIEmy93ZPuqltYDi8zGb8BYlFyAKkAV9VgSQpJ5KYSpaeg91yKSxJKo22KBKKJOQ4MEYXXiNkwTjKT6ySXz65FFbD3w4krR8j1Sfb550vl88VUxsrPn2+wnJoWXCrGp45OOY96x7TfsMJF86so0h5az5xtp6Zf7nsshT58JWKhqNHbRN82dzcd5Wl/lRhkpQ/L1+t9nJJ0uEn9sStXeeAWfjelkfIAgDAXGCz27R/hXkwKXTn0Q8mHUvDk/uGK4HzVXJc6bSPPVJBX9KZmEqW3TeYqvjt2aeqfE1lQo6BuclWYB5EdvonHyNzjIQsOYy/ILEIWYA0kFNtPkBy1Tfu4NRMde1qHf3aqYg6drbF/Rg4YjRkYU5QjMPutKvBu1SS1PZ08tZlqd5iQpCRapRYFC4u0rZ8UwWz78YjU4aFg2GtOPSAJKnofUwdMBcsvvM76lWuVvk365n/94uj3nfsNzf3QwtTf9H7EU05pq+dG+P3e+oMmkoWex4L3wMAMFfkXGauh+v23jut+/32Z801SEN2bJXA5Weaa5na0F6Fg+Fp7z8Z98Pm+r9tLdf7iC9HcYEkyTUwecjiHDTjL3ZCFiQYIQuQBnJrTMhil6W+w/GblmRE377WMX/u2MqUYQnFwmuYREepeZo/8FJy1mWpf+qAlg5uV1gOrfzP82fUVvcGc1OV/fiRkGX7z55VodWlDluxVn5g3YzaR3qoOKlKL178FUnSit98Tl37Ose8n99sznX36vSoZJGknkrT16Ht8fs9dQ+akMVRSCULAABzxeqPnq1e5aos2qJXf/P8lPcbfMVcg8RaCVy1tlYD8sqtIR1+9uDkO0zDQOeAVjeb6c8qryBkQXy5SswYmTfYPem2zpAZf3HkMf6CxCJkAdKAt8CroDySpL6G+E8ZFnhtbMjSv6cp7sfA64yELCy8hgmE5punyux7k1PJsv8HJhDZlr9BBQsLZ9TWvCvNdGCrO55QX6MZQO76tWn/1YUXyOF2zKh9pI8zfvdR7fGsVLHVoa3/+IUx71X1m3O96PT0qWSJLjZ9dR+I3++pJ2R+R1yELAAAzBnuHLe2V58nSWr7xV8m2foI5z5zDRKOsRLY7rSrfriCvvVv8b3v2HbTY/JpQIcdtVr2rhPi2jbgLjUhiy80+fiYm5AFs4SQBUgTfTbzIRJoin/IEjo8NmQZ2E8lSyKNLrxGyIIJuFaZp9HympJTyZLzhJkPuvvMmT91tvAf6vSaa4k8CmnbDQ9Lkua9Ym4eHRfzVNtc4vK55P/2LZKkDTt+oh2/Nk9qdu3rVInVLkmqedPSpPVvurLWmN/Twrb4/Z5mhU3I4ikhZAEAYC6JXGCuiyufn3rIkt8yXAl8fOyVwB3FiamgH/iD+XvsW35hTFOZAceSVVkgSfKFpxCyhM34i6uA8RckFiELkCb6nQWSpIGm7ri3bTWPDVmiDVSyJNLowmvZfMhjfAWnmafRKvpmP2TpbejV6s4nJEnzPzrzEMRmt+m11aadyF1/0WuP7NGi0C6F5NLKT5034/aRXtZ84mw9s+A9sstS9MqrFA1Hdfhxc5432auVU5E+a5GUnmF+T2sGdsuKWnFp0xchZAEAYC467tMXKCK76oIv6/DGQ1Pap8pvrqGKZ1AJPDhcQW/bE7/7Ditqaeku89BW1qU8VIX481Wah5Dzot2TbuslZMEsIWQB0kTAbT5EBlvjX8libzchy5Cc5s/NVLIkkiNoPuRtLLyGCdS8eThkiTaptyH+6zAdy/YbHpZbQzrgWqaF58Vn6qb895ibq+X779NrP/izJGlr0dnKq8mLS/tIL0vu+o56latV/s165v/9Qt2bh0OW/PRZj0WSas5apLAcylW/Wl6Kz8MJvmi/JCmrjJAFAIC5pLiuRNtzzVqF+266b9LtO/d0qNjqkDSzSmDnSnP9ldMYv+nCdv3+JVVGD8svn1Z//E1xaxcYkVNtxseyFdBQYOiY23qjZvzFU8T4CxKLkAVIE0GP+RAZao9/yOLqNiHLAe9xkiRPJyFLIo0svGbP5UMe48ufX6A2W5kk6fATe2b12JG7TWn/weMvjFubqz68QT3KV4nVrpX3f0eS1H92/NpHeilfU6kXL/6KJGnFbz6n6LN/lyT1V6bPeiySmT+9wbVQktT81Myf/oyGo8qR+XzIKk2fih4AABAfnevN9XHWo5NPGTZSCdzoqFF2Wez3laMV9L3xq2Rp/tnw+o4Vb5W3wBu3doERebX5o1/31h97jCyLkAWzhJAFSBOhrAJJUri9O+5t+/pMyNJatUaSlNvHdGGJ5BpZeC2fD3lMrDHX3PB0bozvIpTHEglFtPzA/ZKkgn+NX2m/y+fS9tp/kCSVWubfm4UfZ+qAueyM331UezyrVGx1aMP2H0uSokvTK2SRpLYC0+fe52b+e9rf3D/6dU4llSwAAMw1NR8x18er2x6Tv9V/zG17Nptrj+a8mV0/Vb/J7F8VaZj0mFNVtsmELKHzuN5HYji9TvXLjKf0H544ZLGilrKHH2LyFjP+gsQiZAHSRDjbJPVWd/wrWXKDZtAzvGqNJKkwSCVLIrmHhucEJWTBMfRWmNL9oe2zty7L9v/9u0qsdnXbCrTyijPi2rZ14ZGbrL2eFZp3zqK4to/04vK5FPjOLZIku8x6Jtknptd0YZLkrzV9ju6a+e+pv9msxxKWg6c+AQCYgxZftEKHnAvl1aC23fDIMbcN7zDXHv1VM7t+KlxcpHZbiSSp4fGZV9A3v9ioFYHnJUl1n3r7jNsDJtJnL5AkBZomHiMb7B2UQ1FJUlYJ4y9ILGeyOwBgaiK5BeaL7u64t104ZEKWvA0nSPdIZdFmRUIROdyOuB8LkoeF1zAFkcXLpN2Se/+rs3bMzlvNeinb552vM3yuuLa94tPnK/wjh5yKqGHNRVoS19aRjk742Fl6+oZ/1YYDv5UklW1Iv0oWe90y6UXplBd+ooOuu2fUltMy80n323JVYLfFoXcAACCd2Ow2HVh5kea9fJOWffs/dPC7n55w25PD5h7eikMlcGPOMpX0tavj6Veld6+ZUVu7b7xPFZK2ZZ+mVcdXzLhvwET8rnxp8LCCzd0TbhNo82vk0aWZTKsHTAUhC5AuCgslSY6ezrg2G+oPqdDqkiTVnr9Kkc/a5VBUrTvbVMZFUUJ4IyZkcRfyIY+J5Z97qvSAdHL93Tr46F7Nf0tiY4mm5w/r5Od+JEmyv+udcW+/cHGR/l51sU5svFdV/3l53NtHelp65/VqO+lhBR0+VZ+xINndmbbKd21Q9HabcuRXTnh/XNo8mLtaBXFpCQAApJvij14mffAmFVpdKgx3Tbp96SUbZnzMrsWnSi89q/xbb1D0hnfL7ox90hvPw2aqsPbTmSoMiTXgypcGpcHWiStZBtrN2Mug3PJ4GQJHYnGGAWnCXmkWwXb3tsW13c7d7aqQmZ6keHmp2uxlKo82q2NrIyFLgowsvEbIgmNZc/U5euG6t+rkzkfUetnHNa/5PtkS+HT7gXf+p9arX1tz1mntNy9JyDHWbL9NPYe6tYx/WzCsfE2luva8qnyPU840vPFZeskqNTx9QN2vxmktM5tNyy45Pj5tAQCAtLPqA6fr0JJ96t3bOum2+cvKteKshTM+5nG/+px6TrhVK/3P6an/+F+d9esPxtTOQOeAVrf8VZJUeQUhCxIrmFUg9UvhjolDlmCHGXsJ2LLlmaV+Ye5Kv7tZYI7y1JiQJbt/8out6ejZ06oKSR32UpU77er0VKl8oFn9e+I0YISj+CwWXsPkbHabCn97s0IXrNapbQ9o0xfv0dpvXJyQY2353mNaf+gORWSX66e3zOjptWPxFnjlLSBgwViFi4uS3YUZqTljvmrOmJ/sbgAAgAwx75xF0iyuX1h2fIWevOSrOvuuq7Xqt59T57X/pKKlxdNuZ+uNj+o0Deiwo1bL/pmHRpBYQ1lm3eJIR/eE2wx2mrGXAXu2CmejU5jTWPgeSBO+BSZkyRuMb8jSv9+01+027fflVkmSBvY3xvU4MCKhiLwalMTCa5jcovPr9Oy6/5QkVV//CQXaA3E/Rqg/pLzPf1SS9PTqj2j5ZSfG/RgAAAAAUtcZv7tKu72rVWR1ats/fj6mNoJ/NFOF7Vt+YUIr8AFJCmebkMXqnriSJdRlQpagg7EXJB4hC5Am8paYEKQoHN+QJXjItNfvM+0HiyolSdF6QpZE8Lf6R7/2lfJBj8mdevcXdNhRq5rIQW2+5Jtxb//Zf7lJi0Ovqs1WqhP+/LW4tw8AAAAgtTm9Tg185xZJ0oadP9OOXz03rf2tqKWlu++VJGVdylRhSLxoXoEkydbTPeE2Q93Da7IQsmAWELIAaaJouQlBcuQfM1A/U0ONJmQJ5pr2o+WmksXewnRhiTCy8FpUNnkLvEnuDdJBdlm2Dn3yBknSuqev18FH98at7abnGnTKff8tSdr1H9erYCFF1AAAAMBcdMJHz9TTi94ruyzpyisVCUWmvO/O27eoMtqofmVr9cfflMBeAsPyTSWLvX/iSpZwjxl/CbkIWZB4hCxAmsipyNGAzKB81+62+DXcYkKWcJEJWew1JmTxdFLJkggjC6/5lU0JNabs9G//k54vfps8Cqn1so/LilpxaffAO/9TOfLrldz1Wv/jf4tLmwAAAADS07K7rleP8rQi8Lye+Y//nfJ+LT83U4Vtq3wrDxNiVtiLCiRJLv/EIUukdzhkcROyIPEIWYA0YbPb1OEwQUjPnvhNGeboNG1ZpaZt70IzXVhuHyFLIoyELAN2PuQxdTa7TcW33ayQXDq17QFt/sKfZ9zmi995VOvrf6+I7PL8LHGL3QMAAABID2XHV+ilS74qSVr1u2vUsat9avttNiHL0HlMFYbZ4SgylSzuge4JtxkJWcIexl+QeIyoAGmk12OCEP+B+IUsnh7TlqPStJ1bZypZCoNMF5YIIwuvEbJguhaet0zPrv+MJKn6O59QoD0Qc1uh/pDyvziy2P2Vqnv3mnh0EQAAAECaO+N3V2m3d7WKrE5tf8fnJ92++cVGrQi8oKhsWv7pt89CDwHJXWpCFu/gxJUsVr8Zf4kQsmAWELIAacSfbYKQwfr4hSzZftOWp9a0XbjCVLKURZunNQcrpmYkZBl08iGP6Tv1rs/rsKNWNZFD2nzJN2Nu59l3/0CLQzvVZivVmr+w2D0AAAAAw+l1auA7t0iSNuz8ubbfuvmY2+/+vlnwfkf2aSpdVZ7w/gGS5CkvkCT5hiYOWeQfXhM3i/EXJB4hC5BGgvkmCIk0xS9kyQ+atnzzSyVJJSvKFJFdDkXVsTOOa79A0pGF1whZEIvssmzVf+pGSdK6p6/Xa4/smXYbTc816JT7vyLJLHafP78gjj0EAAAAkO5O+OiZenrRe2WXJdtHrzrmA5jeR8xUYe3rmCoMsyerwlSy5IS7J96IkAWziJAFSCORQhOEqC0+IYsVtVQUMW3lLTEBjtPrVJvdPH3SsZV1WeJtJGQZcvEhj9is/dYler74PHkUUvtlH5MVtaa1/4F3fprF7gEAAAAc07K7rleP8rQi8Lyeef/Px90m0B7Q6ta/SpIqP3jhbHYPc1x2lQlZ8qyeCe+J7QP+4Y0Zf0HiEbIA6aTMBCGuzviELP5Wv3wakCQVLS8bfb3LY6YM69tFyBJvIwuvDTEnKGJks9tUcvvNGpRbp3Q8pE3X3D3lfV+8/q9aX/8HFrsHAAAAcExlx1fopX8yUwuvvv0adexqP2qbbTc9piwFddhRq2X/fPxsdxFzWG5tgSTJrSENdA6Mu409SMiC2cPoCpBGnFUmCPH2xidk6dxp2gkoS9llRz50+nKrJEnB15richwcER1eeC1MyIIZWPDWpdq4/j8lSTXfu1qB9sCk+4T6Q8q/9mOSpKePv4rF7gEAAAAc0xm3Xald3uNVaHVp+zs+f9T7wT+aqcL2HneRbHbbbHcPc1hORY4iw8PafQ3jr8viHA5ZbLmMvyDxCFmANOKdZ0KWnEB8QpbevaadTkfZmAuiYJEJWaL1VLLE3XDIEvHyIY+ZOfWuz6vBMU81kUPa/I5vTLr9s5feOLzYfZnW3PPVWeghAAAAgHTm9Do1+L1bJEkbdv5c2/530+h7VtTS0t1m0fvsd7MeC2aXzW5Tr81MGeZvnCBkGTTjLw5CFswCQhYgjWQvNCFLfihO04UdMO30eMvGvB4tN9OF2ZsJWeJueOE1i4XXMEPZZdlq+PSNkqRznrlOflv2Mf8764HPSZJ2/T8WuwcAAAAwNcdfuUFPL/o32WWp7gMbRu8vBhzZqow2ql/ZWvXRc5LdTcxB/Q4TsgQau8d93zU0HLLkMf6CxCNkAdJIwTIThhRH2xQNR2fcXqjBhCz+7LEhi73GVLJ4upguLN5sgeGQxceHPGZu7Tffob9XvkOSlK3AMf+zy9KLhW/W+h+9N7mdBgAAAJBW6v58vdpsZXIpPHp/MbK+64vLL5e3wJvkHmIuCjhNyBJsGb+SxT0csjjzGX9B4jmT3QEAU1dUVypJcimsroPdKlxcNKP2Is1tkqTB/LEhi3ehqWTJ7aOSJd7sAyy8hvix2W067dCf1LCpXlbk2MGrzW7TCafVstg9AAAAgGkpXVWuQOsB1e9oGfO63eXQmWtrk9QrzHUDngIpKIXaxw9ZvGEz/uIuZPwFiUfIAqQRT55HPcpXvnrUtat1xiGLrc1UskSKxoYsuXWmkqUwSCVLvDlGFl7L4UMe8WF32lVzxvxkdwMAAABABvOV+OQ7a2GyuwGMGszKl3qkcFv3uO97I4QsmD08zgqkmU6XCUT69s18XRZn53Ab5WNDlqJVJmQpizYrEorM+Dg4YmThNTsLrwEAAAAAAMRkyGemC4t2jV/JkmWZ8RdPEeMvSDxCFiDN9A0vUh841Dbjtrx9JmRxVY0NWUpWlCkiuxyKqn3HzMMcHOEKsfAaAAAAAADATERyCswX3d3jvp9lBSRJ3mLGX5B4hCxAmgnkmEBkqGHm4UdOwLThnTc2ZHG4HWqzl0uSOrczZVg8uYYIWQAAAAAAAGbCyjOVLLa+oytZwsGwPApJkrJKGH9B4hGyAGkmVGACkWjzzEOWgpBpI2dR2VHvdXrNlGF9uxpnfBwc4RleeM1VwIc8AAAAAABATAoKJEmO/qNDFn+rf/RrXynjL0g8QhYgzURLTCBia59ZyBINR1UcNVOO5S89OmTpz6mUJAVfo5Ilnlh4DQAAAAAAYGYcRaaSxe3vPuq9gXYz9hKWQ+4c92x2C3MUIQuQZmzDi9S7u2YWsnQf6JJTZlH7omUlR70fLDKVLNF6KlniiZAFAAAAAABgZpzFJmTxBI+uZAl2mLEXv7Jls9tmtV+YmwhZgDTjqjEhS1b/zEKWrl1m/y5b4bipfrTcVLLYmwlZ4slnmQ96Fl4DAAAAAACIjbusQJLkDR0dsgx2mrGXATtjL5gdhCxAmvHNNyFL7sDMQpa+fcMhi+voqcIkyV5jKlk8XUwXFi9W1FK2ApJYeA0AAAAAACBW3nJTyZI91H3UeyMhS9DB2AtmByELkGZGFqkvHJpZyDJw0Ozf5x0/ZPEuMiFLbh+VLPEy0Dkw+jUhCwAAAAAAQGx8VQWSpNzI0ZUsQ90mZBkkZMEsIWQB0kxhnQlFiqxODQWGYm4n1GBClkDu+CFL7jIzXVhRkJAlXgJt/tGvfSW+JPYEAAAAAAAgfeVUm0qWXPUqGo6OeW8kZAk5GXvB7CBkAdJM4eIiRYZ/dTt3t8fcjtViQpahgvFDlqJVppKlNNqiSCgS83FwxMjCawFlye7kn18AAAAAAIBY5NaYkMUuS32NfWPei/QOhyxuKlkwOxjlA9KM3WlXh71UktS9O/Ypw+ztZt9oyfghS8mKMkVkl0NRte+Y2dRkMEZClgEbT1IAAAAAAADEylvgVVAeSVL/4bFTho2ELGFCFswSQhYgDXW7TTDSvz/28MPdbfa1VYwfsjjcDrXZyyVJndubYj4OjhhZeG3Azoc8AAAAAADATPTZTDWL/3D3mNej/cMhi4fxF8wOQhYgDfVnmWAkeCj2kCWr3+zrrh4/ZJGkTq+ZMqxvF+uyxEOoi4XXAAAAAAAA4qHfaUKWgeaeN7xhxl8iWYy/YHYQsgBpaCDPBCNDjbGHLHkDZl/fgolDlv6cSklScD8hSzyMLLw26ORDHgAAAAAAYCYC7gJJ0mDrG0IWvxl/sQhZMEsIWYA0FC4cDkZaYg9ZCsNm39zFE4cswSJTyRI9zHRh8RDuGV54zcWHPAAAAAAAwEwEPaaSZaite8zrtsBwyOJj/AWzg5AFSENWqQlGHB2xhSyh/pAKrG5JUmHdxCFLtMKELPZmKlniYWThtSEWXgMAAAAAAJiRUFaBJCncMbaSxR404y/KZvwFs4OQBUhDjkoTjHh6YgtZOna2SZKG5FT+/IIJt7NXm+nCvJ2ELPEQ7WPhNQAAAAAAgHgIZ5tKFqt7bMjiGA5ZbDmMv2B2ELIAachdXSpJ8vljC1l69pj9Ouylsjsn/mfAu8hUsuT0M11YPFjDC6+FvXzIAwAAAAAAzEQk14Qs6u4e87pz0Iy/2HMZf8HsIGQB0tDIYvX5g7GFLP37zX497omnCpOk3GWmkqUoSCVLXAwvvBZl4TUAAAAAAICZyS+QJNn7xlayuEJm/MWRx/gLZgchC5CG8paYcKQoHFvIEqw3+/X7jh2yFK0ylSyl0RZFQpGYjoXXGVl4jZAFAAAAAABgRmwFppLF6e8e87p7yIy/OPMZf8HsIGQB0lDRchOOZCsgf6t/2vuHD5uQJZhbesztSlaUKSK7HIqqfUdsgQ6OsAdYeA0AAAAAACAeHEUmZHEHxlayeMJm/MVVwPgLZgchC5CGcipyNCCvJKlzZwzhR6vZJ1x07EoWh9uhNnu5Oc42pgybqZGF1whZAAAAAAAAZsZVWiBJ8gyODVm8hCyYZYQsQBqy2W3qcJiAZGQR++lwdJp9rNJjhyyS1Ok1U4b17W6a9nEwloOF1wAAAAAAAOLCU2YqWXyh7jGve6Nm/MVTxPgLZgchC5Cmej0mIAm8Nv2Qxdtj9nFUTh6y9OWakCW4n0qWmXKNhCwsvAYAAAAAADAjWZUFkqTs8NhKFp9lxl+8xYy/YHYQsgBpyp9tApLB+umHLNl+s4+ndvKQZbCwUpIUPUwly0y5RhZeI2QBAAAAAACYEV+lqWTJjR4JWaLhqHwakETIgtlDyAKkqWC+CUgiTdMPWfIGzT6+BZOHLNEKU8lib6aSZaY8IyFLPh/yAAAAAAAAM5FTbUKWbAU0FBiSJAXaA6Pv+0oZf8HscCa7AwBiExlZtL69bVr7WVFLxRETsuQvnTxksVebShZvJyHLTHkiJmRxF/IhDwAAAAAAMBO51XmjX+/5v5eVXVOo/oMdWjn8WlZRVnI6hjmHkAVIV2UmIHF1Tq+Spb+5X7kKSpKKlk8esngXmUqWnH6mC5spLyELAAAAAABAXDi9TvUpR7nq14r3nTrmPb98ynYyiRNmB2cakKac1SYg8fZOL2Tp2m0qX/zyKbts8sH+3DoTshQFqWSZqayoCVk8RYQsAAAAAAAAM/XiCf+hXuUe9d/zq/492V3DHEIlC5CmvMOL1ucEphey9O4123c6yzSVof6ilWa6sNJoiyKhiBxux7SOB8OKWsqWCVlYeA0AAAAAAGDmzn7pB5J+cPTrs98VzGFUsgBpKmeRCVnyQ9MLWfwHzPY9nsmnCpOkkhVlisguh6Jq3zG9Y+GIUH9ITkUksfAaAAAAAAAAkCkIWYA0NbJofXG0TdFwdMr7hRpMUBLInlrI4nA71GqvkCR1bmPKsFgF2vyjXxOyAAAAAAAAAJmBkAVIU8XLSyVJLoXVc7B7yvtFmkzIMpg/tZBFkrq8Zsqwvt1NU+8gxhhoNyFLSC65fK4k9wYAAAAAAABAPBCyAGnKneNWt61AktS1a+rTeNnazLaR4qmHLH25VZKk4H4qWWIV7DAhS8BGFQsAAAAAAACQKQhZgDTW5TRBSd++qYcszq7hbcunHrIMFppKlmgDIUusBjtNyDJAyAIAAAAAAABkDEIWII31ZpmgJPDa1EOWrF6zratq6iFLtMJUsthbmC4sVqEuE7IEHYQsAAAAAAAAQKYgZAHS2ECOCUpCh6cesuQMmG2986YesthrTcji7aSSJVajIYuTkAUAAAAAAADIFIQsQBoLFZigxGqeeshSEDLb5iyaesjiXWCmC8vtI2SJVbhneOF7FyELAAAAAAAAkCkIWYA0Fi0xQYm9fWohSzQcVXG0TZJUsGzqIUtunalkKRxkurBYRXpNyDJEyAIAAAAAAABkDEIWII3Zhhevd3VPLWTp2tcph6KSpKJlJVM+TvFqE7KURlsUCUWm2UtIUqTPhCxhDyELAAAAAAAAkClSPmTp6+vT1Vdfrfnz5ysrK0vr16/Xc889N/q+ZVn60pe+pMrKSmVlZencc8/Vnj17kthjYPa4a0zI4uubYsiyy2zXaSuSy+ea8nGKl5cqIrsciqp9x9SnJsMR1kjI4iVkAQAAAAAAADJFyocsH/jAB/TII4/oN7/5jbZu3aq3ve1tOvfcc3X48GFJ0vXXX6+bbrpJP/7xj7Vp0yZlZ2frvPPOUzAYTHLPgcTLmm9Cltzg1IKP/v1muy7X1KcKkySH26FWe4UkqXMb67LExG9ClighCwAAAAAAAJAxUjpkGRgY0J/+9Cddf/31Ouuss7RkyRL993//t5YsWaIf/ehHsixLN954o774xS/q4osv1vHHH69f//rXamxs1N13353s7gMJl7vYhCWFQ1MLWQIHzXZ9WdMLWSSpy1tp9t1FyBKTkZAli5AFAAAAAAAAyBQpHbKEw2FFIhF5vd4xr2dlZenpp5/WgQMH1NzcrHPPPXf0vfz8fK1du1YbN26csN3BwUH19vaO+Q9IRwVLSyVJhVaXQv2hSbcfajAhy0DO9EOWvlyzLkvwQNO094VkHzAhi7IJWQAAAAAAAIBMkdIhS25urtatW6evfe1ramxsVCQS0W9/+1tt3LhRTU1Nam5uliSVl5eP2a+8vHz0vfF885vfVH5+/uh/tbW1Cf17AIlSuLhIkeFf487d7ZNub7WYkCVUOP2QZbDIhCzRBipZYkHIAgAAAAAAAGSelA5ZJOk3v/mNLMtSdXW1PB6PbrrpJl122WWy22Pv+jXXXKOenp7R/+rr6+PYY2D22J12ddhNNUvPnsmnDLO3m22skumHLNFyM12YvYWQJRaOQROy2HIIWQAAAAAAAIBMkfIhy+LFi/Xkk0+qv79f9fX12rx5s4aGhrRo0SJVVJiFuFtaWsbs09LSMvreeDwej/Ly8sb8B6SrbrcJTEYWtT8Wd7fZxl4x/ZDFXmsqWbydTBcWC+dwyOLII2QBAAAAAAAAMkXKhywjsrOzVVlZqa6uLj300EO6+OKLtXDhQlVUVOjRRx8d3a63t1ebNm3SunXrkthbYPb0Dy9iHzw0ecji6zfbuGqmH7JkLTIhS24flSyxcIcIWQAAAAAAAIBM40x2Bybz0EMPybIs1dXVae/evfrMZz6j5cuX6/3vf79sNpuuvvpqff3rX9fSpUu1cOFCXXvttaqqqtI73vGOZHcdmBUDeWVSlzTUOHnIkhs02/jmTz9kyVlqpgsrHKSSJRbuIROyOPMJWQAAAAAAAIBMkfIhS09Pj6655ho1NDSoqKhI73znO3XdddfJ5XJJkj772c/K7/friiuuUHd3tzZs2KAHH3xQXq83yT0HZke4sEw6KKll8pClaMhsk7t4+iFL8WpTyVIabVE4GJbTm/L/fKQUT8SELK4CQhYAAAAAAAAgU6T8KOmll16qSy+9dML3bTabvvrVr+qrX/3qLPYKSB1WqQlMHJ3HDlkGeweVrx5JUtHyGEKW5aWKyC6Homre0aqKk6qm39k5zDscsrgLCVkAAAAAAACATJE2a7IAGJ+j0gQmnp5jhyydu9okSUNyKn9+wfSP43ao1V4hSerawZRh05UVNSGLp4iQBQAAAAAAAMgUhCxAmnMPL2Lv87cdc7vu3SaE6bCXyma3xXSsLq+pXunb1RjT/nOZzzIhi7eYkAUAAAAAAADIFIQsQJrLXmhClvzBY1ey+A+Y93vc058qbERfbqUkKXiASpbpCAfD8igkScoqIWQBAAAAAAAAMgUhC5Dm8paY0KQofOyQJXjIvN/viz1kGSwylSzRBipZpsPf6h/92ldKyAIAAAAAAABkCkIWIM2NLGKfrcCYwfw3CjeakCWYF3vIEq0wIYu9hZBlOgbazc8lIrs8eZ4k9wYAAAAAAABAvBCyAGkuuyxbAWVJkjp3HqOapdW8N1QUe8hirzHThXk7mS5sOoIdJmTxKzvm9XAAAAAAAAAApB5CFiDN2ew2dTpMcNKzZ+KQxdk5/F5p7CFL1iJTyZLbRyXLdAx2mpBlwM5UYQAAAAAAAEAmIWQBMkCP1wQngdcmDlk8veY9R2XsIUvOUlPJUjRIyDIdIyFLkJAFAAAAAAAAyCiELEAG8Geb4GSwfuKQJdvfJkny1MYeshSvNpUsJdFWBdoDMbcz1wz1mO9V0EnIAgAAAAAAAGQSQhYgAwzmm+Ak0jRxyJI3aN7LXhh7yFK6qlwNjnlyKKptNz0WcztzTbjHVLKECFkAAAAAAACAjELIAmSAyPBi9ra28UMWK2qpOGLey18ae8his9u0b8VFkqTgH/8ScztzzWjI4iZkAQAAAAAAADIJIQuQCcpNcDK6uP0b9Df3K0tBSVLhstIZHSr70gslSUt33ysras2orbki0mtCljAhCwAAAAAAAJBRCFmADOCqMiGLt2/8kKVzp3m9X9nKLpvZQP+qj56jfmWrMtqonb97cUZtzRXR/uGQxUPIAgAAAAAAAGQSQhYgA3jnmZAlJzB+yNK717ze6Yx9qrDRYxV4ta3ybZKklp8zZdiUDIcskSxCFgAAAAAAACCTELIAGSBnkQlPCkLjhyyB18zrvZ6ZhyySNPQPZl2WsufujUt7Gc9vQhaLkAUAAAAAAADIKIQsQAYYWcy+ONqmaDh61PuDDSZk8efEJ2RZ/um3KyqbVgReUPOLjXFpM5PZAiMhiy/JPQEAAAAAAAAQT4QsQAYoWlYiSXIqou4DXUe9H20yIUsoPz4hS+nKMm3PWStJ2v19qlkmYx8wIYuyqWQBAAAAAAAAMgkhC5AB3DluddkKJUldu46eMszWZl6LFMcnZJGkjtMvlCR5H2Fdlsk4giZkseUQsgAAAAAAAACZhJAFyBDdzlJJUt++o0MWV5d5zVYev5Cl6kNmXZbVrX9VoD0Qt3YzkXPQhCz2XEIWAAAAAAAAIJMQsgAZojfLBCgDB48OWbx95jVnVfxClqX/tFoNjnnKUlDbfvBo3NrNRK6QCVkceYQsAAAAAAAAQCYhZAEyxMDwovahhqNDltyAeS1rfvxCFpvdpn0rTDVL8P9Yl+VYXEOELAAAAAAAAEAmImQBMkSowAQoVsvRIUtByLyWsyh+IYskZb/bhCxLd98rK2rFte1M4gmbkMVVQMgCAAAAAAAAZBJCFiBDREtMgGJvHxuyREIRFVntkqSCZfENWVZ/7Bz1K1uV0Ubt/N2LcW07k3gjJmRxFxKyAAAAAAAAAJmEkAXIECOL2ru7x4YsXfs65VBUklS0rCSux/TkebSt8m2SpJaf/yWubWcSQhYAAAAAAAAgMxGyABnCXWNClqz+sSFL63MHJUkdtmI5vc64H3foH8yUYUUvPhL3tjOFzzIhi7eYkAUAAAAAAADIJIQsQIYYWdQ+b+ANIcuvH5Qk7S1bn5DjFp25UpJUEjiUkPbTXTQcVbYCkqSsEkIWAAAAAAAAIJMQsgAZInexCVkKw2NDlpK/m2m8Bt92UUKOW7SqSpJUGmlWNBxNyDHS2UDnwOjXhCwAAAAAAABAZiFkATJEYZ0JWQqsboX6Q5Kk1leatcq/WZJU96kLE3LckpXlisoml8Lq2NWekGOks0Cbf/RrX4kviT0BAAAAAAAAEG+ELECGKFhYqLAckqTO3Sbs2HXD/ZKkHb5TVL6mMiHHdflc6rCVmuNub0rIMdJZsMOELAFlye7kn1wAAAAAAAAgkzDiB2QIu9OuDrsJO3r2mCnDXA+ZqcJaT0tMFcuIDq+ZMqx3Z2NCj5OORkMWG1OFAQAAAAAAAJmGkAXIIN1uM2VY//5WBbuDWt30sCSp/AOJWY9lRF+OqZIJ7idkeaPBThOyBO2ELAAAAAAAAECmIWQBMki/z4QswUOt2nrT48pWQE32ai2/7MSEHjdYaCpZIg1MF/ZGQ93DIYuTkAUAAAAAAADINIQsQAYJ5pqQZaixVQN/MFOF7am7UDa7LaHHjZSbkMXeTCXLG42ELIOELAAAAAAAAEDGIWQBMki4yIQsam7R4p33SpKyLk3sVGGSZK8204V5OghZ3ijcY0KWkIuQBQAAAAAAAMg0hCxABrFKTchSvvWvqo7UK6Asrfr4mxN+XM9CU8mS3cd0YW8U6TUhy5CbkAUAAAAAAADINIQsQAZxVJqQ5biBFyVJWyveqqyirIQfN7fOhCxFQSpZ3ijaZ0KWsIeQBQAAAAAAAMg0hCxABvHUlo358+BbL5yV4xauMNOFlUaaFQ1HZ+WY6cLqNyFLxEvIAgAAAAAAAGQaQhYgg/gWjA1Z6j41OyFLycpyRWWTS2F17GqflWOmDb8JWaKELAAAAAAAAEDGIWQBMkj+0iMhyw7fKSpfUzkrx3X5XOqwlUqSOrcxZdjr2QImZLF8hCwAAAAAAABApiFkATJI0fIjIUvr2otm9dgdXrMuS++uplk9bqqzDZiQRdmELAAAAAAAAECmIWQBMkh2WbY6bMWSpMoP/eOsHrsvx4Qswf1UsryeYyRkySFkAQAAAAAAADKNM9kdABBfB7/9e+18rUVnvHvNrB43WFgptUmRekKW13MOmpDFTsgCAAAAAAAAZBxCFiDDnPSZtyTluJHyKmm3ZG9hurDXc4ZMyOLII2QBAAAAAAAAMg3ThQGIC3t1pSTJ00Ely+u5CVkAAAAAAACAjEXIAiAuPAvNmizZfVSyvJ47bEIWVwEhCwAAAAAAAJBpCFkAxEVunQlZioJUsryel5AFAAAAAAAAyFiELADionCFmS6sNNKsaDia5N6kDm/UhCyeIkIWAAAAAAAAINMQsgCIi5KV5YrKJpfC6tjVnuzupIwsQhYAAAAAAAAgYxGyAIgLl8+ldnuZJKlzG1OGSZIVtZQtE7J4iwlZAAAAAAAAgExDyAIgbjo9Zsqw3l1NSe5JahjsHZRDZuq0rBJCFgAAAAAAACDTELIAiJu+nCpJUnA/lSySFGjzj36dXUbIAgAAAAAAAGQaQhYAcRMsNJUskXpCFkkaaDchy6DccnqdSe4NAAAAAAAAgHgjZAEQN5FyU8lib2G6MEkKdpiQJWCjigUAAAAAAADIRIQsAOLGXmNCFk8HlSySNNhpQpYBOyELAAAAAAAAkIkIWQDEjWeBmS4sp4+QRZJCXSZkCToIWQAAAAAAAIBMRMgCIG5y60wlS2GQ6cIkaah7eE0WQhYAAAAAAAAgIxGyAIibwpUmZCmNNCsajia5N8kX7jEhS8hFyAIAAAAAAABkIkIWAHFTuqpcUdnkUlgdu9qT3Z2ki/QOhyxuQhYAAAAAAAAgExGyAIgbp9epdnuZJKlzG+uyjIQsYQ8hCwAAAAAAAJCJCFkAxFWnp1KS1LuTkMXqNyFLhJAFAAAAAAAAyEiELADiqi/HrMsSPNCU5J6kAL8JWaJZhCwAAAAAAABAJiJkARBXA0UmZInUU8lCyAIAAAAAAABkNkIWAHEVLTPThdmbCVnswYD5IpuQBQAAAAAAAMhEhCwA4speYypZPJ1MF2YfMJUshCwAAAAAAABAZiJkARBXnoUmZMnpo5LFMWhCFlsuIQsAAAAAAACQiQhZAMRV7jIzXVhhkEoW53DI4iBkAQAAAAAAADISIQuAuCpcaSpZyiJNioajSe5NcrlDwyFLHiELAAAAAAAAkIkIWQDEVemqckVlk1MRdexsS3Z3kso9ZEIWZz4hCwAAAAAAAJCJCFkAxJXT61S7vUyS1Ll9bk8Z5omYkMVdSMgCAAAAAAAAZCJCFgBx1+ExU4b17mxMck+Sy0vIAgAAAAAAAGQ0QhYAcdefUylJCu6f2yFLVtSELJ4iQhYAAAAAAAAgExGyAIi7gSJTyRJpmNvThfms4ZCl0JfkngAAAAAAAABIBEIWAHEXLTOVLPbmuVvJEg6G5VFIkpRVQiULAAAAAAAAkIkIWQDEnb3GVLJ4OuduJYu/1T/6ta+UkAUAAAAAAADIRIQsAOLOs9CELDl9c7eSZaDdhCwR2eXJ8yS5NwAAAAAAAAASgZAFQNzlLjPThRUNzN2QJdhhQha/smWz25LcGwAAAAAAAACJQMgCIO4KV5pKltJos6LhaJJ7kxyDnSZkGbAzVRgAAAAAAACQqQhZAMRd6apyRWWTUxF17GxLdneSYiRkCRKyAAAAAAAAABmLkAVA3Dm9TrXbyyRJndubktyb5BjqHg5ZnIQsAAAAAAAAQKYiZAGQEB0eM2VY7865uS7LSMgSImQBAAAAAAAAMhYhC4CE6M+plCQF98/NkCXSOxyyuAlZAAAAAAAAgExFyAIgIQaKTCVLpGFuThc2ErKECVkAAAAAAACAjEXIAiAhouUmZLE3z81Klmj/cMjiIWQBAAAAAAAAMhUhC4CEsFeb6cI8nXMzZNFwyBLJImQBAAAAAAAAMhUhC4CE8Cw0lSw5fXNzujD5TchiEbIAAAAAAAAAGYuQBUBC5NaZkKVoYG5WstgCwyGLj5AFAAAAAAAAyFSELAASonCFmS6sNNqsaDia5N7MPnvQhCzKJmQBAAAAAAAAMpUz2R0AkJlKV5UrKpuciqhtZ5tKV5Unu0tTtukL98j7w+/KHg2Peb1z0Sk6a8sPZLPbJm3DMRyy2HIIWQAAAAAAAIBMRcgCICGcXqda7WUqi7aoY2tjWoUsuTd+TSsCzx/9xisbte/+j2jxhcdN2oZz0IQs9lxCFgAAAAAAACBTMV0YgITp8Jh1Wfp2NyW5J1NnRS3VBHZJkp667EfadM3d2nTN3drvrpMktT+7e0rtuEImZHHkEbIAAAAAAAAAmYpKFgAJ05dbJQ1sUXB/Y7K7MmVt21pUpj5FZNfaH79fnjyPJOmZ3/1eiw7u0sDLUwtZ3EMmZHHmE7IAAAAAAAAAmYpKFgAJEyyslCRF6tMnZGl83FSxNDgXjAYskjS0YJkkybF315Ta8YRNyOIqIGQBAAAAAAAAMhUhC4CEiZab6cLsLekzXVjvC6ZSpbWwbszr7tXmz3nNU6tk8RKyAAAAAAAAABmPkAVAwtirTSWLpzN9KlmiO0ylSqB62ZjXC9eaP1f1Ta2SxRs1IYuniJAFAAAAAAAAyFSELAASxrPQVLLk9KVPJUtWg6lUsS0fW8lS82YTspRareo52D1pOz7LhCzeYkIWAAAAAAAAIFMRsgBImNw6E7IUDaRPJUtZp6lUyTlpbCVLblWumu2mMqfhsWNPGRYNR+XTgCRCFgAAAAAAACCTEbIASJjCFSaUKI02KxKKJLk3kxsKDKlmaL8kqfKcuqPeb8ozr3VvPnbIEmgPjH7tKyVkAQAAAAAAADIVIQuAhCldVa6obHIqos7d7cnuzqQa/nZALoXll0/lJ1Yd9X5fhaluGdp+7JBloN0/+nVWUVZ8OwkAAAAAAAAgZRCyAEgYp9epNnu5JKlja+pPGdb2jAlPGrxLZXce/c9jdIkJWdyv7TpmOyMhi1++cdsBAAAAAAAAkBkY/QOQUJ0eM2VY3+6mJPdkcoGXTcjSUXr0VGGS5DvRvF7UfuxKlmCHCVkCNqYKAwAAAAAAADIZIQuAhOrLNdNuBfenfiWLfbepUAnNXzbu+6VnmNdrB3YrGo5O2E6oy4QsQQchCwAAAAAAAJDJCFkAJFSw0FSyROpTP2TJbTYVKq5V41ey1Jy5UENyKlsBtWyZ+O9DyAIAAAAAAADMDYQsABIqWm4qWewtqT9dWGWvqWQpOG38ShaXz6UG1yJJUtMTE6/LMtRtQpZBJyELAAAAAAAAkMkIWQAklL3GhCyeztSuZOlr7FNF1ARBNW8eP2SRpNYiU+XS/+LE67JEek3IMuQiZAEAAAAAAAAyGSELgITyLDDTheX2pnbI0vCYCU3abGXKn18w4XYDNSaAsXZNIWRxE7IAAAAAAAAAmYyQBUBC5daZSpbCYGpPF9a1yYQmjbkTV7FIkn25ed/XMPF0YdE+E7KEPYQsAAAAAAAAQCYjZAGQUEWrTMhSGm1WJBRJcm8mFtpmQpbeivEXvR+Rd6p5v6xr4koWq9+ELBEvIQsAAAAAAACQyQhZACRUyYoyRWWTUxF17m5Pdncm5DpgKlMii49dyVJ5tnm/JnxAg72D42/kNyFLNIuQBQAAAAAAAMhkhCwAEsrpdarNXi5J6tiauuuyFLaZypSsNceuZCk7vkK9ypVDUTU8tX/cbWwBE7JYPkIWAAAAAAAAIJMRsgBIuE5PpSSpb1dqhixW1FJtwFSylKw/diWLzW5Tg89s0/7M+Ouy2AZMyKJsQhYAAAAAAAAgkxGyAEi4vlyzLkvwQFOSezK+1lealat+RWRX7TmLJ92+q9RUuwy8PP66LI7gcMiSQ8gCAAAAAAAAZDJCFgAJFywyIUukPjUrWZqeMBUpDc6Fcue4J91+aKGpZHHsGz9kcQ6akMVOyAIAAAAAAABkNEIWAAkXLTPThdmbUzNk6X3ehCWthceeKmyEe5XZLq95/OnCXMMhiyOPkAUAAAAAAADIZIQsABLOXmMqWTxdqTldWHSnCUsCNcde9H5E4elmu6q+8StZXEMmZHHmE7IAAAAAAAAAmYyQBUDCeRaYSpbc3tSsZPHVm7DEVje1SpaaNy2VJJVareo52H3U+54wIQsAAAAAAAAwFxCyAEi43DpTyVIYTM1KltIuE7LknjK1Spbcqlw12c3fqeGxo6tZPOGAJMldSMgCAAAAAAAAZDJCFgAJV7TKBBKl0WZFQpEk92asocCQaob2S5IqzppaJYskNeeZbbs2Hb0uizdqKlkIWQAAAAAAAIDMRsgCIOFKVpQpKpuciqhjZ1uyuzNGw98OyKWw/PKp/MSqKe/XV2FClvD2oytZsoZDFm8xIQsAAAAAAACQyQhZACSc0+tUm71cktS5PbWmDGt72lSi1Gctk9059X8So8vM1GLug2NDFitqKVuELAAAAAAAAMBcQMgCYFZ0ekyVSO+rh5Pck7ECL5mQpLNk6lOFSZLvBLN9cdvY6cIGewflUFSSlFVCyAIAAAAAAABkMkIWALOis8xUfgQe+3uSezKWfa8JSUILprbo/YiyM832NcE9ioajo68H2vyjX2eXEbIAAAAAAAAAmYyQBcDsOP8CSVLlC39JckfGymsylSyuldOrZKk+Y4GG5FS2Amp+4Uh1zkC7CVmC8sjhdsSvowAAAAAAAABSDiELgFlx3KfOV0R21QVfUcMzB5PdnVEVfSZkKTx9epUsLp9L9e7FkqTmp46syxLsMCFLwEYVCwAAAAAAAJDpCFkAzIqipcXalrdekrTvB/cmuTdGb0OvKqJNkqTqc5ZOe/+2QlP90vfCkXVZBjtNyDJgJ2QBAAAAAAAAMh0hC4BZ03XGRZKk7MdSY8qww0/skSS12cqUP79g2vsP1AxPMbbrSCVLqGt4ujAHIQsAAAAAAACQ6QhZAMya2itNyLK643H1NfYluTdS50ZTgdKYO72pwkbYV5j9fIePhCxD3SZkGXQSsgAAAAAAAACZjpAFwKxZdMFyHXQulkchbb/xkWR3R0PbTTjSWzG9Re9H5J1s9ivrOjJdWLjHhCwhFyELAAAAAAAAkOkIWQDMGpvdptdWm2qWobuSP2WY+4AJRyJLYqtkqXqT2a8m/JoGewdNW70mZBlyE7IAAAAAAAAAmY6QBcCsynuPCVmW77tPkVAkqX0pbDOVLFknxFbJUrqqXL3KlUNR1T+xT9KRkCXs9sWnkwAAAAAAAABSFiELgFm16iNnqkd5KrXatOOXm5PWDytqqWbAhCylG2KrZLHZbWrwmX07Npq2rH4TskQ8VLIAAAAAAAAAmY6QBcCscvlc2l77D5Kkjl/dm7R+tLzUpFz1KyK7as5aFHM7XaWmCmbgpeF1WfwmZIlmEbIAAAAAAAAAmY6QBcCss95upgyrejF567I0P2UqTxqcC+XOccfcztBCE7I49pn2CFkAAAAAAACAuYOQBcCsO+5T5ysiu5YFt6rhmYNJ6UPvc6bypLUwtqnCRrhXm/3zWkzIYh8wIYuyCVkAAAAAAACATEfIAmDWFS0t1ra8MyRJ+25MTjVLdJcJRQI1sS16P6Jwrdm/qs+ENvYgIQsAAAAAAAAwVxCyAEiKrg1myrDsx5MTsvjqTShiWz6zSpbat5iQpdRqU/eBLjmHQxZbLiELAAAAAAAAkOkIWQAkxbyrTMhyfMfj6m/un/Xjl3aZSpbck2dWyZJTkaMme5UkqeGx3XIOmpDFQcgCAAAAAAAAZDxCFgBJsfAf6nTYUSu3hrT39y/M6rFD/SHVDu2XJFWcNbOQRZKa80wb3c/tlmtoOGTJI2QBAAAAAAAAMh0hC4CksNltqi87WZLU/dfnZ/XYDX87IKci8sunipOrZ9xeX6WZciy8bZfcwyGLM5+QBQAAAAAAAMh0hCwAkia48hRJkmvr7FaytD9rpgqrz1omm9024/aiS00li+fgbnnDJmRxFxKyAAAAAAAAAJmOkAVA0uScbSpZqhpnN2QJbDGL3neWzGzR+xHZJ5p2itp3yxshZAEAAAAAAADmCkIWAEmz4J0mZFk4tFu9Db2zdlz7PlPJElow8/VYJKn0DNNObXC3fNF+SZKniJAFAAAAAAAAyHSELACSpuS4Uh121EqS9v9py6wdN6/JVLK4VsWnkqXmzIUaklM+DShfPZIkbzEhCwAAAAAAAJDpCFkAJFV9mVmXpfuvz8/aMSv7TCVL4dr4VLI4vU7VuxePeS2rhJAFAAAAAAAAyHSELACSKrjSTBnm2jo767L0NvSqPNosSap+U3xCFklqKxzblq+UkAUAAAAAAADIdIQsAJIq52wTslQ1zk7I0vCYqWJptZcrf15+3NodqD0y9VhYDrlz3HFrGwAAAAAAAEBqImQBkFQL3mlCloVDu9Xb0Jvw43X93azH0pQTvyoWSbIfd6Q9v7Jls9vi2j4AAAAAAACA1EPIAiCpSo4rVYNjniRp//+9mPDjDW03lSw9lfFZ9H5E/qlH2huwM1UYAAAAAAAAMBcQsgBIuoYyU83S/Wjipwxzv2ZCluji+FayVJ59pL2gg5AFAAAAAAAAmAtSOmSJRCK69tprtXDhQmVlZWnx4sX62te+JsuyRrexLEtf+tKXVFlZqaysLJ177rnas2dPEnsNYLqCK03I4tqa+JClsM1MF5a1Jr6VLKWrytWjPEnSICELAAAAAAAAMCekdMjy7W9/Wz/60Y/0wx/+UK+++qq+/e1v6/rrr9fNN988us3111+vm266ST/+8Y+1adMmZWdn67zzzlMwGExizwFMR87ZJmSpakxsyGJFLdUOmEqW0jPiW8lis9t02GfaHHQRsgAAAAAAAABzgTPZHTiWZ599VhdffLHe/va3S5IWLFig22+/XZs3b5ZkqlhuvPFGffGLX9TFF18sSfr1r3+t8vJy3X333fqXf/mXpPUdwNQteOfJ0rXSwqHd6m3oVV5N3qT7ND3XoFDf4LSO07e/TavkV1gO1Zy1KNbuTqirdJl08HkNEbIAAAAAAAAAc0JKhyzr16/XT3/6U+3evVvLli3Tyy+/rKefflrf//73JUkHDhxQc3Ozzj333NF98vPztXbtWm3cuHHCkGVwcFCDg0cGZ3t7exP7FwFwTCXHlarBMU81kUPa/38vas3V5xxz+yfe/h2dc/9nYz5eg2uhFuS4Y95/IkOL6qSD0pCHkAUAAAAAAACYC1I6ZPnc5z6n3t5eLV++XA6HQ5FIRNddd53e8573SJKam5slSeXl5WP2Ky8vH31vPN/85jf1la98JXEdBzBtDWUnq6bpkLoffUGaJGTJ2/iQJGlAXg3JNa3jRG0OvXbuB7Ugxn4eS/XH/kkHnr5NkUvelYDWAQAAAAAAAKSalA5Z/vCHP+i2227T7373O61cuVIvvfSSrr76alVVVel973tfzO1ec801+tSnPjX6597eXtXW1sajywBiFFx5stR0l1xbJ1+XpbzXrKuy9yePafUV66Z9rHOmvcfULL1klRTapYUJah8AAAAAAABAaknpkOUzn/mMPve5z41O+7V69WodPHhQ3/zmN/W+971PFRUVkqSWlhZVVlaO7tfS0qI1a9ZM2K7H45HH40lo3wFMT87ZJ0t/laoajx2yBNoDqo7US5Kq3xTfxesBAAAAAAAAYDrsye7AsQQCAdntY7vocDgUjUYlSQsXLlRFRYUeffTR0fd7e3u1adMmrVs3/afbASTPgneeLElaOLRbPYd6Jtyu/rE9kqROW5GKlhbPSt8AAAAAAAAAYDwpHbJcdNFFuu6663Tffffptdde01133aXvf//7uuSSSyRJNptNV199tb7+9a/rnnvu0datW/Vv//Zvqqqq0jve8Y7kdh7AtJQcV6oGxzxJ0oE7t0y4XeffzVRhh7PrZqVfAAAAAAAAADCRlJ4u7Oabb9a1116rK6+8Uq2traqqqtKHPvQhfelLXxrd5rOf/az8fr+uuOIKdXd3a8OGDXrwwQfl9XqT2HMAsWgoO1k1TYfU/egL0tXnjLvN4Cu7JEk95UwVBgAAAAAAACC5Ujpkyc3N1Y033qgbb7xxwm1sNpu++tWv6qtf/ersdQxAQgRXniw13SXX1onXZXEeMJUs4cVUsgAAAAAAAABIrpSeLgzA3JJzzimSpKrGiUOWghZTyeI5nkoWAAAAAAAAAMlFyAIgZSz855PN/4d2q+dQz1HvW1FLNQFTyVJ8OiELAAAAAAAAgOQiZAGQMorrStTgmCdJOnDnlqPeb3+1TQVWt6KyqfZNS2a7ewAAAAAAAAAwBiELgJTSUGaqWbofPXrKsKYnTRVLo2OesoqyZrVfAAAAAAAAAPBGhCwAUkpwlVmXxbX16JCl5zkTsjQXsOg9AAAAAAAAgOQjZAGQUnLONpUsVY3PH/VeZIdZ9N5fxXosAAAAAAAAAJKPkAVASln4zyZkWTi0Rz2Hesa85603lSyqo5IFAAAAAAAAQPIRsgBIKcV1JWpwzJMkHbhzy5j3SjtMJUvOSVSyAAAAAAAAAEg+QhYAKaehzFSzdD96ZF2WSCii2tBeSVL5mYQsAAAAAAAAAJKPkAVAygmuOkWS5Np6JGRpePo1uTWkoDyqOn1esroGAAAAAAAAAKMIWQCknJyzTSVLVePzo6+1Pm3WY6n3LJXdyT9dAAAAAAAAAJKPkUoAKWfhP5uQZeHQHvUc6pEkBbaY9VjaS1j0HgAAAAAAAEBqIGQBkHKK60rU4DBTgh24c4skybbHVLIMzmM9FgAAAAAAAACpgZAFQEpqKDfrsnQ/atZlyWk0IYtzBSELAAAAAAAAgNRAyAIgJQVXminD3K+YdVkqes10YfmnMV0YAAAAAAAAgNRAyAIgJeWcbUKWyqYX5G/1qyrSIEmqfhOVLAAAAAAAAABSAyELgJS08J9NyLJwaI/2/t5MGdZhK1bR0uJkdgsAAAAAAAAARhGyAEhJxXUlanDMlyT1/OQOSVJjNlUsAAAAAAAAAFIHIQuAlNVQbqpZVuz4oySpp5yQBQAAAAAAAEDqIGQBkLKCK03IUmK1S5LCi1n0HgAAAAAAAEDqIGQBkLJyzj55zJ89x1PJAgAAAAAAACB1ELIASFkL/3lsyFKynkoWAAAAAAAAAKmDkAVAyiquK1GDY74kKSqbas5enOQeAQAAAAAAAMARhCwAUlpDualmaXTMU1ZRVpJ7AwAAAAAAAABHELIASGnBVadIkpoLlie5JwAAAAAAAAAwljPZHQCAYznhfz6kp9/2qvI/++FkdwUAAAAAAAAAxiBkAZDSChcXacO+Xye7GwAAAAAAAABwFKYLAwAAAAAAAAAAiAEhCwAAAAAAAAAAQAwIWQAAAAAAAAAAAGJAyAIAAAAAAAAAABADQhYAAAAAAAAAAIAYELIAAAAAAAAAAADEgJAFAAAAAAAAAAAgBoQsAAAAAAAAAAAAMSBkAQAAAAAAAAAAiAEhCwAAAAAAAAAAQAwIWQAAAAAAAAAAAGJAyAIAAAAAAAAAABADQhYAAAAAAAAAAIAYELIAAAAAAAAAAADEgJAFAAAAAAAAAAAgBoQsAAAAAAAAAAAAMSBkAQAAAAAAAAAAiAEhCwAAAAAAAAAAQAwIWQAAAAAAAAAAAGJAyAIAAAAAAAAAABADQhYAAAAAAAAAAIAYELIAAAAAAAAAAADEgJAFAAAAAAAAAAAgBoQsAAAAAAAAAAAAMSBkAQAAAAAAAAAAiAEhCwAAAAAAAAAAQAwIWQAAAAAAAAAAAGJAyAIAAAAAAAAAABADQhYAAAAAAAAAAIAYELIAAAAAAAAAAADEgJAFAAAAAAAAAAAgBoQsAAAAAAAAAAAAMXAmuwOpwLIsSVJvb2+SewIAAAAAAAAAAJJtJC8YyQ8mQsgiqa+vT5JUW1ub5J4AAAAAAAAAAIBU0dfXp/z8/Anft1mTxTBzQDQaVWNjo3Jzc2Wz2ZLdnaTo7e1VbW2t6uvrlZeXl+zuAMfE+Yp0wvmKdML5inTC+Yp0wvmKdML5inTC+Yp0wvmafizLUl9fn6qqqmS3T7zyCpUskux2u2pqapLdjZSQl5fHLznSBucr0gnnK9IJ5yvSCecr0gnnK9IJ5yvSCecr0gnna3o5VgXLCBa+BwAAAAAAAAAAiAEhCwAAAAAAAAAAQAwIWSBJ8ng8+vKXvyyPx5PsrgCT4nxFOuF8RTrhfEU64XxFOuF8RTrhfEU64XxFOuF8zVwsfA8AAAAAAAAAABADKlkAAAAAAAAAAABiQMgCAAAAAAAAAAAQA0IWAAAAAAAAAACAGBCyAAAAAAAAAAAAxICQJYXdcsstWrBggbxer9auXavNmzePef9DH/qQFi9erKysLJWWluriiy/Wzp07J233lVde0Zlnnimv16va2lpdf/31Y97/5S9/KZvNNuY/r9c7abtPPPGETjrpJHk8Hi1ZskS//OUvp/13QvrKtPP1Rz/6kY4//njl5eUpLy9P69at0wMPPDD5NwIpL9POVUk6fPiw/vVf/1XFxcXKysrS6tWr9fzzz0/aNlJfpp2vfX19uvrqqzV//nxlZWVp/fr1eu655yb/RiAtpNP52tTUpMsvv1zLli2T3W7X1VdffdQ2P/vZz3TmmWeqsLBQhYWFOvfcc7l2zSCZdr7G+u820kOmna+SdOONN6qurk5ZWVmqra3VJz/5SQWDwUn7jNSXTufrnXfeqbe+9a0qLS0dve9/6KGHxmzz1FNP6aKLLlJVVZVsNpvuvvvuqX0jkBaSdb5KUnd3t6666ipVVlbK4/Fo2bJluv/++2fc7h//+EctX75cXq9Xq1evnrRNxImFlHTHHXdYbrfb+sUvfmFt377d+uAHP2gVFBRYLS0to9v85Cc/sZ588knrwIED1gsvvGBddNFFVm1trRUOhydst6enxyovL7fe8573WNu2bbNuv/12Kysry/rJT34yus2tt95q5eXlWU1NTaP/NTc3H7O/+/fvt3w+n/WpT33K2rFjh3XzzTdbDofDevDBB6f1d0J6ysTz9Z577rHuu+8+a/fu3dauXbusz3/+85bL5bK2bds2g+8Uki0Tz9XOzk5r/vz51r//+79bmzZtsvbv32899NBD1t69e2fwnUIqyMTz9dJLL7VWrFhhPfnkk9aePXusL3/5y1ZeXp7V0NAwg+8UUkG6na8HDhywPv7xj1u/+tWvrDVr1lif+MQnjtrm8ssvt2655RZry5Yt1quvvmr9+7//u5Wfn8/5mgEy8XyNpV2kh0w8X2+77TbL4/FYt912m3XgwAHroYcesiorK61PfvKT0/8GIaWk2/n6iU98wvr2t79tbd682dq9e7d1zTXXWC6Xy3rxxRdHt7n//vutL3zhC9add95pSbLuuuuu2L9BSCnJPF8HBwetU045xbrgggusp59+2jpw4ID1xBNPWC+99NKM2n3mmWcsh8NhXX/99daOHTusL37xi5bL5bK2bt06w+8WJkPIkqJOO+0066qrrhr9cyQSsaqqqqxvfvObE+7z8ssvW5KOObD2P//zP1ZhYaE1ODg4+tp//dd/WXV1daN/vvXWW638/Pxp9fezn/2stXLlyjGvvfvd77bOO++80T/H8ndCesjE83U8hYWF1s9//vNpHQupJRPP1f/6r/+yNmzYMK12kR4y7XwNBAKWw+Gw7r333jHbnHTSSdYXvvCFaR0LqSfdztfXO/vss8cdBHyjcDhs5ebmWr/61a9iPhZSQyaerzNtF6krE8/Xq666ynrzm9885rVPfepT1hlnnBHzsZAa0vl8HbFixQrrK1/5yrjvEbJklmSerz/60Y+sRYsWWaFQaMr9nUq7l156qfX2t799zH5r1661PvShD035OIgN04WloFAopBdeeEHnnnvu6Gt2u13nnnuuNm7cOO4+fr9ft956qxYuXKja2toJ2964caPOOussud3u0dfOO+887dq1S11dXaOv9ff3a/78+aqtrdXFF1+s7du3H7PPGzduHNPfkXZH+hvL3wnpIRPP1zeKRCK644475Pf7tW7dumO2jdSVqefqPffco1NOOUXvete7VFZWphNPPFE/+9nPjtkuUl8mnq/hcFiRSOSoaRuysrL09NNPH7NtpLZ0PF9jEQgENDQ0pKKiori3jdmTyefrbPweYHZl6vm6fv16vfDCC6PT8uzfv1/333+/Lrjgghm3jeTJhPM1Go2qr6+Pz/o5INnn6z333KN169bpqquuUnl5uVatWqVvfOMbikQiM2p3uuNdiB9ClhTU3t6uSCSi8vLyMa+Xl5erubl5zGv/8z//o5ycHOXk5OiBBx7QI488MuaX7Y2am5vHbXfkPUmqq6vTL37xC/35z3/Wb3/7W0WjUa1fv14NDQ3Tbre3t1cDAwPT+jshvWTi+Tpi69atysnJkcfj0Yc//GHdddddWrFixTG+G0hlmXqu7t+/Xz/60Y+0dOlSPfTQQ/rIRz6ij3/84/rVr341yXcEqSwTz9fc3FytW7dOX/va19TY2KhIJKLf/va32rhxo5qamib/piBlpeP5Gov/+q//UlVV1VE3rkgvmXq+ztbvAWZXpp6vl19+ub761a9qw4YNcrlcWrx4sc455xx9/vOfn1G7SK5MOF+/+93vqr+/X5deeumU90F6Svb5un//fv3f//2fIpGI7r//fl177bX63ve+p69//eszaneibRh7TTxCljT3nve8R1u2bNGTTz6pZcuW6dJLLx1dLG7lypWj/wicf/75U25z3bp1+rd/+zetWbNGZ599tu68806VlpbqJz/5SaL+Gpgj0u18raur00svvaRNmzbpIx/5iN73vvdpx44dM24XqS+dztVoNKqTTjpJ3/jGN3TiiSfqiiuu0Ac/+EH9+Mc/nlG7SB/pdL7+5je/kWVZqq6ulsfj0U033aTLLrtMdjuXpHNFOp2vr/etb31Ld9xxh+666y4WE59D0ul85R4O6XS+PvHEE/rGN76h//mf/9GLL76oO++8U/fdd5++9rWvzahdpI9UPF9/97vf6Stf+Yr+8Ic/qKysLKa/FzJTIs7XaDSqsrIy/fSnP9XJJ5+sd7/73frCF77AfXwacya7AzhaSUmJHA6HWlpaxrze0tKiioqKMa/l5+crPz9fS5cu1emnn67CwkLddddduuyyy3T//fdraGhIkpmKQ5IqKirGbXfkvfG4XC6deOKJ2rt374R9nqjdvLw8ZWVlyeFwTPnvhPSSiefrCLfbrSVLlkiSTj75ZD333HP6wQ9+wM1qmsrUc7WysvKoCqvjjjtOf/rTnyZsF6kvU8/XxYsX68knn5Tf71dvb68qKyv17ne/W4sWLZrsW4IUlo7n63R897vf1be+9S399a9/1fHHHx+XNpE8mX6+JrpdzK5MPV+vvfZavfe979UHPvABSdLq1avl9/t1xRVX6Atf+AIPX6SpdD5f77jjDn3gAx/QH//4RypW54hkn6+VlZVyuVxyOByj2xx33HFqbm5WKBQat1JmKu1OtA1jr4nHJ1cKcrvdOvnkk/Xoo4+OvhaNRvXoo48ecz0Iy7JkWZYGBwclSfPnz9eSJUu0ZMkSVVdXSzLJ/lNPPTX6D4AkPfLII6qrq1NhYeG47UYiEW3dulWVlZUTHnvdunVj+jvS7kh/Y/07IfVl4vk6kWg0OtpfpJ9MPVfPOOMM7dq1a8w2u3fv1vz58ydsF6kvU8/XEdnZ2aqsrFRXV5ceeughXXzxxRO2i9SXjufrVF1//fX62te+pgcffFCnnHLKjNtD8mXy+Tob7WJ2Zer5GggEjgpSRgYaLcuaUdtInnQ9X2+//Xa9//3v1+233663v/3tU/77Ir0l+3w944wztHfvXkWj0dFtdu/ercrKygmnIptKu7GOdyEOLKSkO+64w/J4PNYvf/lLa8eOHdYVV1xhFRQUWM3NzZZlWda+ffusb3zjG9bzzz9vHTx40HrmmWesiy66yCoqKrJaWlombLe7u9sqLy+33vve91rbtm2z7rjjDsvn81k/+clPRrf5yle+Yj300EPWvn37rBdeeMH6l3/5F8vr9Vrbt2+fsN39+/dbPp/P+sxnPmO9+uqr1i233GI5HA7rwQcfnPLfCekrE8/Xz33uc9aTTz5pHThwwHrllVesz33uc5bNZrMefvjhOHzHkCyZeK5u3rzZcjqd1nXXXWft2bPHuu222yyfz2f99re/jcN3DMmUiefrgw8+aD3wwAPW/v37rYcfftg64YQTrLVr11qhUCgO3zEkU7qdr5ZlWVu2bLG2bNlinXzyydbll19ubdmyZcw+3/rWtyy322393//9n9XU1DT6X19f3wy/W0i2TDxfY20XqS8Tz9cvf/nLVm5urnX77bePXhMsXrzYuvTSS2f43UKypdv5etttt1lOp9O65ZZbxnzWd3d3j27T19c3ek5Lsr7//e9bW7ZssQ4ePBiH7xiSKZnn66FDh6zc3Fzrox/9qLVr1y7r3nvvtcrKyqyvf/3rM2r3mWeesZxOp/Xd737XevXVV60vf/nLlsvlsrZu3RqH7xiOhZAlhd18883WvHnzLLfbbZ122mnW3//+99H3Dh8+bJ1//vlWWVmZ5XK5rJqaGuvyyy+3du7cOWm7L7/8srVhwwbL4/FY1dXV1re+9a0x71999dWjxy0vL7cuuOAC68UXX5y03ccff9xas2aN5Xa7rUWLFlm33nrrtP5OSG+Zdr7+x3/8hzV//nzL7XZbpaWl1lve8hYClgyRaeeqZVnWX/7yF2vVqlWWx+Oxli9fbv30pz+d/BuBtJBp5+vvf/97a9GiRZbb7bYqKiqsq666asxNLNJbup2vko76b/78+aPvz58/f9xtvvzlL0/5e4LUlWnna6ztIj1k2vk6NDRk/fd//7e1ePFiy+v1WrW1tdaVV15pdXV1Tfl7gtSVTufr2WefPe75+r73vW90m8cff3zSbZC+knW+WpZlPfvss9batWstj8djLVq0yLruuuuscDg843b/8Ic/WMuWLbPcbre1cuVK67777pvCdwIzZbMsajEBAAAAAAAAAACmizVZAAAAAAAAAAAAYkDIAgAAAAAAAAAAEANCFgAAAAAAAAAAgBgQsgAAAAAAAAAAAMSAkAUAAAAAAAAAACAGhCwAAAAAAAAAAAAxIGQBAAAAAAAAAACIASELAAAAAAAAAABADAhZAAAAAMwp//7v/653vOMdye4GAAAAgAzgTHYHAAAAACBebDbbMd//8pe/rB/84AeyLGuWegQAAAAgkxGyAAAAAMgYTU1No1///ve/15e+9CXt2rVr9LWcnBzl5OQko2sAAAAAMhDThQEAAADIGBUVFaP/5efny2azjXktJyfnqOnCzjnnHH3sYx/T1VdfrcLCQpWXl+tnP/uZ/H6/3v/+9ys3N1dLlizRAw88MOZY27Zt0/nnn6+cnByVl5frve99r9rb22f5bwwAAAAgmQhZAAAAAMx5v/rVr1RSUqLNmzfrYx/7mD7ykY/oXe96l9avX68XX3xRb3vb2/Te975XgUBAktTd3a03v/nNOvHEE/X888/rwQcfVEtLiy699NIk/00AAAAAzCZCFgAAAABz3gknnKAvfvGLWrp0qa655hp5vV6VlJTogx/8oJYuXaovfelL6ujo0CuvvCJJ+uEPf6gTTzxR3/jGN7R8+XKdeOKJ+sUvfqHHH39cu3fvTvLfBgAAAMBsYU0WAAAAAHPe8ccfP/q1w+FQcXGxVq9ePfpaeXm5JKm1tVWS9PLLL+vxxx8fd32Xffv2admyZQnuMQAAAIBUQMgCAAAAYM5zuVxj/myz2ca8ZrPZJEnRaFSS1N/fr4suukjf/va3j2qrsrIygT0FAAAAkEoIWQAAAABgmk466ST96U9/0oIFC+R0clsFAAAAzFWsyQIAAAAA03TVVVeps7NTl112mZ577jnt27dPDz30kN7//vcrEokku3sAAAAAZgkhCwAAAABMU1VVlZ555hlFIhG97W1v0+rVq3X11VeroKBAdju3WQAAAMBcYbMsy0p2JwAAAAAAAAAAANINj1gBAAAAAAAAAADEgJAFAAAAAAAAAAAgBoQsAAAAAAAAAAAAMSBkAQAAAAAAAAAAiAEhCwAAAAAAAAAAQAwIWQD8//bsWAAAAABgkL/1HHaXRgAAAAAADJIFAAAAAABgkCwAAAAAAACDZAEAAAAAABgkCwAAAAAAwCBZAAAAAAAAhgAfvMXPSgiHxAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we plot the graph of the final_df along with the checked df.\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.lineplot(data=final_df, x=final_df.index, y='reading', color='blue')\n",
    "sns.lineplot(data=checked_df, x=checked_df.index, y='reading', color='red')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Reading')\n",
    "plt.title('Predicted Glucose Levels')\n",
    "\n",
    "plt.legend(['Actual+Predicted', 'Actual'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 10\n",
    "\n",
    "X, y = prepare_data(time_series_data, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], X.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8 * len(X))\n",
    "X_train, X_val = X[:split], X[split:]\n",
    "y_train, y_val = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 322ms/step - loss: 0.3545 - val_loss: 0.1484\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.2260 - val_loss: 0.0567\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0982 - val_loss: 0.0153\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0322 - val_loss: 0.0257\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0301 - val_loss: 0.0090\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0244 - val_loss: 0.0091\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0231 - val_loss: 0.0135\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0210 - val_loss: 0.0106\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0171 - val_loss: 0.0101\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0176 - val_loss: 0.0104\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0187 - val_loss: 0.0100\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0192 - val_loss: 0.0099\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0175 - val_loss: 0.0106\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0177 - val_loss: 0.0091\n",
      "Epoch 15/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0171 - val_loss: 0.0100\n",
      "Epoch 16/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0140 - val_loss: 0.0090\n",
      "Epoch 17/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0144 - val_loss: 0.0093\n",
      "Epoch 18/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0161 - val_loss: 0.0083\n",
      "Epoch 19/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0119 - val_loss: 0.0086\n",
      "Epoch 20/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0109 - val_loss: 0.0081\n",
      "Epoch 21/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0127 - val_loss: 0.0075\n",
      "Epoch 22/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0109 - val_loss: 0.0083\n",
      "Epoch 23/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 24/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 25/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 26/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0084 - val_loss: 0.0089\n",
      "Epoch 27/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 28/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 29/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 30/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0081 - val_loss: 0.0079\n",
      "Epoch 31/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0068 - val_loss: 0.0084\n",
      "Epoch 32/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 33/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0068 - val_loss: 0.0085\n",
      "Epoch 34/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0073 - val_loss: 0.0089\n",
      "Epoch 35/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 36/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 37/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0081 - val_loss: 0.0089\n",
      "Epoch 38/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 39/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 40/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 41/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 42/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 43/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0074 - val_loss: 0.0075\n",
      "Epoch 44/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0068 - val_loss: 0.0081\n",
      "Epoch 45/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 46/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 47/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0097 - val_loss: 0.0074\n",
      "Epoch 48/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 49/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0068 - val_loss: 0.0081\n",
      "Epoch 50/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 51/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 52/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 53/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 54/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 55/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 56/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 57/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0044 - val_loss: 0.0072\n",
      "Epoch 58/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0070 - val_loss: 0.0071\n",
      "Epoch 59/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 60/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 61/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 62/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 63/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 64/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 65/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0052 - val_loss: 0.0069\n",
      "Epoch 66/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0054 - val_loss: 0.0070\n",
      "Epoch 67/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0058 - val_loss: 0.0068\n",
      "Epoch 68/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 69/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 70/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 71/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 72/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 73/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 74/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - val_loss: 0.0066\n",
      "Epoch 75/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 76/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0061 - val_loss: 0.0066\n",
      "Epoch 77/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0051 - val_loss: 0.0076\n",
      "Epoch 78/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 79/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 80/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 81/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 82/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 83/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 84/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 85/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0055 - val_loss: 0.0072\n",
      "Epoch 86/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 87/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 88/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 89/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 90/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 91/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 92/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 93/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 94/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 95/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 96/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 97/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 98/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 99/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 100/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 101/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 102/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 103/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 104/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 105/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 106/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 107/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 108/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 109/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 110/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 111/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 112/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 113/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 114/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 115/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 116/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 117/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 118/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 119/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 120/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 121/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 122/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 123/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 124/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 125/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 126/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 127/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 128/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 129/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 130/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 131/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 132/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 133/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 134/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 135/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 136/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 137/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 138/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 139/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 140/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 141/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 142/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 143/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 144/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 145/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 146/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 147/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 148/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 149/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 150/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 151/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 152/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 153/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 154/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 155/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 156/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 157/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 158/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 159/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 160/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 161/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 162/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 163/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 164/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 165/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 166/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 167/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 168/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 169/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 170/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 171/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 172/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 173/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 174/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 175/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 176/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 177/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 178/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 179/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 180/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 181/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 182/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 183/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 184/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 185/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 186/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 187/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 188/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 189/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 190/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 191/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 192/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 193/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 194/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 195/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 196/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 197/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 198/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 199/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 200/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 201/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 202/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 203/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 204/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 205/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 206/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 207/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 208/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 209/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 210/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 211/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 212/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 213/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 214/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 215/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 216/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 217/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 218/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 219/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 220/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 221/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 222/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 223/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 224/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 225/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 226/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 227/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 228/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 229/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 230/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 231/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 232/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0023 - val_loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "# Building the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_features, 1)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=17)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=500, verbose=1, validation_data = (X_val, y_val) ,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGfCAYAAAB8wYmvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABPl0lEQVR4nO3deXxU5d3//9eZmcxkXyBkw0jYF4GALLlxq5VIUOuNa4HbX1na6l2rvds7alv6raDSNqKWH21F+NV+rUvdaqvevVubaqOxLhEUxIVNwLCTBILJZJ/MzPn9MclAJDAzkMwJ8H4+HkeSM2fOXCcDmbfX9bmuY5imaSIiIiLSh9msboCIiIhIKAosIiIi0ucpsIiIiEifp8AiIiIifZ4Ci4iIiPR5CiwiIiLS5ymwiIiISJ+nwCIiIiJ9ngKLiIiI9HkKLCIiItLnOU7mSStXruTBBx+kqqqK/Px8fvOb3zB16tRuj33xxRf5xS9+wfbt22lvb2f48OHccccdfOMb3wges2DBAp544okuzysqKqK0tDSs9vj9fvbv309SUhKGYZzMJYmIiEiUmaZJQ0MDOTk52Gwh+lDMCD333HOm0+k0H3vsMXPjxo3mzTffbKampprV1dXdHv/GG2+YL774orlp0yZz+/bt5ooVK0y73W6WlpYGj5k/f745c+ZM88CBA8Ht8OHDYbdpz549JqBNmzZt2rRpOw23PXv2hPysN0wzspsfFhQUMGXKFB5++GEg0LuRm5vL9773PX784x+HdY7zzz+fq666iqVLlwKBHpa6ujpefvnlSJoSVF9fT2pqKnv27CE5OfmkziEiIiLR5Xa7yc3Npa6ujpSUlBMeG9GQkMfjYd26dSxatCi4z2azUVhYSEVFRcjnm6bJ66+/ztatW1m2bFmXx8rLy8nIyCAtLY3LLruMn/3sZ/Tv37/b87S1tdHW1hb8vqGhAYDk5GQFFhERkdNMOOUcEQWWQ4cO4fP5yMzM7LI/MzOTLVu2HPd59fX1DBw4kLa2Nux2O4888giXX3558PGZM2dy3XXXMXjwYHbs2MFPfvITrrjiCioqKrDb7cecr6SkhHvvvTeSpouIiMhp7KSKbiOVlJTEhg0baGxspKysjOLiYoYMGcKll14KwJw5c4LHjhs3jvHjxzN06FDKy8uZPn36MedbtGgRxcXFwe87u5RERETkzBRRYElPT8dut1NdXd1lf3V1NVlZWcd9ns1mY9iwYQBMmDCBzZs3U1JSEgwsXzZkyBDS09PZvn17t4HF5XLhcrkiabqIiIicxiIKLE6nk0mTJlFWVsY111wDBIpuy8rKuP3228M+j9/v71KD8mV79+6ltraW7OzsSJonIiJnENM08Xq9+Hw+q5sip8But+NwOE552ZGIh4SKi4uZP38+kydPZurUqaxYsYKmpiYWLlwIwLx58xg4cCAlJSVAoN5k8uTJDB06lLa2Nl555RWeeuopVq1aBUBjYyP33nsv119/PVlZWezYsYMf/vCHDBs2jKKiolO6OBEROT15PB4OHDhAc3Oz1U2RHhAfH092djZOp/OkzxFxYJk9ezYHDx5k8eLFVFVVMWHCBEpLS4OFuLt37+6y+EtTUxPf/e532bt3L3FxcYwaNYo//OEPzJ49Gwgkr48//pgnnniCuro6cnJymDFjBkuXLtWwj4jIWcjv91NZWYndbicnJwen06lFQU9Tpmni8Xg4ePAglZWVDB8+PPQCcccR8TosfZHb7SYlJYX6+npNaxYROc21trZSWVnJoEGDiI+Pt7o50gOam5vZtWsXgwcPJjY2Nrg/ks9v3UtIRET6pJP9P3Hpe3rivdTfBhEREenzFFhERESkz1NgERER6YPy8vJYsWJFj5yrvLwcwzCoq6vrkfNZISor3YqIiJwNLr30UiZMmNAjQeP9998nISHh1Bt1hlBgOYF2n5+SV7bgN00WXTkKl+PY+xqJiIiEyzRNfD4fDkfoj98BAwZEoUWnDw0JnYDfNHnsnUoef3cnbV6/1c0RETlrmaZJs8dryRbu6h8LFizgzTff5Fe/+hWGYWAYBo8//jiGYfD3v/+dSZMm4XK5ePvtt9mxYwezZs0iMzOTxMREpkyZwj//+c8u5/vykJBhGPzud7/j2muvJT4+nuHDh/OXv/zlpH+mf/7znznvvPNwuVzk5eXxy1/+ssvjjzzyCMOHDyc2NpbMzExuuOGG4GN/+tOfGDduHHFxcfTv35/CwkKamppOui3hUA/LCTiOmobl95/2y9WIiJy2Wtp9jFn8D0tee9N9RcQ7Q39c/upXv+Kzzz5j7Nix3HfffQBs3LgRgB//+Mc89NBDDBkyhLS0NPbs2cOVV17Jz3/+c1wuF08++SRXX301W7du5dxzzz3ua9x777088MADPPjgg/zmN7/hpptuYteuXfTr1y+ia1q3bh1f//rXueeee5g9ezbvvvsu3/3ud+nfvz8LFizggw8+4L/+67946qmnuOCCCzh8+DBvvfUWAAcOHGDu3Lk88MADXHvttTQ0NPDWW2+FHexOlgLLCdiOWljRq8AiIiInkJKSgtPpJD4+PnhD4C1btgBw3333cfnllweP7devH/n5+cHvly5dyksvvcRf/vKXE96bb8GCBcydOxeAX/ziF/z6179m7dq1zJw5M6K2Ll++nOnTp3P33XcDMGLECDZt2sSDDz7IggUL2L17NwkJCXzta18jKSmJQYMGMXHiRCAQWLxeL9dddx2DBg0CYNy4cRG9/slQYDkBwzCw2wx8fhOfAouIiGXiYuxsus+a+8vFxZx6/eLkyZO7fN/Y2Mg999zD3/72t2AAaGlpYffu3Sc8z/jx44NfJyQkkJycTE1NTcTt2bx5M7Nmzeqy78ILL2TFihX4fD4uv/xyBg0axJAhQ5g5cyYzZ84MDkXl5+czffp0xo0bR1FRETNmzOCGG24gLS0t4nZEQjUsIdg7ulnUwyIiYh3DMIh3OizZeuI+Rl+e7XPnnXfy0ksv8Ytf/IK33nqLDRs2MG7cODwezwnPExMTc8zPxe/v+RrLpKQk1q9fz7PPPkt2djaLFy8mPz+furo67HY7r732Gn//+98ZM2YMv/nNbxg5ciSVlZU93o6jKbCE4OgILKphERGRUJxOJz6fL+Rx77zzDgsWLODaa69l3LhxZGVlsXPnzt5vYIfRo0fzzjvvHNOmESNGYLcHepQcDgeFhYU88MADfPzxx+zcuZPXX38dCASlCy+8kHvvvZcPP/wQp9PJSy+91Ktt1pBQCOphERGRcOXl5bFmzRp27txJYmLicXs/hg8fzosvvsjVV1+NYRjcfffdvdJTcjx33HEHU6ZMYenSpcyePZuKigoefvhhHnnkEQD++te/8vnnn3PJJZeQlpbGK6+8gt/vZ+TIkaxZs4aysjJmzJhBRkYGa9as4eDBg4wePbpX26welhA6A4svin+RRETk9HTnnXdit9sZM2YMAwYMOG5NyvLly0lLS+OCCy7g6quvpqioiPPPPz9q7Tz//PP54x//yHPPPcfYsWNZvHgx9913HwsWLAAgNTWVF198kcsuu4zRo0ezevVqnn32Wc477zySk5P517/+xZVXXsmIESP46U9/yi9/+UuuuOKKXm2zYfb2PKQoiOT21JGa/LPXONTo4R8/uISRWUk9em4RETlWa2srlZWVDB48mNjYWKubIz3geO9pJJ/f6mEJ4ciQkHpYRERErKLAEkLn4nGa1iwiIn3Vd77zHRITE7vdvvOd71jdvB6hotsQOhe7VdGtiIj0Vffddx933nlnt4/1dKmEVRRYQujsYdG0ZhER6asyMjLIyMiwuhm9SkNCIWhas4iIiPUUWEKwG53TmhVYRERErKLAEoJ6WERERKynwBKCw66l+UVERKymwBKCelhERESsp8ASwpEaFi0cJyIivSsvL48VK1aEdaxhGLz88su92p6+RIElBPWwiIiIWE+BJYTOGhbNEhIREbGOAksIdi3NLyJiPdMET5M1W5j3CP7tb39LTk4O/i+VEMyaNYtvfvOb7Nixg1mzZpGZmUliYiJTpkzhn//8Z4/9iD755BMuu+wy4uLi6N+/P7fccguNjY3Bx8vLy5k6dSoJCQmkpqZy4YUXsmvXLgA++ugjvvrVr5KUlERycjKTJk3igw8+6LG29QStdBtCRweLhoRERKzU3gy/yLHmtX+yH5wJIQ+78cYb+d73vscbb7zB9OnTATh8+DClpaW88sorNDY2cuWVV/Lzn/8cl8vFk08+ydVXX83WrVs599xzT6mJTU1NFBUVMW3aNN5//31qamr49re/ze23387jjz+O1+vlmmuu4eabb+bZZ5/F4/Gwdu1ajI46zZtuuomJEyeyatUq7HY7GzZsICYm5pTa1NMUWEKwa2l+EREJQ1paGldccQXPPPNMMLD86U9/Ij09na9+9avYbDby8/ODxy9dupSXXnqJv/zlL9x+++2n9NrPPPMMra2tPPnkkyQkBMLVww8/zNVXX82yZcuIiYmhvr6er33tawwdOhSA0aNHB5+/e/du7rrrLkaNGgXA8OHDT6k9vUGBJQSHim5FRKwXEx/o6bDqtcN00003cfPNN/PII4/gcrl4+umnmTNnDjabjcbGRu655x7+9re/ceDAAbxeLy0tLezevfuUm7h582by8/ODYQXgwgsvxO/3s3XrVi655BIWLFhAUVERl19+OYWFhXz9618nOzsbgOLiYr797W/z1FNPUVhYyI033hgMNn2FalhC6JwlpBoWERELGUZgWMaKrWPYJBxXX301pmnyt7/9jT179vDWW29x0003AXDnnXfy0ksv8Ytf/IK33nqLDRs2MG7cODweT2/91Lr4/e9/T0VFBRdccAHPP/88I0aM4L333gPgnnvuYePGjVx11VW8/vrrjBkzhpdeeikq7QqXAksImtYsIiLhio2N5brrruPpp5/m2WefZeTIkZx//vkAvPPOOyxYsIBrr72WcePGkZWVxc6dO3vkdUePHs1HH31EU1NTcN8777yDzWZj5MiRwX0TJ05k0aJFvPvuu4wdO5Znnnkm+NiIESP47//+b1599VWuu+46fv/73/dI23qKAksInUNCqmEREZFw3HTTTfztb3/jscceC/auQKAu5MUXX2TDhg189NFH/Md//McxM4pO5TVjY2OZP38+n376KW+88Qbf+973+MY3vkFmZiaVlZUsWrSIiooKdu3axauvvsq2bdsYPXo0LS0t3H777ZSXl7Nr1y7eeecd3n///S41Ln2BalhCUA+LiIhE4rLLLqNfv35s3bqV//iP/wjuX758Od/85je54IILSE9P50c/+hFut7tHXjM+Pp5//OMffP/732fKlCnEx8dz/fXXs3z58uDjW7Zs4YknnqC2tpbs7Gxuu+02/vM//xOv10ttbS3z5s2jurqa9PR0rrvuOu69994eaVtPMUwzzAnmfZjb7SYlJYX6+nqSk5N79Nw//vPHPPf+Hu6cMYLbL+t7VdMiImea1tZWKisrGTx4MLGxsVY3R3rA8d7TSD6/NSQUgnpYRERErKfAEoJqWEREJNqefvppEhMTu93OO+88q5tnCdWwhNC5cJx6WEREJFr+/d//nYKCgm4f62sr0EbLSfWwrFy5kry8PGJjYykoKGDt2rXHPfbFF19k8uTJpKamkpCQwIQJE3jqqae6HGOaJosXLyY7O5u4uDgKCwvZtm3byTStx9k7fkJah0VERKIlKSmJYcOGdbsNGjTI6uZZIuLA8vzzz1NcXMySJUtYv349+fn5FBUVUVNT0+3x/fr14//8n/9DRUUFH3/8MQsXLmThwoX84x//CB7zwAMP8Otf/5rVq1ezZs0aEhISKCoqorW19eSvrIfo5ociItY4A+aESIeeeC8jDizLly/n5ptvZuHChYwZM4bVq1cTHx/PY4891u3xl156Kddeey2jR49m6NChfP/732f8+PG8/fbbQOAiVqxYwU9/+lNmzZrF+PHjefLJJ9m/fz8vv/zyKV1cT9DS/CIi0dU55NHc3GxxS6SndL6XpzKcFVENi8fjYd26dSxatCi4z2azUVhYSEVFRcjnm6bJ66+/ztatW1m2bBkAlZWVVFVVUVhYGDwuJSWFgoICKioqmDNnzjHnaWtro62tLfh9T81j746W5hcRiS673U5qamqw5z4+Pj54V2E5vZimSXNzMzU1NaSmpmK320/6XBEFlkOHDuHz+cjMzOyyPzMzky1bthz3efX19QwcOJC2tjbsdjuPPPIIl19+OQBVVVXBc3z5nJ2PfVlJSUnUFrTRtGYRkejLysoCOG65gZxeUlNTg+/pyYrKLKGkpCQ2bNhAY2MjZWVlFBcXM2TIEC699NKTOt+iRYsoLi4Ofu92u8nNze2h1nZl17RmEZGoMwyD7OxsMjIyaG9vt7o5cgpiYmJOqWelU0SBJT09HbvdTnV1dZf91dXVJ0xONpuNYcOGATBhwgQ2b95MSUkJl156afB51dXVwdtcd34/YcKEbs/ncrlwuVyRNP2kqYZFRMQ6dru9Rz7s5PQXUdGt0+lk0qRJlJWVBff5/X7KysqYNm1a2Ofx+/3BGpTBgweTlZXV5Zxut5s1a9ZEdM7ecqSGpWduUCUiIiKRi3hIqLi4mPnz5zN58mSmTp3KihUraGpqYuHChQDMmzePgQMHUlJSAgTqTSZPnszQoUNpa2vjlVde4amnnmLVqlVAoNvvBz/4AT/72c8YPnw4gwcP5u677yYnJ4drrrmm5670JKmGRURExHoRB5bZs2dz8OBBFi9eTFVVFRMmTKC0tDRYNLt7925stiMdN01NTXz3u99l7969xMXFMWrUKP7whz8we/bs4DE//OEPaWpq4pZbbqGuro6LLrqI0tLSPnHTq+DS/FoPQERExDK6W3MIz6zZzU9e+oQZYzL57bzJPXpuERGRs5nu1tyDtDS/iIiI9RRYQtDND0VERKynwBKCalhERESsp8ASQnCWkE+BRURExCoKLCHoXkIiIiLWU2AJIRhYNCQkIiJiGQWWELQ0v4iIiPUUWEKwaWl+ERERyymwhOBQ0a2IiIjlFFhCsGtas4iIiOUUWEJwaOE4ERERyymwhKCl+UVERKynwBJCcGl+1bCIiIhYRoElBC3NLyIiYj0FlhDsWodFRETEcgosIWhpfhEREespsISgwCIiImI9BZYQHAosIiIillNgCcFmdNawaGl+ERERqyiwhOCwq4dFRETEagosIaiGRURExHoKLCF0Ls3vN8Gv0CIiImIJBZYQ7B01LAA+LR4nIiJiCQWWEOz2owKLelhEREQsocASQue0ZlBgERERsYoCSwj2owKLlucXERGxhgJLCF1qWBRYRERELKHAEoLNZtCZWRRYRERErKHAEgYtzy8iImItBZYwdNaxaHl+ERERayiwhKGzjkU9LCIiItZQYAmDlucXERGxlgJLGBz2wI9JgUVERMQaCixhsBmdNSwKLCIiIlZQYAmDZgmJiIhYS4ElDKphERERsZYCSxgcdg0JiYiIWEmBJQya1iwiImItBZYwaOE4ERERa51UYFm5ciV5eXnExsZSUFDA2rVrj3vso48+ysUXX0xaWhppaWkUFhYec/yCBQswDKPLNnPmzJNpWq/oDCzKKyIiItaIOLA8//zzFBcXs2TJEtavX09+fj5FRUXU1NR0e3x5eTlz587ljTfeoKKigtzcXGbMmMG+ffu6HDdz5kwOHDgQ3J599tmTu6JecKSGRYlFRETEChEHluXLl3PzzTezcOFCxowZw+rVq4mPj+exxx7r9vinn36a7373u0yYMIFRo0bxu9/9Dr/fT1lZWZfjXC4XWVlZwS0tLe3krqgXqIZFRETEWhEFFo/Hw7p16ygsLDxyApuNwsJCKioqwjpHc3Mz7e3t9OvXr8v+8vJyMjIyGDlyJLfeeiu1tbXHPUdbWxtut7vL1ps0rVlERMRaEQWWQ4cO4fP5yMzM7LI/MzOTqqqqsM7xox/9iJycnC6hZ+bMmTz55JOUlZWxbNky3nzzTa644gp8Pl+35ygpKSElJSW45ebmRnIZEXPYtDS/iIiIlRzRfLH777+f5557jvLycmJjY4P758yZE/x63LhxjB8/nqFDh1JeXs706dOPOc+iRYsoLi4Ofu92u3s1tHTkFa3DIiIiYpGIeljS09Ox2+1UV1d32V9dXU1WVtYJn/vQQw9x//338+qrrzJ+/PgTHjtkyBDS09PZvn17t4+7XC6Sk5O7bL1JPSwiIiLWiiiwOJ1OJk2a1KVgtrOAdtq0acd93gMPPMDSpUspLS1l8uTJIV9n79691NbWkp2dHUnzeo1qWERERKwV8Syh4uJiHn30UZ544gk2b97MrbfeSlNTEwsXLgRg3rx5LFq0KHj8smXLuPvuu3nsscfIy8ujqqqKqqoqGhsbAWhsbOSuu+7ivffeY+fOnZSVlTFr1iyGDRtGUVFRD13mqdHND0VERKwVcQ3L7NmzOXjwIIsXL6aqqooJEyZQWloaLMTdvXs3NtuRHLRq1So8Hg833HBDl/MsWbKEe+65B7vdzscff8wTTzxBXV0dOTk5zJgxg6VLl+JyuU7x8nqGzaZ7CYmIiFjJME3ztP8UdrvdpKSkUF9f3yv1LLf+YR1//7SKpbPO4xvT8nr8/CIiImejSD6/dS+hMKiGRURExFoKLGFwaEhIRETEUgosYbCph0VERMRSCixhCM4SOv3LfURERE5LCixhsHcuHOdTYBEREbGCAksY7FqaX0RExFIKLGHQ0vwiIiLWUmAJg101LCIiIpZSYAmDluYXERGxlgJLGIJL86voVkRExBIKLGE40sPit7glIiIiZycFljCohkVERMRaCixhUA2LiIiItRRYwqAaFhEREWspsIRBS/OLiIhYS4ElDHYtHCciImIpBZYw2AMdLFqaX0RExCIKLGGw23XzQxERESspsIRBNSwiIiLWUmAJg13TmkVERCylwBIGu9ExrVmBRURExBIKLGFw2LU0v4iIiJUUWMKgISERERFrKbCEQUvzi4iIWEuBJQw21bCIiIhYSoElDEdqWBRYRERErKDAEgYtzS8iImItBZYwqIZFRETEWgosYVANi4iIiLUUWMLQWcPiV2ARERGxhAJLGDrXYVEPi4iIiDUUWMLQuTS/alhERESsocAShiM9LFqaX0RExAoKLGE4sg6LxQ0RERE5SymwhOHItGYlFhERESsosIRB05pFRESspcASBodWuhUREbGUAksY7LqXkIiIiKUUWMKgpflFRESspcASBtWwiIiIWOukAsvKlSvJy8sjNjaWgoIC1q5de9xjH330US6++GLS0tJIS0ujsLDwmONN02Tx4sVkZ2cTFxdHYWEh27ZtO5mm9YrOHhbQ8vwiIiJWiDiwPP/88xQXF7NkyRLWr19Pfn4+RUVF1NTUdHt8eXk5c+fO5Y033qCiooLc3FxmzJjBvn37gsc88MAD/PrXv2b16tWsWbOGhIQEioqKaG1tPfkr60GdNSygXhYRERErGKZpRvQJXFBQwJQpU3j44YcB8Pv95Obm8r3vfY8f//jHIZ/v8/lIS0vj4YcfZt68eZimSU5ODnfccQd33nknAPX19WRmZvL4448zZ86cY87R1tZGW1tb8Hu3201ubi719fUkJydHcjlhaWrzct6SfwCw+b6ZxDntPf4aIiIiZxu3201KSkpYn98R9bB4PB7WrVtHYWHhkRPYbBQWFlJRURHWOZqbm2lvb6dfv34AVFZWUlVV1eWcKSkpFBQUHPecJSUlpKSkBLfc3NxILiNidtvRPSxaPE5ERCTaIgoshw4dwufzkZmZ2WV/ZmYmVVVVYZ3jRz/6ETk5OcGA0vm8SM65aNEi6uvrg9uePXsiuYyIda1h6dWXEhERkW44ovli999/P8899xzl5eXExsae9HlcLhcul6sHW3Zi6mERERGxVkQ9LOnp6djtdqqrq7vsr66uJisr64TPfeihh7j//vt59dVXGT9+fHB/5/NO5pzRYhgGnZlFa7GIiIhEX0SBxel0MmnSJMrKyoL7/H4/ZWVlTJs27bjPe+CBB1i6dCmlpaVMnjy5y2ODBw8mKyuryzndbjdr1qw54TmjrXN5fs0SEhERib6Ih4SKi4uZP38+kydPZurUqaxYsYKmpiYWLlwIwLx58xg4cCAlJSUALFu2jMWLF/PMM8+Ql5cXrEtJTEwkMTERwzD4wQ9+wM9+9jOGDx/O4MGDufvuu8nJyeGaa67puSs9RXabAT71sIiIiFgh4sAye/ZsDh48yOLFi6mqqmLChAmUlpYGi2Z3796NzXak42bVqlV4PB5uuOGGLudZsmQJ99xzDwA//OEPaWpq4pZbbqGuro6LLrqI0tLSU6pz6Wlanl9ERMQ6Ea/D0hdFMo/7ZOXf+yr1Le38s/grDMtI7JXXEBEROZv02josZ7POHhb/6Z/vRERETjsKLGHqnNrs9SmwiIiIRJsCS5jsqmERERGxjAJLmII9LFo4TkREJOoUWMKkGhYRERHrKLCESTUsIiIi1lFgCZNqWERERKyjwBImu5bmFxERsYwCS5iCK92qhkVERCTqFFjCFBwSUg2LiIhI1CmwhOnItGYFFhERkWhTYAmTim5FRESso8ASJtWwiIiIWEeBJUxHeli00q2IiEi0KbCESQvHiYiIWEeBJUxaml9ERMQ6Cixh0iwhERER6yiwhEmzhERERKyjwBKm4NL8qmERERGJOgWWMKmGRURExDoKLGFSDYuIiIh1FFjCZDdUwyIiImIVBZYw2e1ah0VERMQqCixh0tL8IiIi1lFgCZOW5hcREbGOAkuYOmtYVHQrIiISfQosYeqsYfErsIiIiESdAkuYHJrWLCIiYhkFljBpWrOIiIh1FFjCFFyaX4FFREQk6hRYwuRQDYuIiIhlFFjCpKX5RURErKPAEibVsIiIiFhHgSVM6mERERGxjgJLmFTDIiIiYh0FljAd6WHR0vwiIiLRpsASJtWwiIiIWEeBJUxHbn6owCIiIhJtCixh6qxhUdGtiIhI9J1UYFm5ciV5eXnExsZSUFDA2rVrj3vsxo0buf7668nLy8MwDFasWHHMMffccw+GYXTZRo0adTJN6zU2DQmJiIhYJuLA8vzzz1NcXMySJUtYv349+fn5FBUVUVNT0+3xzc3NDBkyhPvvv5+srKzjnve8887jwIEDwe3tt9+OtGm9yqGl+UVERCwTcWBZvnw5N998MwsXLmTMmDGsXr2a+Ph4HnvssW6PnzJlCg8++CBz5szB5XId97wOh4OsrKzglp6eHmnTelVnDYumNYuIiERfRIHF4/Gwbt06CgsLj5zAZqOwsJCKiopTasi2bdvIyclhyJAh3HTTTezevfu4x7a1teF2u7tsvc2hheNEREQsE1FgOXToED6fj8zMzC77MzMzqaqqOulGFBQU8Pjjj1NaWsqqVauorKzk4osvpqGhodvjS0pKSElJCW65ubkn/don1N4Cy8fAg8OI8bcAqmERERGxQp+YJXTFFVdw4403Mn78eIqKinjllVeoq6vjj3/8Y7fHL1q0iPr6+uC2Z8+e3mmYzQHufdB0EAc+QD0sIiIiVnBEcnB6ejp2u53q6uou+6urq09YUBup1NRURowYwfbt27t93OVynbAepsfYjvx4nLQDqmERERGxQkQ9LE6nk0mTJlFWVhbc5/f7KSsrY9q0aT3WqMbGRnbs2EF2dnaPnfOkGAbYYgCwB3tYtDS/iIhItEXUwwJQXFzM/PnzmTx5MlOnTmXFihU0NTWxcOFCAObNm8fAgQMpKSkBAoW6mzZtCn69b98+NmzYQGJiIsOGDQPgzjvv5Oqrr2bQoEHs37+fJUuWYLfbmTt3bk9d58mzx4C/HYfpBVTDIiIiYoWIA8vs2bM5ePAgixcvpqqqigkTJlBaWhosxN29ezc225GOm/379zNx4sTg9w899BAPPfQQX/nKVygvLwdg7969zJ07l9raWgYMGMBFF13Ee++9x4ABA07x8npARw+Lg0BgUQ2LiIhI9BmmaZ72n8But5uUlBTq6+tJTk7u2ZM/MBSaD/HZda8x45mD5KTE8u6i6T37GiIiImehSD6/+8QsoT7N3lnDEii6VQ+LiIhI9CmwhNIRWFTDIiIiYh0FllC+NEvId/qPoImIiJx2FFhCsTuBo3pYfAosIiIi0abAEoo9MJHKbqqGRURExCoKLKF0DAnZVMMiIiJiGQWWUL48JKQaFhERkahTYAnFfmwPyxmwdI2IiMhpRYEllGBgaQ/u0rCQiIhIdCmwhNJZw+L3Bnep8FZERCS6FFhC6Vzp1vQFd/k1JCQiIhJVCiyhdAQWw/QEd6mHRUREJLoUWELpXOn2qCEhLR4nIiISXQosoXRMazb8RxXdakhIREQkqhRYQulY6dbwe3HYDECzhERERKJNgSWUjh4WfB5sHYFFNSwiIiLRpcASSkcNC772Iz0sqmERERGJKgWWUDpmCeH3Yu8MLKphERERiSoFllA6A4vPc1QNi9/CBomIiJx9FFhCOWpIyK4aFhEREUsosIRi7yawqIZFREQkqhRYQgnWsLTjsAV+XFqaX0REJLoUWEI5alqzhoRERESsocASii2wcNzRQ0JaOE5ERCS6FFhC6exhOXpaswKLiIhIVCmwhNLttGYFFhERkWhSYAnlqCEhm6EaFhERESsosIQSLLptx2HXwnEiIiJWUGAJ5ahpzUdqWCxsj4iIyFlIgSUULc0vIiJiOQWWUIJL83tVwyIiImIRBZZQgtOaj65hUWARERGJJgWWUI4aErJ3LM2vwCIiIhJdCiyhBKc1e4M1LBoSEhERiS4FllCOupdQZw2LelhERESiS4EllC53a1YPi4iIiBUUWEIJ1rC0Y+8ouvUrsIiIiESVAksotqMCi6Y1i4iIWEKBJZSjpzUH8ooWjhMREYmykwosK1euJC8vj9jYWAoKCli7du1xj924cSPXX389eXl5GIbBihUrTvmcUWV3BL+MsQWCipbmFxERia6IA8vzzz9PcXExS5YsYf369eTn51NUVERNTU23xzc3NzNkyBDuv/9+srKyeuScUdU5JAS4bD5APSwiIiLRFnFgWb58OTfffDMLFy5kzJgxrF69mvj4eB577LFuj58yZQoPPvggc+bMweVy9cg5o6pzSAiIwQuohkVERCTaIgosHo+HdevWUVhYeOQENhuFhYVUVFScVANO5pxtbW243e4uW6+xH+lhcdLZw6LAIiIiEk0RBZZDhw7h8/nIzMzssj8zM5OqqqqTasDJnLOkpISUlJTglpube1KvHRbDCK526zQUWERERKxwWs4SWrRoEfX19cFtz549vfuCHXUsTpsCi4iIiBUcoQ85Ij09HbvdTnV1dZf91dXVxy2o7Y1zulyu49bD9Aq7E7wtODqGhFTDIiIiEl0R9bA4nU4mTZpEWVlZcJ/f76esrIxp06adVAN645w9rmNqs7Oj6FY9LCIiItEVUQ8LQHFxMfPnz2fy5MlMnTqVFStW0NTUxMKFCwGYN28eAwcOpKSkBAgU1W7atCn49b59+9iwYQOJiYkMGzYsrHNarmNIKAYfYFNgERERibKIA8vs2bM5ePAgixcvpqqqigkTJlBaWhosmt29ezc225GOm/379zNx4sTg9w899BAPPfQQX/nKVygvLw/rnJbrmNocY3gBp4aEREREoswwTfO0//R1u92kpKRQX19PcnJyz7/AryfC4c/584T/yx3vxfH1yefwwA35Pf86IiIiZ5FIPr9Py1lCUdfRw3KkhsXKxoiIiJx9FFjC0VHD4kBL84uIiFhBgSUc9s7AoqX5RURErKDAEg575ywhTWsWERGxggJLOI4ZElJgERERiSYFlnB0DgmZ6mERERGxggJLODoCi11L84uIiFhCgSUcnQvH0Q6oh0VERCTaFFjCYQssCGw3VcMiIiJiBQWWcHT0sDhM9bCIiIhYQYElHMEals51WLRwnIiISDQpsIRDQ0IiIiKWUmAJR8eQkL1zSOj0v1+kiIjIaUWBJRydQ0Id67B4fQosIiIi0aTAEo4vBRYNCYmIiESXAks4Opbmt3UGFg0JiYiIRJUCSzi+XMOiHhYREZGoUmAJhz0wS8imGhYRERFLKLCEo3NIyK8aFhERESsosISjY0jIpmnNIiIillBgCUfHkJBdPSwiIiKWUGAJR0cPi9HRw+L1aWl+ERGRaFJgCYdqWERERCylwBIOe2dgCfSweNTDIiIiElUKLOEI3q05cPPDdp9Ja7vPyhaJiIicVRRYwhFcOM6LYQR2uVvbLWyQiIjI2UWBJRwdNSyGz0OSKzBjqKHVa2WLREREzioKLOHomNaM30tSbCC8uFvUwyIiIhItCizh6BgSwuchOa4jsKiHRUREJGoUWMLRMSSEr53k2M4hIfWwiIiIRIsCSzjsRwLLkSEh9bCIiIhEiwJLODoDi7+d5LhAD4tmCYmIiESPAks4gjUs7SSr6FZERCTqFFjCYeuYJdSlhkVDQiIiItGiwBKOLkNCnbOE1MMiIiISLQos4Th6WnPHwnEaEhIREYkeBZZwdAYWIMUVuFOzhoRERESiR4ElHM6E4JepjkDPioaEREREokeBJRz2GLC7AEixewCtwyIiIhJNJxVYVq5cSV5eHrGxsRQUFLB27doTHv/CCy8watQoYmNjGTduHK+88kqXxxcsWIBhGF22mTNnnkzTek9HL0uyvQ3QSrciIiLRFHFgef755ykuLmbJkiWsX7+e/Px8ioqKqKmp6fb4d999l7lz5/Ktb32LDz/8kGuuuYZrrrmGTz/9tMtxM2fO5MCBA8Ht2WefPbkr6i3ORAASjEBgafL48Pr8VrZIRETkrBFxYFm+fDk333wzCxcuZMyYMaxevZr4+Hgee+yxbo//1a9+xcyZM7nrrrsYPXo0S5cu5fzzz+fhhx/ucpzL5SIrKyu4paWlndwV9ZaOHpYEWoO7VHgrIiISHREFFo/Hw7p16ygsLDxyApuNwsJCKioqun1ORUVFl+MBioqKjjm+vLycjIwMRo4cya233kptbe1x29HW1obb7e6y9bqOwOLwNhPvtAMKLCIiItESUWA5dOgQPp+PzMzMLvszMzOpqqrq9jlVVVUhj585cyZPPvkkZWVlLFu2jDfffJMrrrgCn8/X7TlLSkpISUkJbrm5uZFcxsnpnCnkaSIpVvcTEhERiSaH1Q0AmDNnTvDrcePGMX78eIYOHUp5eTnTp08/5vhFixZRXFwc/N7tdvd+aOmoYcHTSHJsBtXuNi0eJyIiEiUR9bCkp6djt9uprq7usr+6upqsrKxun5OVlRXR8QBDhgwhPT2d7du3d/u4y+UiOTm5y9brjuph0fL8IiIi0RVRYHE6nUyaNImysrLgPr/fT1lZGdOmTev2OdOmTetyPMBrr7123OMB9u7dS21tLdnZ2ZE0r3d1OySkGhYREZFoiHiWUHFxMY8++ihPPPEEmzdv5tZbb6WpqYmFCxcCMG/ePBYtWhQ8/vvf/z6lpaX88pe/ZMuWLdxzzz188MEH3H777QA0NjZy11138d5777Fz507KysqYNWsWw4YNo6ioqIcuswcEA0sjybEdPSwaEhIREYmKiGtYZs+ezcGDB1m8eDFVVVVMmDCB0tLSYGHt7t27sdmO5KALLriAZ555hp/+9Kf85Cc/Yfjw4bz88suMHTsWALvdzscff8wTTzxBXV0dOTk5zJgxg6VLl+JyuXroMntAsIalieQ49bCIiIhE00kV3d5+++3BHpIvKy8vP2bfjTfeyI033tjt8XFxcfzjH/84mWZE19FDQvGBHhatdisiIhIdupdQuLodElIPi4iISDQosISr2yEh9bCIiIhEgwJLuLrMEtKQkIiISDQpsITr6HVYOqc1a0hIREQkKhRYwnX0SrdaOE5ERCSqFFjCdVQPS3pCYLr1wYY2fH7TwkaJiIicHRRYwnVUYBmYFofLYaPN62fP4WZr2yUiInIWUGAJV+eQkLcFO36GZQS+/6y6wcJGiYiInB0UWMLV2cMC4GliRGYSoMAiIiISDQos4XK4wLAHvvY0MTyzs4el0cJGiYiInB0UWMJlGF0WjxuRoR4WERGRaFFgicRRy/N3Dgl9frAJr89vYaNERETOfAoskThqptA5aXHExdjx+Pzs0kwhERGRXqXAEomjAovNZhypY6nSsJCIiEhvUmCJxFGr3QIMD9axqPBWRESkNymwROKoHhaAEZ09LDXqYREREelNCiyRcB3Vw/Kvh7jA8y4Ar22s5od/+kir3oqIiPQSBZZIdPaw7HoHXl/K2PWLmXhuKh6fnz9+sJf5j63VjCEREZFeoMASic4all2BnhWj5TAvfnMsf751GmnxMXx+qIm/fnzAwgaKiIicmRRYItHZw9JcG9xluPczaVA/vn3xEAAefmM7ft3BWUREpEcpsETi6PsJdarfC8A3pg0iOdbB9ppG/vLR/ig3TERE5MymwBKJziGho3UEluTYGBZcOBiAHzy/gRtWvUvZ5upotk5EROSMpcASiRP0sAD85yVD+Pf8HOw2gw92fcG3nviAbz7+Pu9uP0Sb1xfFhoqIiJxZHFY34LQSIrAkuBz8eu5EfnrVaP7vO5U89nYlr2+p4fUtNcTG2Jg+KpN/n5BDeqKLGLvBeTkp2G1GFC9ARETk9KTAEomjA4srBdrquwSWThnJsSy6YjRfn5zLI2/s4F/bDnKwoY2/fXKAv31yZBZRXv94/vMrQ/n3/BwSXHorREREjscwTfO0n9LidrtJSUmhvr6e5OTk3nuh3e/BY0WBr8deD5/+GdLy4PsfnfBppmny6T43L324j/LPavD5TQ43emho8wLgcti4aFg6Y3KSGZmVxOVjMnE57L13HSIiIn1AJJ/f+t/6SBzdwzLyykBgqd8Hfj/Yjl8OZBgG485JYdw5KSxmDABNbV6eXbubP7y3i521zZRtqaFsSw0A2SmxgXqYCQPpl+Ds1UsSERE5HaiHJRKHP4dfTwx8/aOd8MAQMP1wx1ZIyjqpU5qmyZaqBt7ZfogdB5t4Y0sNVe5WAOw2g8mD0piQm8qUvH5MH52BYajmRUREzgzqYektqXkw6muQOgji0iApG9z7AnUsSVlgmvBZKWRPgOTssE5pGAajs5MZnR14o9q8Pv74/h6eXbuHTQfcrKk8zJrKw/x///qci4alU3LdOHL7xffeNYqIiPRB6mE5Ff93BuxZAzc+DuddC5/8Cf78LUgbDLe+C85TCxa7apt4d0ctH++t58X1e2nz+nE6bNw46RxuvngIeendzFoSERE5TUTy+a11WE5FyjmBP+v3BXpXKlYGvv+iEl5fesqnH9Q/gblTz6XkunH84weXMG1IfzxeP0+v2c1lvyzntqfXU/rpAco2V+tO0SIickbTkNCpCAaWvbD3fdi/HmwO8HvhvVWQNQ5GzIS2hsDQUf/hkDjgyPMPfBx43tjrAkNMJ5CXnsAzNxcEhofe3MEbWw92mSYdYzf46VVjmDdtkOpcRETkjKMhoVOx5rfw97sCdS12J2x8ESb8P4HHNvyh++f0GwIJAwIhpmZTYF9aHly1HLaXwcHNgSnT4+eApzEQfhLSjznNlio3j71dydbqRpravGyvaQRgTHYy6UkuRmclccOkcxiemdQLFy4iInLqIvn8VmA5FVtegefmgi0mECww4TtvB2pY3vg5bHsVarcHwkxiJtTv6fp8uxNiU6Dp4LHndiYGAgsE6mMm/j/QUB14jcFfgdTc4KFm40Hef+lXZG7/I1+YifxX++3sNjMBmDGwjR/G/5UBjha8rn586hjDn5rPJzs9lSvHZZObFkeMw0YSLRg1myFjVKBNzYdh22uBGh33fsyx19E8fBYJcS7weuD9R2H/h3DpIug/tHd+viIickZTYInaC++HX00AX1vg++Ez4KYXuh7T6g6s32KzB0JA1ceBfaYvEDwA/vxt2FEGgy+Bc6fB+7+D5toTv/aAUTCsMHDcpy8eaQPgcSRRmnQd1Ydqucn2GvFGW5enfmEmstPMwgT82HDhYbRtNw78eI0Y9sYO55zWz3CY3i7P2+nPpDp2MCNs+0hrDYSvNnsCHw/9T3KoJbVlJ0Z7M9hd+HMmEtNvEE5fU2CIKr4/HPoMtv0T7DGBdWyyxmEaNva729lW00hW82cMatyAvWE/ZssXNKbn4x43n34jLyQlOTUQCptr4eBWqNsN/YfBgJGBrxuqAsGp3xDw+8DfDjHx0OaGrX+HxupAT1h34aq9FbytgaDW28NpNZth17swfja4urmZZih+H2CccN0fEZHThQJLNDUehIYDgd6S/sPAfhJlQaYZ+CDuHPrxNAV6ZtLyoG4P/OuBQL1L6rmBD9a97wfWfzlazkQ4fz5seDrw+FE+cYzlVXMqGeYhrjAqSPd106NDIMikGY3B7zf7z+Vt/1hacDLf/iopxpHC3hozlf1mPybYPo/8ek9COw5i8IY8zsTAIPBX2md3YZh+bP724OP1ySNosydg2pw4XbHEt9firN2C4fdiOmIxEzMxEjPB4Qy8D7YYTFcydR4btU0emhNyiR96IckxXmLdu0hITMQRmwS7K2DPWsgcC6O/Bo5YaK2npfEwNbWHabfHk9Swk4zP/4Rh+mHAaJjzdCBA+drhcGUgXA0Y1X2Q8fvho2fh9Z8BJlz034H3OyY2/B+i3wcHNkDGGIiJC/95IiK9RIHlTNfyBXxeDjteB8MGE+fBOZMCj3k98N5KOLQ90Ksz6EIYd+OR/yP3+wK3GGitB0z8fh9tXj8b/YN4vy6Z1KbtZLs/YVfsGHY58jAxcdptXHiOkzFtH7L180r21rWxO7uIuLhExu74LQPr1vKpbxAftg+i2RZPkr+Bkb7P6IebBuIxMOlHA4dJ4nXfROKMNgpt68kw6rDhJ8bwkxgD+4wsXmsZSaVxDilJSVza/i8ua3+TZJqCl+43DXaZGewz0xlu20emUcdhM5Fqsx95RhVxhueYH9d2fw77zf5caPsUu2H9X/dm4oinhXYctNticZmt2Dt6s0wM2uMy8Nqc+GxOsMdg83txth4ixlPX5Twew8XB5POwpQ2if3I8TqcrEJxtjkAvlj3wfGJTA+de81uM2s9oTRrE1vE/YnBcE8mHPoJzJsOw6YFwXL830GuVMSYQ2kwzENxMX6AHCgL7GmugblfgNbLzob0Z1j8Z6EWzuwIF6YMvhsxxPdsb1FIHez+AvIsiC2si0icpsIjlTNOk2eOjodVLQ2s77lYvftPEYTOIsdtwOmzE2G3E2A0ykmJxOgIfah6vnxi7cWSmk2nS0FDHnn37+bzeZJvbRnN74DiPz4/paaLJjMXr8+P1thPnOUyT34nHD7HeenxeP3sZgInBOY46xhg7SXT4Mb1t1Dc0Ut3mZL1vMNXeRAYYdWRQR6bxBXb8NOMiBh/JRhOpThiREUdGyw6yGzbS4I/lczMTu+kllUa2mOey1j+S823buNC2ES923GYCbuKxuxJItnnw+Pz8rvkSdpmZrHL+ism2z4I/r2bTRSNxZBh1x/2Zus04HvZeQzOx3Or4CwONEMOGp8hnODAAW0eY8senY8SlYdTvBW/LkQNTzwVPMzQfOvYkCQNg1FWBniO/L9AzaPoCRectdRDfL7AQY0I6uJLBlRQYyqvfHVguIOWcQIByxAaG0v52BzRW4U3MZlPePEaMnUxsSlagd9MZHwjsh7bCropADdjQr0JW/pHQ5OvobbPHBP40zcB2olDVfBh2vQPpI2HACPC2BYb2+g8NtLcv2rMW3v5/YUQRTPxG4H9ewrHpL7D5L2DYAz/7qbdAUmbPts3vhwMfBoJ02mANb/Y00wzURSZmWN2SsCiwiETINE28fpN2nx+P14+/419FZ0VLSlwMNptxzHP21bWwvaaRdp+J3zRxt7RT39JOjN1GvNPO1MH9GNT/yAJ/ew4381l1A7EOGxyuZMuBOrYf9rLPn0ajx4+j5TD9fNUkOyHO8GL422nzGxw2EznsHEhaahrZKbFkJbtIaNiJY//71NdW0dDcgtPw4sCHAx9OvB1/tpNqNJFME2/7x/F3+6X8l+uvFLW/zjZ/Nmv8o/k32ybG2yrZa6az3+zPSGNPl+G/7vgxqKE/yTQST+BWEvtt2fyPtwD8PkYae5hq20Ki0dpj71EnH3bs+Lq+Fxi0OZKI9bqPOd60x4IzHsPvC9xhHTp6i4zAMJzpD3ztSoaE/oGv21sCQ3OuJDjwUUdRPYGlCr7YFXie3QV5F0JbY2BYODYFf0IGtsQMiEsN9Ex5GgPhzOcJnD82pctmuvdjbHs1cNsPvy+wYvaYayB3aqD3tOPqaKwJDBvGpsDA8wNBEPNI4GqrD/S8OpMCPV//+EngNTvbPGkBDLoocE5PQ6BtXk/g+mJTAu19bxW8s6LrDy8mHqbeDKNnBc7jbQm0MyYucP1Hh43aHYGVvh0uyC0IBNKqjwND20OnB3rj9q+Hv/8Q9q0LPMeZGKhnO/8bcM6UI0OVfl+g4P/g1sDPImPMkfoyvz9Qo+ZwRfLX5kt/KUxoOhRYM+uLXYGwm3JOYKjW4ex63Bc7A+09XAnnFgR6rcMNgL3B5w2E8vj+gckcR/3PHZVvQtl9gfYOnQ5FP4eM0YHH/T6o/jRQMuBpCtTRneQtZXqSAovIWaamoZX65nZ8ponfDz6/SbvfT1t7oCfK6/MzqH8CQ9ITgsGrtrGN93ceZntNI1WH3TicsbhibDS1tmM2HaKltY2mtnYOtMVyuMlDSvMuko0m9pnpHDD7046DWNr4iu0jwOCf/vPxYWdIegJOh40dVV/wb7ZNTLetp5/RgA8bfgz8po1G4nATT3/cnGvUkGw0kUQLyUYzcbRRZfZjv9mfgcYh8owq7IZJqxnD476ZPOL9d2bZ3+GqmHWk+OvJNA7T76jaq0YzlvX+4bTg4kLbpz0SmvbbB5LpO4CdQO2YxxaL09/zYawnfRabT65nB3H+xtAHH+V583I+96Yz0/4+E23bT3isaXeBw4Vpd2LrroetQzOxGPiJIxCiWnFiAC66DuF6EzLBHovRVo+9re7I68QPgORsDMMGh7YFhiD7DTlS19cZopwJHaHHCBwDgWDjiAsMITbXBsLh4Z2B4PYl7fZ4WgZeiD8mAZprSfxiI47Ww12vOSEDI3cqDBhJq8/A3eKhX5wdh2F29CB2bK31+A99ht/Tgj17HEa/IccW9Zsd/zHNQCj2eQKh0tExvOuIDQQoW0xgLa+aTVD5FrR2/GxiUwK9l0nZ+Pesxdawv8vp/Ri4k0eQkDkMx953MVq+OPLSjljMMbOwxffHY9qpawPD305/WwM20w9x/QI1mZ7mQI9kfP/Adv68Hg1svR5YVq5cyYMPPkhVVRX5+fn85je/YerUqcc9/oUXXuDuu+9m586dDB8+nGXLlnHllVcGHzdNkyVLlvDoo49SV1fHhRdeyKpVqxg+fHhY7VFgEel9re0+aps8tHv9tPv8tHX86fH6afeZeHw+MpNjGZOdjGEY7KtrYVt1A/vqWtj3RQv761rw+PzYDAO7zcBuGNhsBgZwuMnDgfpWqt2t1DYd+RDLPyeFC4b2Y+O+Ojbtd5OeHM/QAYnMmzaI/NxUHn93J+9sP8QgVxOpppsPv4hhm9tJjCPwC9XX3oqrpYYYsw0Tg1ozOVBTZTRgYOI2E2jHjgM/SUYz/Qn00LTgJNFopR9utpjn8rmZwwC+4BLbJ3xuZrPBHMpIYy9TbZupNVM4YPYjyWghnXrSjXqSjcBQZRNxNJpxtGMnyWghmWaSjGaSaSLZaKbVdPIv/3g2mMNoN+2Ms1Vylf09BhpdP/zrzER2mZmkG/WMMypJ6AhhJoHeJbcZTz2JJNFMIi284PsKK32zSKOROfY3uMT+MeONz2nHTiNxNJmxeIghiWaSO9rTSByL2xfwP/6LOl7VZIbtA66xv8PFtk9IMlo4Ea9p413/eRiYTLRtx008G/2DOc9WSY4R+NBvN+38r38aJe1zOUwy44xKvm5/g5n297uEToB6M54t5rnkGzuINdq7e8lT4sfgoJHOTl86sbQxyKgm1Wg65jiPaWeTmcdecwAX2T7p9phoayYWF23Y6frx3WrG8KzvMv7HdyHfcfwvM+1dJ2C4zXg2+IeSaLRwfogw2p12HDgWH8TowWG8Xg0szz//PPPmzWP16tUUFBSwYsUKXnjhBbZu3UpGxrFjZu+++y6XXHIJJSUlfO1rX+OZZ55h2bJlrF+/nrFjxwKwbNkySkpKeOKJJxg8eDB33303n3zyCZs2bSI2NnRhnQKLyJnD6/Pj7RiTi4059f+T83j97PmiGXfHUJ1pQqvXR2u7jxaPj9gYO+mJLpwOA4+3Y1jQ56fd66et4892n0mM3cBhN9h5qJmdtU2kxMXQL8HJ4SYPXzR7mDQojWlD0qlvaWd/XQtfNHv4ormdL5o8HGpsY399K3XNHuw2g/4JTq4cl01+bio7ahppbPMyIMlFbaOH9z6vZffhZupb2jFNcDps9EtwMjA1jiaPl121gWsJXIOftnYf/RNdDEyNo7Xdx+FmD8MzEpk0KI1mj4+dh5r4dL+bykNNpMbFkJbgDATOdj8Ou4HLYSM9PobMFBdThwxg6uB+nJMWGJr5rLqRLQfcfHbgCyr3V/NRdTv1rT5ctBOLJ/Cn4SEWD/vN/tRzZIabYUCiy0HBoFS+PaqNnPQ0muJyaPXbaPP6aW0P1Lhtq25g8wE39bVV2N17MX3teA0HZJ7HgJRENu6qIrVxB/0MN0687DBzcJvxjLLtYQB1NBOLiUEsbcQZHuJowwCaCQwZxRJoX6zhwW0msNPMZJeZyV5zAG0Ehn/SE11MOTeFNPcWBhx+H8OAdkcSG70Deb/1HBzOWGJjbNQ3NjOBrYwxdjHIqALA4bDT5iXYg2hiw4dBi+mi0szGg4Oxtp1k8AVfFvhbbmBi4MWGFwcGJi7acdKO0/AG/sRLjZnK52Y26/wj+MgcigMfg40qhht7GWgcYpM5iL3JE7lodC6TBqXh85vU7N/FwY3lONx7+MA/gg3mMHzYAZNptk38m20zMXiJwUtSjEm7aXCgPREfdtKMBhz4aMaFEx9pNOCy+bnmvv895X+TR+vVwFJQUMCUKVN4+OGHAfD7/eTm5vK9732PH//4x8ccP3v2bJqamvjrX/8a3Pdv//ZvTJgwgdWrV2OaJjk5Odxxxx3ceeedANTX15OZmcnjjz/OnDlzjjlnW1sbbW1H1hZxu93k5uYqsIiIHIdpmqd8247OWq/A1x37jvq//KM/TZx22zF1Xyf7mu4WL+1+Py0eH4ebPDS0erEZYLMFeusMOnqbzMDxJuA3zcBoC9DY5uVwkweHzSAt3onPNKlvbqd/opORWUkMTI0L62fj9fmpbmhjb0egzM9NJSPJxe7DzWyrbqTN66fN68PTcaPa8eekck5aHHXN7RxqbONQYxu1jYEA6zNNUuJicNptR0aGMOloNn7zyNd0XJNpQkaSi9x+8cQ77fj8JttrGtl1uJnJg9KYNCit2+twt7bT4vHh9ZskOO24HHa8/kAQ9/r8uBx2UuJj8Pr8fLS3nr1fNOM3TWIddjJTYnHabbS0+2j3+rlg2LErr5+KSAJLRIuGeDwe1q1bx6JFi4L7bDYbhYWFVFRUdPuciooKiouLu+wrKiri5ZdfBqCyspKqqioKCwuDj6ekpFBQUEBFRUW3gaWkpIR77703kqaLiJzVeuIeY4ZhEGOP7r3KDMMgJT4m+H1uv/iovv7RHHYbA1PjGJjadR2jQf0TuhTXf1lWip2slN6Zhh/O7VeSY2NIjo350t5jey8ddhuTOoJPXxTRQNShQ4fw+XxkZnad5paZmUlVVVW3z6mqqjrh8Z1/RnLORYsWUV9fH9z27NnT7XEiIiJyZjgt79bscrlwuU5hSpuIiIicViLqYUlPT8dut1NdXd1lf3V1NVlZ3c/nzsrKOuHxnX9Gck4RERE5u0QUWJxOJ5MmTaKsrCy4z+/3U1ZWxrRp07p9zrRp07ocD/Daa68Fjx88eDBZWVldjnG73axZs+a45xQREZGzS8RDQsXFxcyfP5/JkyczdepUVqxYQVNTEwsXLgRg3rx5DBw4kJKSEgC+//3v85WvfIVf/vKXXHXVVTz33HN88MEH/Pa3vwUCBVU/+MEP+NnPfsbw4cOD05pzcnK45ppreu5KRURE5LQVcWCZPXs2Bw8eZPHixVRVVTFhwgRKS0uDRbO7d+/GdtSiMhdccAHPPPMMP/3pT/nJT37C8OHDefnll4NrsAD88Ic/pKmpiVtuuYW6ujouuugiSktLw1qDRURERM58WppfRERELBHJ57dukykiIiJ9ngKLiIiI9HkKLCIiItLnKbCIiIhIn6fAIiIiIn2eAouIiIj0eaflvYS+rHNmttvttrglIiIiEq7Oz+1wVlg5IwJLQ0MDALm5uRa3RERERCLV0NBASkrKCY85IxaO8/v97N+/n6SkJAzD6NFzu91ucnNz2bNnjxals5DeB+vpPegb9D5YT+9BzzFNk4aGBnJycrqskt+dM6KHxWazcc455/TqayQnJ+svZh+g98F6eg/6Br0P1tN70DNC9ax0UtGtiIiI9HkKLCIiItLnKbCE4HK5WLJkCS6Xy+qmnNX0PlhP70HfoPfBenoPrHFGFN2KiIjImU09LCIiItLnKbCIiIhIn6fAIiIiIn2eAouIiIj0eQosIiIi0ucpsISwcuVK8vLyiI2NpaCggLVr11rdpDPWPffcg2EYXbZRo0YFH29tbeW2226jf//+JCYmcv3111NdXW1hi88M//rXv7j66qvJycnBMAxefvnlLo+bpsnixYvJzs4mLi6OwsJCtm3b1uWYw4cPc9NNN5GcnExqairf+ta3aGxsjOJVnN5CvQcLFiw45t/GzJkzuxyj9+DUlJSUMGXKFJKSksjIyOCaa65h69atXY4J53fQ7t27ueqqq4iPjycjI4O77roLr9cbzUs5YymwnMDzzz9PcXExS5YsYf369eTn51NUVERNTY3VTTtjnXfeeRw4cCC4vf3228HH/vu//5v//d//5YUXXuDNN99k//79XHfddRa29szQ1NREfn4+K1eu7PbxBx54gF//+tesXr2aNWvWkJCQQFFREa2trcFjbrrpJjZu3Mhrr73GX//6V/71r39xyy23ROsSTnuh3gOAmTNndvm38eyzz3Z5XO/BqXnzzTe57bbbeO+993jttddob29nxowZNDU1BY8J9TvI5/Nx1VVX4fF4ePfdd3niiSd4/PHHWbx4sRWXdOYx5bimTp1q3nbbbcHvfT6fmZOTY5aUlFjYqjPXkiVLzPz8/G4fq6urM2NiYswXXnghuG/z5s0mYFZUVESphWc+wHzppZeC3/v9fjMrK8t88MEHg/vq6upMl8tlPvvss6ZpmuamTZtMwHz//feDx/z97383DcMw9+3bF7W2nym+/B6YpmnOnz/fnDVr1nGfo/eg59XU1JiA+eabb5qmGd7voFdeecW02WxmVVVV8JhVq1aZycnJZltbW3Qv4AykHpbj8Hg8rFu3jsLCwuA+m81GYWEhFRUVFrbszLZt2zZycnIYMmQIN910E7t37wZg3bp1tLe3d3k/Ro0axbnnnqv3oxdVVlZSVVXV5eeekpJCQUFB8OdeUVFBamoqkydPDh5TWFiIzWZjzZo1UW/zmaq8vJyMjAxGjhzJrbfeSm1tbfAxvQc9r76+HoB+/foB4f0OqqioYNy4cWRmZgaPKSoqwu12s3Hjxii2/sykwHIchw4dwufzdfmLB5CZmUlVVZVFrTqzFRQU8Pjjj1NaWsqqVauorKzk4osvpqGhgaqqKpxOJ6mpqV2eo/ejd3X+bE/076CqqoqMjIwujzscDvr166f3pofMnDmTJ598krKyMpYtW8abb77JFVdcgc/nA/Qe9DS/388PfvADLrzwQsaOHQsQ1u+gqqqqbv+tdD4mp8ZhdQNEOl1xxRXBr8ePH09BQQGDBg3ij3/8I3FxcRa2TMRac+bMCX49btw4xo8fz9ChQykvL2f69OkWtuzMdNttt/Hpp592qaET66mH5TjS09Ox2+3HVIBXV1eTlZVlUavOLqmpqYwYMYLt27eTlZWFx+Ohrq6uyzF6P3pX58/2RP8OsrKyjilE93q9HD58WO9NLxkyZAjp6els374d0HvQk26//Xb++te/8sYbb3DOOecE94fzOygrK6vbfyudj8mpUWA5DqfTyaRJkygrKwvu8/v9lJWVMW3aNAtbdvZobGxkx44dZGdnM2nSJGJiYrq8H1u3bmX37t16P3rR4MGDycrK6vJzd7vdrFmzJvhznzZtGnV1daxbty54zOuvv47f76egoCDqbT4b7N27l9raWrKzswG9Bz3BNE1uv/12XnrpJV5//XUGDx7c5fFwfgdNmzaNTz75pEt4fO2110hOTmbMmDHRuZAzmdVVv33Zc889Z7pcLvPxxx83N23aZN5yyy1mampqlwpw6Tl33HGHWV5eblZWVprvvPOOWVhYaKanp5s1NTWmaZrmd77zHfPcc881X3/9dfODDz4wp02bZk6bNs3iVp/+GhoazA8//ND88MMPTcBcvny5+eGHH5q7du0yTdM077//fjM1NdX8n//5H/Pjjz82Z82aZQ4ePNhsaWkJnmPmzJnmxIkTzTVr1phvv/22OXz4cHPu3LlWXdJp50TvQUNDg3nnnXeaFRUVZmVlpfnPf/7TPP/8883hw4ebra2twXPoPTg1t956q5mSkmKWl5ebBw4cCG7Nzc3BY0L9DvJ6vebYsWPNGTNmmBs2bDBLS0vNAQMGmIsWLbLiks44Ciwh/OY3vzHPPfdc0+l0mlOnTjXfe+89q5t0xpo9e7aZnZ1tOp1Oc+DAgebs2bPN7du3Bx9vaWkxv/vd75ppaWlmfHy8ee2115oHDhywsMVnhjfeeMMEjtnmz59vmmZgavPdd99tZmZmmi6Xy5w+fbq5devWLueora01586dayYmJprJycnmwoULzYaGBguu5vR0ovegubnZnDFjhjlgwAAzJibGHDRokHnzzTcf8z9Oeg9OTXc/f8D8/e9/HzwmnN9BO3fuNK+44gozLi7OTE9PN++44w6zvb09yldzZjJM0zSj3asjIiIiEgnVsIiIiEifp8AiIiIifZ4Ci4iIiPR5CiwiIiLS5ymwiIiISJ+nwCIiIiJ9ngKLiIiI9HkKLCIiItLnKbCIiIhIn6fAIiIiIn2eAouIiIj0ef8/Tjeg+2P73cYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label=\"train_loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"val_loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "[[0.54538381 0.54779112 0.55333787 0.55894899 0.5640524  0.56823003\n",
      "  0.57136452 0.57333332 0.57567298 0.57856309]]\n"
     ]
    }
   ],
   "source": [
    "# Now\n",
    "# Reshape the last_sequence to match the input shape of the model\n",
    "last_sequence = X[-1].reshape((1, n_features, 1))\n",
    "\n",
    "# Predict the next 10 values\n",
    "predictions = []\n",
    "for _ in range(10):\n",
    "    next_value = model.predict(last_sequence)\n",
    "    predictions.append(next_value[0][0])\n",
    "    last_sequence = np.roll(last_sequence, -1, axis=1)\n",
    "    last_sequence[0][-1] = next_value\n",
    "\n",
    "# To convert this predictions to the actual glucose values, we need to inverse the scaling\n",
    "predictions = scaler.inverse_transform([predictions])\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 302ms/step - loss: 0.3604 - val_loss: 0.1731\n",
      "Epoch 2/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2852 - val_loss: 0.1263\n",
      "Epoch 3/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2233 - val_loss: 0.0738\n",
      "Epoch 4/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1321 - val_loss: 0.0249\n",
      "Epoch 5/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0534 - val_loss: 0.0070\n",
      "Epoch 6/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0165 - val_loss: 0.0287\n",
      "Epoch 7/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0246 - val_loss: 0.0108\n",
      "Epoch 8/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0141 - val_loss: 0.0062\n",
      "Epoch 9/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0156 - val_loss: 0.0072\n",
      "Epoch 10/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 11/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0126 - val_loss: 0.0081\n",
      "Epoch 12/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0112 - val_loss: 0.0065\n",
      "Epoch 13/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0107 - val_loss: 0.0073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "[[0.57756382 0.5784294  0.57088363 0.58107072 0.58085907 0.58074862\n",
      "  0.58418536 0.58454198 0.58540112 0.58679032]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 263ms/step - loss: 0.3920 - val_loss: 0.1992\n",
      "Epoch 2/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.3385 - val_loss: 0.1673\n",
      "Epoch 3/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2961 - val_loss: 0.1275\n",
      "Epoch 4/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2311 - val_loss: 0.0794\n",
      "Epoch 5/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1465 - val_loss: 0.0294\n",
      "Epoch 6/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0651 - val_loss: 0.0063\n",
      "Epoch 7/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0179 - val_loss: 0.0292\n",
      "Epoch 8/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0250 - val_loss: 0.0117\n",
      "Epoch 9/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0147 - val_loss: 0.0063\n",
      "Epoch 10/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0143 - val_loss: 0.0068\n",
      "Epoch 11/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 12/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0099 - val_loss: 0.0069\n",
      "Epoch 13/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 14/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0085 - val_loss: 0.0065\n",
      "Epoch 15/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 16/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 17/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0077 - val_loss: 0.0063\n",
      "Epoch 18/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 19/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0070 - val_loss: 0.0064\n",
      "Epoch 20/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 21/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 22/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 23/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 24/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0071 - val_loss: 0.0063\n",
      "Epoch 25/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "[[0.55442703 0.54942155 0.53280562 0.53196418 0.52405077 0.5154596\n",
      "  0.51097238 0.50407082 0.49786994 0.49270618]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 202ms/step - loss: 0.3704 - val_loss: 0.1827\n",
      "Epoch 2/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.3027 - val_loss: 0.1442\n",
      "Epoch 3/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.2340 - val_loss: 0.0986\n",
      "Epoch 4/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1778 - val_loss: 0.0483\n",
      "Epoch 5/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0965 - val_loss: 0.0095\n",
      "Epoch 6/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0268 - val_loss: 0.0171\n",
      "Epoch 7/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0202 - val_loss: 0.0217\n",
      "Epoch 8/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0187 - val_loss: 0.0083\n",
      "Epoch 9/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0141 - val_loss: 0.0064\n",
      "Epoch 10/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0128 - val_loss: 0.0076\n",
      "Epoch 11/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 12/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0094 - val_loss: 0.0066\n",
      "Epoch 13/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0091 - val_loss: 0.0062\n",
      "Epoch 14/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 15/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 16/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 17/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 18/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 19/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 20/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 21/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 22/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 23/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0084 - val_loss: 0.0061\n",
      "Epoch 24/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 25/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 26/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 27/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0075 - val_loss: 0.0061\n",
      "Epoch 28/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 29/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "[[0.57802469 0.57825935 0.57129359 0.58309251 0.58329397 0.58439708\n",
      "  0.5894891  0.59097892 0.59342575 0.59646004]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - loss: 0.3824 - val_loss: 0.1886\n",
      "Epoch 2/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3264 - val_loss: 0.1514\n",
      "Epoch 3/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2637 - val_loss: 0.1065\n",
      "Epoch 4/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2068 - val_loss: 0.0529\n",
      "Epoch 5/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1094 - val_loss: 0.0097\n",
      "Epoch 6/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0247 - val_loss: 0.0233\n",
      "Epoch 7/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0257 - val_loss: 0.0195\n",
      "Epoch 8/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0145 - val_loss: 0.0062\n",
      "Epoch 9/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0158 - val_loss: 0.0068\n",
      "Epoch 10/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 11/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0120 - val_loss: 0.0089\n",
      "Epoch 12/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0109 - val_loss: 0.0065\n",
      "Epoch 13/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 14/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 15/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0102 - val_loss: 0.0072\n",
      "Epoch 16/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0101 - val_loss: 0.0060\n",
      "Epoch 17/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0095 - val_loss: 0.0070\n",
      "Epoch 18/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 19/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0082 - val_loss: 0.0062\n",
      "Epoch 20/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 21/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0079 - val_loss: 0.0059\n",
      "Epoch 22/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 23/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 24/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0077 - val_loss: 0.0062\n",
      "Epoch 25/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 26/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 27/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 28/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 29/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 30/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 31/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0083 - val_loss: 0.0062\n",
      "Epoch 32/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 33/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0070 - val_loss: 0.0062\n",
      "Epoch 34/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 35/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0079 - val_loss: 0.0061\n",
      "Epoch 36/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 37/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 38/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 39/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 40/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0073 - val_loss: 0.0061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "[[0.5494507  0.546143   0.52735448 0.52520132 0.51786596 0.50816339\n",
      "  0.50359792 0.49698848 0.49061912 0.48586306]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 243ms/step - loss: 0.3650 - val_loss: 0.1521\n",
      "Epoch 2/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2373 - val_loss: 0.0859\n",
      "Epoch 3/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1376 - val_loss: 0.0217\n",
      "Epoch 4/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0374 - val_loss: 0.0176\n",
      "Epoch 5/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0213 - val_loss: 0.0138\n",
      "Epoch 6/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0137 - val_loss: 0.0076\n",
      "Epoch 7/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0127 - val_loss: 0.0107\n",
      "Epoch 8/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0126 - val_loss: 0.0091\n",
      "Epoch 9/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0124 - val_loss: 0.0079\n",
      "Epoch 10/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0120 - val_loss: 0.0088\n",
      "Epoch 11/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0124 - val_loss: 0.0100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "[[0.56118548 0.57575494 0.58571053 0.58625144 0.58403093 0.59266067\n",
      "  0.59866911 0.6023103  0.60475445 0.60814923]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 259ms/step - loss: 0.3643 - val_loss: 0.1827\n",
      "Epoch 2/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3322 - val_loss: 0.1410\n",
      "Epoch 3/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.2400 - val_loss: 0.0888\n",
      "Epoch 4/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1555 - val_loss: 0.0309\n",
      "Epoch 5/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0555 - val_loss: 0.0099\n",
      "Epoch 6/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 7/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0171 - val_loss: 0.0074\n",
      "Epoch 8/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0189 - val_loss: 0.0073\n",
      "Epoch 9/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 10/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0120 - val_loss: 0.0086\n",
      "Epoch 11/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0113 - val_loss: 0.0078\n",
      "Epoch 12/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 13/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0106 - val_loss: 0.0078\n",
      "Epoch 14/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 15/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0119 - val_loss: 0.0081\n",
      "Epoch 16/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 17/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 18/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0144 - val_loss: 0.0081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "[[0.50996351 0.51514262 0.51053661 0.49818873 0.48350078 0.4749921\n",
      "  0.46880898 0.46049657 0.45206109 0.44471681]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 248ms/step - loss: 0.3968 - val_loss: 0.1937\n",
      "Epoch 2/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.3281 - val_loss: 0.1568\n",
      "Epoch 3/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.2737 - val_loss: 0.1103\n",
      "Epoch 4/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1948 - val_loss: 0.0511\n",
      "Epoch 5/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0857 - val_loss: 0.0072\n",
      "Epoch 6/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0185 - val_loss: 0.0285\n",
      "Epoch 7/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0210 - val_loss: 0.0072\n",
      "Epoch 8/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0170 - val_loss: 0.0072\n",
      "Epoch 9/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0146 - val_loss: 0.0093\n",
      "Epoch 10/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0121 - val_loss: 0.0086\n",
      "Epoch 11/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0122 - val_loss: 0.0080\n",
      "Epoch 12/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 13/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0099 - val_loss: 0.0081\n",
      "Epoch 14/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0106 - val_loss: 0.0081\n",
      "Epoch 15/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 16/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0104 - val_loss: 0.0078\n",
      "Epoch 17/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0113 - val_loss: 0.0078\n",
      "Epoch 18/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0100 - val_loss: 0.0077\n",
      "Epoch 19/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 20/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0118 - val_loss: 0.0085\n",
      "Epoch 21/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0098 - val_loss: 0.0079\n",
      "Epoch 22/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0111 - val_loss: 0.0077\n",
      "Epoch 23/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0095 - val_loss: 0.0076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "[[0.53449947 0.53824317 0.53312862 0.52803463 0.51990008 0.51547742\n",
      "  0.51182663 0.50707459 0.50298995 0.49896386]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 130ms/step - loss: 0.3543 - val_loss: 0.1769\n",
      "Epoch 2/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.3070 - val_loss: 0.1306\n",
      "Epoch 3/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2244 - val_loss: 0.0740\n",
      "Epoch 4/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1365 - val_loss: 0.0180\n",
      "Epoch 5/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0375 - val_loss: 0.0239\n",
      "Epoch 6/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0332 - val_loss: 0.0214\n",
      "Epoch 7/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0152 - val_loss: 0.0072\n",
      "Epoch 8/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0234 - val_loss: 0.0072\n",
      "Epoch 9/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0152 - val_loss: 0.0120\n",
      "Epoch 10/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0135 - val_loss: 0.0086\n",
      "Epoch 11/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0127 - val_loss: 0.0077\n",
      "Epoch 12/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 13/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0127 - val_loss: 0.0080\n",
      "Epoch 14/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0136 - val_loss: 0.0083\n",
      "Epoch 15/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 16/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0105 - val_loss: 0.0084\n",
      "Epoch 17/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0089 - val_loss: 0.0081\n",
      "Epoch 18/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 19/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0101 - val_loss: 0.0083\n",
      "Epoch 20/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0101 - val_loss: 0.0080\n",
      "Epoch 21/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0088 - val_loss: 0.0079\n",
      "Epoch 22/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0107 - val_loss: 0.0077\n",
      "Epoch 23/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 24/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 25/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 26/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0106 - val_loss: 0.0077\n",
      "Epoch 27/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0086 - val_loss: 0.0072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[0.52908492 0.53185058 0.52486235 0.51608455 0.5073573  0.50161576\n",
      "  0.49599501 0.48982772 0.48419973 0.47901151]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 317ms/step - loss: 0.3797 - val_loss: 0.1733\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.2892 - val_loss: 0.1049\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.1671 - val_loss: 0.0245\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0456 - val_loss: 0.0445\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0466 - val_loss: 0.0102\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0247 - val_loss: 0.0099\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0252 - val_loss: 0.0124\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0238 - val_loss: 0.0143\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0215 - val_loss: 0.0092\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0191 - val_loss: 0.0112\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0198 - val_loss: 0.0116\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0189 - val_loss: 0.0093\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0167 - val_loss: 0.0109\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0185 - val_loss: 0.0096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "[[0.47385925 0.4878079  0.4989194  0.50714308 0.51263928 0.51034021\n",
      "  0.50663108 0.50460291 0.50281191 0.50122005]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 293ms/step - loss: 0.3709 - val_loss: 0.1730\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.3051 - val_loss: 0.1186\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.1918 - val_loss: 0.0499\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0773 - val_loss: 0.0167\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0367 - val_loss: 0.0133\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0214 - val_loss: 0.0110\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0249 - val_loss: 0.0110\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0203 - val_loss: 0.0114\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0204 - val_loss: 0.0098\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0213 - val_loss: 0.0104\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0185 - val_loss: 0.0099\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0190 - val_loss: 0.0095\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0166 - val_loss: 0.0097\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0172 - val_loss: 0.0093\n",
      "Epoch 15/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0162 - val_loss: 0.0090\n",
      "Epoch 16/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0146 - val_loss: 0.0092\n",
      "Epoch 17/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0124 - val_loss: 0.0086\n",
      "Epoch 18/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0141 - val_loss: 0.0082\n",
      "Epoch 19/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0119 - val_loss: 0.0089\n",
      "Epoch 20/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0124 - val_loss: 0.0084\n",
      "Epoch 21/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0108 - val_loss: 0.0078\n",
      "Epoch 22/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0093 - val_loss: 0.0102\n",
      "Epoch 23/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0108 - val_loss: 0.0088\n",
      "Epoch 24/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 25/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 26/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 27/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 28/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 29/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0064 - val_loss: 0.0080\n",
      "Epoch 30/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 31/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "[[0.59739339 0.61600357 0.62837809 0.63678575 0.6451056  0.65973622\n",
      "  0.67215693 0.68075216 0.69017649 0.70031947]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 275ms/step - loss: 0.3768 - val_loss: 0.1620\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.2833 - val_loss: 0.0997\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1636 - val_loss: 0.0269\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0460 - val_loss: 0.0363\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0418 - val_loss: 0.0110\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0219 - val_loss: 0.0099\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0245 - val_loss: 0.0101\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0219 - val_loss: 0.0140\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0192 - val_loss: 0.0099\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0170 - val_loss: 0.0098\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0195 - val_loss: 0.0105\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0158 - val_loss: 0.0101\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0182 - val_loss: 0.0093\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0181 - val_loss: 0.0103\n",
      "Epoch 15/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0160 - val_loss: 0.0089\n",
      "Epoch 16/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0155 - val_loss: 0.0094\n",
      "Epoch 17/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0156 - val_loss: 0.0086\n",
      "Epoch 18/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 19/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0114 - val_loss: 0.0084\n",
      "Epoch 20/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 21/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0124 - val_loss: 0.0080\n",
      "Epoch 22/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 23/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 24/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 25/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 26/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0085 - val_loss: 0.0093\n",
      "Epoch 27/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0080 - val_loss: 0.0120\n",
      "Epoch 28/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0117 - val_loss: 0.0078\n",
      "Epoch 29/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 30/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 31/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 32/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 33/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 34/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 35/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 36/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 37/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 38/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0073 - val_loss: 0.0085\n",
      "Epoch 39/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0079 - val_loss: 0.0088\n",
      "Epoch 40/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 41/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0075 - val_loss: 0.0083\n",
      "Epoch 42/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 43/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 44/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 45/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 46/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 47/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 48/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 49/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 50/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 51/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 52/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 53/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 54/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 55/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 56/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0067 - val_loss: 0.0073\n",
      "Epoch 57/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 58/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 59/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 60/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 61/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 62/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 63/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0053 - val_loss: 0.0072\n",
      "Epoch 64/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 65/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 66/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 67/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 68/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0045 - val_loss: 0.0072\n",
      "Epoch 69/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 70/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 71/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 72/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 73/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0044 - val_loss: 0.0066\n",
      "Epoch 74/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0048 - val_loss: 0.0068\n",
      "Epoch 75/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 76/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0048 - val_loss: 0.0066\n",
      "Epoch 77/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 78/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 79/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 80/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 81/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 82/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 83/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 84/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 85/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 86/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 87/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 88/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 89/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0044 - val_loss: 0.0065\n",
      "Epoch 90/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 91/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 92/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 93/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 94/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 95/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 96/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 97/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 98/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 99/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 100/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 101/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 102/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 103/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 104/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 105/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 106/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 107/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 108/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 109/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 110/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 111/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 112/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 113/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 114/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 115/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 116/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 117/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 118/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 119/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 120/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 121/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 122/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 123/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 124/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 125/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 126/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 127/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 128/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 129/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 130/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 131/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 132/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 133/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 134/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 135/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 136/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 137/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 138/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 139/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 140/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 141/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 142/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 143/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 144/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 145/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 146/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 147/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 148/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 149/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 150/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 151/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 152/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 153/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0020 - val_loss: 0.0049\n",
      "Epoch 154/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 155/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 156/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 157/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 158/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 159/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 160/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 161/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 162/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 163/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 164/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 165/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 166/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 167/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 168/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 169/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 170/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 171/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 172/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0022 - val_loss: 0.0041\n",
      "Epoch 173/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 174/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 175/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 176/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 177/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 178/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 179/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 180/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 181/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 182/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 183/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 184/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 185/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 186/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 187/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 188/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 189/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 190/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 191/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 192/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "[[0.56190968 0.5629763  0.57262135 0.58812469 0.60663497 0.62625802\n",
      "  0.64664018 0.6673153  0.68570387 0.7020933 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 274ms/step - loss: 0.3661 - val_loss: 0.1799\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.2867 - val_loss: 0.1371\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2207 - val_loss: 0.0793\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1302 - val_loss: 0.0134\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0299 - val_loss: 0.0303\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0329 - val_loss: 0.0109\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0275 - val_loss: 0.0103\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0212 - val_loss: 0.0123\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0196 - val_loss: 0.0094\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0187 - val_loss: 0.0099\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0151 - val_loss: 0.0100\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0212 - val_loss: 0.0095\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0186 - val_loss: 0.0099\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0158 - val_loss: 0.0091\n",
      "Epoch 15/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0165 - val_loss: 0.0088\n",
      "Epoch 16/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0138 - val_loss: 0.0088\n",
      "Epoch 17/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0138 - val_loss: 0.0083\n",
      "Epoch 18/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0111 - val_loss: 0.0081\n",
      "Epoch 19/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 20/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0116 - val_loss: 0.0076\n",
      "Epoch 21/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0108 - val_loss: 0.0076\n",
      "Epoch 22/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 23/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0091 - val_loss: 0.0085\n",
      "Epoch 24/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0082 - val_loss: 0.0084\n",
      "Epoch 25/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 26/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0078 - val_loss: 0.0080\n",
      "Epoch 27/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0073 - val_loss: 0.0083\n",
      "Epoch 28/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0073 - val_loss: 0.0083\n",
      "Epoch 29/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 30/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - val_loss: 0.0083\n",
      "Epoch 31/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 32/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 33/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 34/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 35/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 36/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0083 - val_loss: 0.0084\n",
      "Epoch 37/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 38/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0068 - val_loss: 0.0083\n",
      "Epoch 39/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 40/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "[[0.57512778 0.59186172 0.60010004 0.60043311 0.59543824 0.59833413\n",
      "  0.59820944 0.59486282 0.59230095 0.59065711]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 277ms/step - loss: 0.3395 - val_loss: 0.1416\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.2287 - val_loss: 0.0529\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0842 - val_loss: 0.0278\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0448 - val_loss: 0.0194\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0335 - val_loss: 0.0116\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0338 - val_loss: 0.0121\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0303 - val_loss: 0.0174\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0232 - val_loss: 0.0115\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0256 - val_loss: 0.0118\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0219 - val_loss: 0.0118\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0227 - val_loss: 0.0103\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0235 - val_loss: 0.0117\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0200 - val_loss: 0.0100\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0172 - val_loss: 0.0092\n",
      "Epoch 15/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0158 - val_loss: 0.0098\n",
      "Epoch 16/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0155 - val_loss: 0.0078\n",
      "Epoch 17/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 18/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0086 - val_loss: 0.0073\n",
      "Epoch 19/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 20/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0100 - val_loss: 0.0079\n",
      "Epoch 21/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0086 - val_loss: 0.0069\n",
      "Epoch 22/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 23/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 24/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 25/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 26/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0081 - val_loss: 0.0072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "[[0.4943358  0.52378488 0.55398792 0.57678711 0.59301925 0.60130656\n",
      "  0.60492289 0.61050612 0.61470729 0.61794412]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - loss: 0.2981 - val_loss: 0.1259\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1905 - val_loss: 0.0395\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0529 - val_loss: 0.0352\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0482 - val_loss: 0.0132\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0293 - val_loss: 0.0125\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0272 - val_loss: 0.0116\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0243 - val_loss: 0.0143\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0251 - val_loss: 0.0101\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0241 - val_loss: 0.0104\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0196 - val_loss: 0.0095\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0190 - val_loss: 0.0096\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0176 - val_loss: 0.0089\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0164 - val_loss: 0.0086\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0138 - val_loss: 0.0067\n",
      "Epoch 15/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0119 - val_loss: 0.0067\n",
      "Epoch 16/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0131 - val_loss: 0.0066\n",
      "Epoch 17/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0103 - val_loss: 0.0065\n",
      "Epoch 18/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0104 - val_loss: 0.0065\n",
      "Epoch 19/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 20/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 21/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0107 - val_loss: 0.0065\n",
      "Epoch 22/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 23/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 24/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0094 - val_loss: 0.0071\n",
      "Epoch 25/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 26/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 27/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0076 - val_loss: 0.0071\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "[[0.47391078 0.49887228 0.52109498 0.5385071  0.54797077 0.55161661\n",
      "  0.54950851 0.54563493 0.53817654 0.53238106]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - loss: 0.3454 - val_loss: 0.1651\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2433 - val_loss: 0.0986\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1512 - val_loss: 0.0158\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0468 - val_loss: 0.0274\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0342 - val_loss: 0.0129\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0374 - val_loss: 0.0110\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0268 - val_loss: 0.0157\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0306 - val_loss: 0.0119\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0251 - val_loss: 0.0111\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0208 - val_loss: 0.0106\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0217 - val_loss: 0.0097\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0183 - val_loss: 0.0109\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0180 - val_loss: 0.0094\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0150 - val_loss: 0.0075\n",
      "Epoch 15/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0161 - val_loss: 0.0095\n",
      "Epoch 16/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0150 - val_loss: 0.0108\n",
      "Epoch 17/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0145 - val_loss: 0.0066\n",
      "Epoch 18/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0125 - val_loss: 0.0064\n",
      "Epoch 19/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0102 - val_loss: 0.0067\n",
      "Epoch 20/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0099 - val_loss: 0.0079\n",
      "Epoch 21/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0113 - val_loss: 0.0088\n",
      "Epoch 22/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0099 - val_loss: 0.0079\n",
      "Epoch 23/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0111 - val_loss: 0.0067\n",
      "Epoch 24/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0086 - val_loss: 0.0067\n",
      "Epoch 25/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0094 - val_loss: 0.0075\n",
      "Epoch 26/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0097 - val_loss: 0.0071\n",
      "Epoch 27/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 28/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 29/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0099 - val_loss: 0.0076\n",
      "Epoch 30/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 31/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0083 - val_loss: 0.0073\n",
      "Epoch 32/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 33/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0090 - val_loss: 0.0073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "[[0.49391282 0.52885014 0.55292523 0.5703389  0.58034432 0.59236932\n",
      "  0.60428566 0.61022651 0.61082208 0.61038929]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 187ms/step - loss: 0.3601 - val_loss: 0.1418\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.2048 - val_loss: 0.0410\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0594 - val_loss: 0.0440\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0496 - val_loss: 0.0130\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0342 - val_loss: 0.0127\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0328 - val_loss: 0.0149\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0238 - val_loss: 0.0138\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0252 - val_loss: 0.0110\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0247 - val_loss: 0.0115\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0200 - val_loss: 0.0103\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0202 - val_loss: 0.0098\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0197 - val_loss: 0.0101\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0159 - val_loss: 0.0077\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0156 - val_loss: 0.0076\n",
      "Epoch 15/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0154 - val_loss: 0.0072\n",
      "Epoch 16/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0119 - val_loss: 0.0067\n",
      "Epoch 17/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 18/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 19/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0108 - val_loss: 0.0066\n",
      "Epoch 20/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 21/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0084 - val_loss: 0.0073\n",
      "Epoch 22/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 23/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 24/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0083 - val_loss: 0.0070\n",
      "Epoch 25/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 26/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 27/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 28/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 29/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 30/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 31/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 32/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 33/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0069 - val_loss: 0.0067\n",
      "Epoch 34/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 35/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0085 - val_loss: 0.0076\n",
      "Epoch 36/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 37/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 38/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 39/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 40/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 41/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 42/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 43/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 44/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 45/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 46/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0063 - val_loss: 0.0082\n",
      "Epoch 47/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 48/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 49/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 50/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 51/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0060 - val_loss: 0.0066\n",
      "Epoch 52/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0048 - val_loss: 0.0073\n",
      "Epoch 53/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0056 - val_loss: 0.0077\n",
      "Epoch 54/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 55/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 56/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0057 - val_loss: 0.0081\n",
      "Epoch 57/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 58/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 59/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 60/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0049 - val_loss: 0.0079\n",
      "Epoch 61/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 62/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 63/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 64/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 65/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 66/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 67/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 68/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 69/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 70/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 71/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 72/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 73/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 74/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 75/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 0.0046\n",
      "Epoch 76/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0027 - val_loss: 0.0070\n",
      "Epoch 77/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 78/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - val_loss: 0.0049\n",
      "Epoch 79/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 80/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 81/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 82/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 83/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 84/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0025 - val_loss: 0.0052\n",
      "Epoch 85/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 86/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 87/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 88/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 89/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 90/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 91/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 92/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 93/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 94/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 95/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 96/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 97/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 98/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 99/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 100/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 101/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 102/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 103/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 104/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 105/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 106/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 107/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 108/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 109/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 110/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 111/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 112/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 113/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 114/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 115/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 116/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 117/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 118/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 119/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 120/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 121/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 122/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 123/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 124/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 125/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 126/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 127/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 128/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 129/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 130/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 131/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 132/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 133/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 134/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 135/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0018 - val_loss: 0.0036\n",
      "Epoch 136/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 137/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 138/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 139/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 140/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 141/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 142/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 143/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 144/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 145/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 146/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 147/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 148/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 149/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 150/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 151/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 152/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 153/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 154/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 155/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 156/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 157/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 158/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 159/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 160/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 161/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 162/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 163/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 164/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 165/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 166/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 167/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 168/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 169/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 170/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 171/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 172/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 173/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 174/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 175/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 176/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 177/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 178/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 179/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 180/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 181/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 182/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 183/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 184/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 185/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 186/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0018 - val_loss: 0.0028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "[[0.55193448 0.55147594 0.55565286 0.56810313 0.58305442 0.59919441\n",
      "  0.61412543 0.62974864 0.64531857 0.65937555]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 284ms/step - loss: 0.3317 - val_loss: 0.1122\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.1491 - val_loss: 0.0147\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0445 - val_loss: 0.0316\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0312 - val_loss: 0.0128\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0392 - val_loss: 0.0114\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0296 - val_loss: 0.0160\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0290 - val_loss: 0.0121\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0251 - val_loss: 0.0110\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0263 - val_loss: 0.0116\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0227 - val_loss: 0.0097\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0224 - val_loss: 0.0097\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0203 - val_loss: 0.0095\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0195 - val_loss: 0.0079\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0145 - val_loss: 0.0082\n",
      "Epoch 15/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0123 - val_loss: 0.0075\n",
      "Epoch 16/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 17/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 18/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0120 - val_loss: 0.0070\n",
      "Epoch 19/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0097 - val_loss: 0.0069\n",
      "Epoch 20/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0113 - val_loss: 0.0070\n",
      "Epoch 21/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0112 - val_loss: 0.0089\n",
      "Epoch 22/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 23/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 24/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0093 - val_loss: 0.0072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "[[0.5141142  0.53466523 0.55065113 0.56332833 0.57310444 0.58262163\n",
      "  0.59156328 0.60034513 0.60805821 0.6147123 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 313ms/step - loss: 0.3561 - val_loss: 0.1930\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.3117 - val_loss: 0.1316\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2018 - val_loss: 0.0392\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0671 - val_loss: 0.0521\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0568 - val_loss: 0.0122\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0357 - val_loss: 0.0115\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0315 - val_loss: 0.0157\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0303 - val_loss: 0.0140\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0257 - val_loss: 0.0114\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0252 - val_loss: 0.0128\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0244 - val_loss: 0.0108\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0212 - val_loss: 0.0107\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0214 - val_loss: 0.0095\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0190 - val_loss: 0.0084\n",
      "Epoch 15/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0174 - val_loss: 0.0107\n",
      "Epoch 16/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0143 - val_loss: 0.0070\n",
      "Epoch 17/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 18/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0104 - val_loss: 0.0076\n",
      "Epoch 19/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 20/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0107 - val_loss: 0.0068\n",
      "Epoch 21/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0107 - val_loss: 0.0072\n",
      "Epoch 22/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0110 - val_loss: 0.0071\n",
      "Epoch 23/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 24/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0089 - val_loss: 0.0069\n",
      "Epoch 25/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0096 - val_loss: 0.0073\n",
      "Epoch 26/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 27/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0080 - val_loss: 0.0073\n",
      "Epoch 28/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0092 - val_loss: 0.0070\n",
      "Epoch 29/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 30/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0069 - val_loss: 0.0072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "[[0.53096032 0.55337197 0.57280678 0.58904123 0.60229623 0.6143887\n",
      "  0.62553239 0.63656104 0.6468578  0.65650356]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 298ms/step - loss: 0.3057 - val_loss: 0.1324\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1845 - val_loss: 0.0416\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0611 - val_loss: 0.0400\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0570 - val_loss: 0.0158\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0390 - val_loss: 0.0140\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0308 - val_loss: 0.0154\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0299 - val_loss: 0.0131\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0296 - val_loss: 0.0112\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0248 - val_loss: 0.0128\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0220 - val_loss: 0.0103\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0225 - val_loss: 0.0104\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0203 - val_loss: 0.0089\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0175 - val_loss: 0.0079\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0147 - val_loss: 0.0093\n",
      "Epoch 15/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 16/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0116 - val_loss: 0.0067\n",
      "Epoch 17/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0109 - val_loss: 0.0076\n",
      "Epoch 18/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0108 - val_loss: 0.0067\n",
      "Epoch 19/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 20/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0108 - val_loss: 0.0087\n",
      "Epoch 21/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0099 - val_loss: 0.0068\n",
      "Epoch 22/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0102 - val_loss: 0.0068\n",
      "Epoch 23/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 24/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0103 - val_loss: 0.0071\n",
      "Epoch 25/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 26/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0101 - val_loss: 0.0069\n",
      "Epoch 27/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0087 - val_loss: 0.0077\n",
      "Epoch 28/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0101 - val_loss: 0.0073\n",
      "Epoch 29/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0092 - val_loss: 0.0068\n",
      "Epoch 30/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0091 - val_loss: 0.0069\n",
      "Epoch 31/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0089 - val_loss: 0.0065\n",
      "Epoch 32/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 33/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 34/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0076 - val_loss: 0.0063\n",
      "Epoch 35/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 36/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 37/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 38/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 39/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 40/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 41/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 42/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0076 - val_loss: 0.0063\n",
      "Epoch 43/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 44/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 45/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0059 - val_loss: 0.0091\n",
      "Epoch 46/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 47/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 48/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 49/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 50/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 51/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 52/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0055 - val_loss: 0.0094\n",
      "Epoch 53/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 54/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 55/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 56/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 57/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 58/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0046 - val_loss: 0.0063\n",
      "Epoch 59/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 60/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 61/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 62/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 63/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 64/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 65/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 66/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 67/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 68/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 69/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 70/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 71/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 72/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 73/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 74/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0039 - val_loss: 0.0073\n",
      "Epoch 75/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 76/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 77/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 78/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 79/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 80/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 81/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 82/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 83/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0027 - val_loss: 0.0063\n",
      "Epoch 84/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 85/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 86/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0030 - val_loss: 0.0105\n",
      "Epoch 87/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 88/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 89/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 90/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 91/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 92/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0047 - val_loss: 0.0066\n",
      "Epoch 93/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 94/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 95/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 96/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 97/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 98/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 99/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 100/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 101/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 102/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 103/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 104/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 105/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 106/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0029 - val_loss: 0.0060\n",
      "Epoch 107/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 108/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 109/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 110/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 111/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 112/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 113/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 114/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 115/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 116/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 117/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 118/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 119/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 120/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 121/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 122/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 123/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 124/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 125/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 126/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 127/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 128/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 129/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 130/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 131/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 132/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 133/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 134/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 135/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 136/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 137/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 138/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 139/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 140/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 141/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 142/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 143/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 144/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 145/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 146/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 147/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 148/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 149/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 150/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 151/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 152/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 153/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 154/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 155/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 156/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 157/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 158/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 159/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 160/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "[[0.55338579 0.56152332 0.57165056 0.58316028 0.59527022 0.60699898\n",
      "  0.61819714 0.628667   0.63775378 0.64546919]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 311ms/step - loss: 0.3403 - val_loss: 0.1646\n",
      "Epoch 2/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2504 - val_loss: 0.1000\n",
      "Epoch 3/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1596 - val_loss: 0.0234\n",
      "Epoch 4/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0475 - val_loss: 0.0384\n",
      "Epoch 5/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0368 - val_loss: 0.0125\n",
      "Epoch 6/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0380 - val_loss: 0.0121\n",
      "Epoch 7/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0361 - val_loss: 0.0140\n",
      "Epoch 8/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0299 - val_loss: 0.0131\n",
      "Epoch 9/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0275 - val_loss: 0.0110\n",
      "Epoch 10/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0268 - val_loss: 0.0115\n",
      "Epoch 11/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0238 - val_loss: 0.0104\n",
      "Epoch 12/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0221 - val_loss: 0.0096\n",
      "Epoch 13/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0176 - val_loss: 0.0085\n",
      "Epoch 14/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0154 - val_loss: 0.0078\n",
      "Epoch 15/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0157 - val_loss: 0.0089\n",
      "Epoch 16/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0149 - val_loss: 0.0079\n",
      "Epoch 17/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0129 - val_loss: 0.0117\n",
      "Epoch 18/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0133 - val_loss: 0.0071\n",
      "Epoch 19/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0103 - val_loss: 0.0090\n",
      "Epoch 20/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0115 - val_loss: 0.0071\n",
      "Epoch 21/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0101 - val_loss: 0.0072\n",
      "Epoch 22/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0106 - val_loss: 0.0070\n",
      "Epoch 23/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0108 - val_loss: 0.0072\n",
      "Epoch 24/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 25/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 26/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0119 - val_loss: 0.0071\n",
      "Epoch 27/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0104 - val_loss: 0.0075\n",
      "Epoch 28/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0090 - val_loss: 0.0071\n",
      "Epoch 29/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 30/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0099 - val_loss: 0.0073\n",
      "Epoch 31/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0088 - val_loss: 0.0074\n",
      "Epoch 32/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 33/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 34/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0089 - val_loss: 0.0072\n",
      "Epoch 35/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 36/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 37/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 38/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 39/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 40/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 41/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 42/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 43/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 44/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 45/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 46/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 47/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 48/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 49/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0065 - val_loss: 0.0087\n",
      "Epoch 50/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 51/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 52/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 53/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0075 - val_loss: 0.0070\n",
      "Epoch 54/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 55/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 56/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 57/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 58/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 59/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0083 - val_loss: 0.0069\n",
      "Epoch 60/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 61/500\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "[[0.50667417 0.5223617  0.53311813 0.54077059 0.5458439  0.54977584\n",
      "  0.5522154  0.55437291 0.55612975 0.55742735]]\n"
     ]
    }
   ],
   "source": [
    "# I want to implement an LSTM model by taking values of n_features from [3, 5, 10, 15, 20] and then compare the results and also want to choose patience values from [5, 10, 15, 20] and compare the results.\n",
    "\n",
    "# I will use the above code and modify it to take the values of n_features and patience as input and then return the predictions and the model.\n",
    "\n",
    "# To do this I will apply a loop on the values of n_features and patience and then store the results in a dictionary\n",
    "\n",
    "# I will then convert the dictionary to a pandas dataframe and then save it as a csv file\n",
    "\n",
    "for n_features in [3, 5, 10, 15, 20]:\n",
    "    for patience in [5, 10, 15, 20]:\n",
    "        X, y = prepare_data(time_series_data, n_features)\n",
    "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        split = int(0.8 * len(X))\n",
    "        X_train, X_val = X[:split], X[split:]\n",
    "        y_train, y_val = y[:split], y[split:]\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_features, 1)))\n",
    "        model.add(LSTM(50, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "\n",
    "        history = model.fit(X_train, y_train, epochs=500, verbose=1, validation_data = (X_val, y_val) ,callbacks=[early_stop])\n",
    "\n",
    "        last_sequence = X[-1].reshape((1, n_features, 1))\n",
    "\n",
    "        predictions = []\n",
    "        for _ in range(10):\n",
    "            next_value = model.predict(last_sequence)\n",
    "            predictions.append(next_value[0][0])\n",
    "            last_sequence = np.roll(last_sequence, -1, axis=1)\n",
    "            last_sequence[0][-1] = next_value\n",
    "\n",
    "        predictions = scaler.inverse_transform([predictions])\n",
    "        print(predictions)\n",
    "\n",
    "        # Save the results in a dictionary\n",
    "        results = {\n",
    "            'n_features': n_features,\n",
    "            'patience': patience,\n",
    "            'predictions': predictions.flatten()\n",
    "        }\n",
    "\n",
    "        # Convert the dictionary to a pandas dataframe\n",
    "        results_df = pd.DataFrame([results])\n",
    "\n",
    "        # Save the dataframe as a csv file\n",
    "        results_df.to_csv(f\"results_n_features_{n_features}_patience_{patience}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50667417, 0.5223617 , 0.53311813, 0.54077059, 0.5458439 ,\n",
       "        0.54977584, 0.5522154 , 0.55437291, 0.55612975, 0.55742735]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.flatten()\n",
    "scaler.inverse_transform([predictions.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.99999999999999\n"
     ]
    }
   ],
   "source": [
    "mean_240 = get_previous_3_values_mean(actual_values, 0)\n",
    "print(mean_240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CGPT Generated Code\n",
    "def prepare_data(time_series_data, n_features):\n",
    "    X, y = [], []\n",
    "    for i in range(len(time_series_data) - n_features):\n",
    "        seq_x = time_series_data[i:i + n_features]\n",
    "        seq_y = time_series_data[i + n_features]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CGPT Generated Code\n",
    "def train_and_evaluate(n_features, patience):\n",
    "    # Preparing the dataset\n",
    "    X, y = prepare_data(df['reading'].values, n_features)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "    X_train, X_val = X[:-17], X[-17:-9]\n",
    "    y_train, y_val = y[:-17], y[-17:-9]\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_features, 1)))\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Define early stopping\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=500, verbose=1, validation_data=(X_val, y_val), callbacks=[early_stop])\n",
    "\n",
    "    # Plot training history\n",
    "    plt.plot(history.history['loss'], label=\"train_loss\")\n",
    "    plt.plot(history.history['val_loss'], label=\"val_loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluate the model on the last 9 values\n",
    "    X_test, y_test = X[-9:], y[-9:]\n",
    "    last_sequence = X_test[-1].reshape((1, n_features, 1))\n",
    "    predictions = []\n",
    "    for _ in range(9):\n",
    "        next_value = model.predict(last_sequence)\n",
    "        predictions.append(next_value[0][0])\n",
    "        last_sequence = np.roll(last_sequence, -1, axis=1)\n",
    "        last_sequence[0][-1] = next_value\n",
    "\n",
    "    # Inverse transform the predictions\n",
    "    predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "    actuals = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    print('Predictions:', predictions)\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "\n",
    "    print(f'n_features: {n_features}, patience: {patience}, RMSE: {rmse}')\n",
    "    return model, rmse, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_list = [3, 5, 10, 15, 20]\n",
    "patience_list = [5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_rmse = float('inf')\n",
    "best_params = {}\n",
    "best_predictions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_features in n_features_list:\n",
    "    for patience in patience_list:\n",
    "        model, rmse, predictions = train_and_evaluate(n_features, patience)\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_model = model\n",
    "            best_predictions = predictions\n",
    "            best_params = {'n_features': n_features, 'patience': patience}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best RMSE: {best_rmse}, Best Params: {best_params}')\n",
    "print('Best Predictions:', best_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'e', 'b', 'a', 'c']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diction = {'a': 2, 'b': 4, 'e': 8, 'c': 1, 'd': 8}\n",
    "# I want to sort the dictionary based on the values of the dictionary and on the basis of lexographical order of the keys in such a way that the result is {'d': 8, 'e': 8, 'b': 4, 'a': 2, 'c': 1}\n",
    "\n",
    "sorted_diction = {k: v for k, v in sorted(diction.items(), key=lambda item: (-item[1], item[0]))}\n",
    "\n",
    "# Simplified version of the above code is\n",
    "\n",
    "# The key = lambda item: (-item[1], item[0]) is used to sort the dictionary based on the values in descending order and then on the basis of keys in ascending order\n",
    "# -Item[1] will sort the dictionary based on the values in descending order\n",
    "# item[0] will sort the dictionary based on the keys in ascending order\n",
    "\n",
    "# Preference is given to the values in the dictionary and then to the keys in the dictionary\n",
    "\n",
    "keys = []\n",
    "for key, value in sorted(diction.items(), key=lambda item: (-item[1], item[0])):\n",
    "    # Store the keys in an array\n",
    "    keys.append(key)\n",
    "\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'cattle', 'was', 'rattled', 'by', 'the', 'battery']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
