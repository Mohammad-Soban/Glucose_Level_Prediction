{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose_time</th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-05 00:05:00</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-05 00:10:00</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-05 00:15:00</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-05 00:20:00</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-05 00:25:00</td>\n",
       "      <td>116.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Glucose_time  reading\n",
       "0  2023-03-05 00:05:00    115.0\n",
       "1  2023-03-05 00:10:00    115.0\n",
       "2  2023-03-05 00:15:00    114.0\n",
       "3  2023-03-05 00:20:00    116.0\n",
       "4  2023-03-05 00:25:00    116.5"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./CSV_Files/glucose_data_resampled.csv\")\n",
    "# Drop all the columns which have unnamed in them\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:05:00</th>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:10:00</th>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:15:00</th>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:20:00</th>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:25:00</th>\n",
       "      <td>116.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     reading\n",
       "Glucose_time                \n",
       "2023-03-05 00:05:00    115.0\n",
       "2023-03-05 00:10:00    115.0\n",
       "2023-03-05 00:15:00    114.0\n",
       "2023-03-05 00:20:00    116.0\n",
       "2023-03-05 00:25:00    116.5"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the Glucose_time to datetime format and set it as the index\n",
    "df['Glucose_time'] = pd.to_datetime(df['Glucose_time'])\n",
    "df.set_index('Glucose_time', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:05:00</th>\n",
       "      <td>0.840909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:10:00</th>\n",
       "      <td>0.840909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:15:00</th>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:20:00</th>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-05 00:25:00</th>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      reading\n",
       "Glucose_time                 \n",
       "2023-03-05 00:05:00  0.840909\n",
       "2023-03-05 00:10:00  0.840909\n",
       "2023-03-05 00:15:00  0.818182\n",
       "2023-03-05 00:20:00  0.863636\n",
       "2023-03-05 00:25:00  0.875000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_df = df.copy()\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['reading'] = scaler.fit_transform(df[['reading']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(time_series_data, n_features):\n",
    "    X, y = [], []\n",
    "    for i in range(len(time_series_data)):\n",
    "        end_ix = i + n_features\n",
    "        if end_ix > len(time_series_data)-1:\n",
    "            break\n",
    "        seq_x, seq_y = time_series_data[i:end_ix], time_series_data[end_ix]\n",
    "\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 6, 8, 10]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfs = int(input(\"Enter the continuous inputs you want to give: \"))\n",
    "\n",
    "n_feat_list = []\n",
    "\n",
    "for i in range(4, nfs+1):\n",
    "    if i % 2 == 0:\n",
    "        n_feat_list.append(i)\n",
    "\n",
    "if nfs not in n_feat_list:\n",
    "    n_feat_list.append(nfs)\n",
    "\n",
    "n_feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience_lst = [10, 15, 20, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_data = df['reading'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameter = {}\n",
    "best_rmse = float('inf')\n",
    "best_predictions = None\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape:  (240, 4, 1) (240,)\n",
      "Validation Shape:  (24, 4, 1) (24,)\n",
      "Test Shape:  (19, 4, 1) (19,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835ms/step\n",
      "Train Shape:  (240, 4, 1) (240,)\n",
      "Validation Shape:  (24, 4, 1) (24,)\n",
      "Test Shape:  (19, 4, 1) (19,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Train Shape:  (240, 4, 1) (240,)\n",
      "Validation Shape:  (24, 4, 1) (24,)\n",
      "Test Shape:  (19, 4, 1) (19,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Train Shape:  (240, 4, 1) (240,)\n",
      "Validation Shape:  (24, 4, 1) (24,)\n",
      "Test Shape:  (19, 4, 1) (19,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Train Shape:  (240, 6, 1) (240,)\n",
      "Validation Shape:  (24, 6, 1) (24,)\n",
      "Test Shape:  (17, 6, 1) (17,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Train Shape:  (240, 6, 1) (240,)\n",
      "Validation Shape:  (24, 6, 1) (24,)\n",
      "Test Shape:  (17, 6, 1) (17,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Train Shape:  (240, 6, 1) (240,)\n",
      "Validation Shape:  (24, 6, 1) (24,)\n",
      "Test Shape:  (17, 6, 1) (17,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Train Shape:  (240, 6, 1) (240,)\n",
      "Validation Shape:  (24, 6, 1) (24,)\n",
      "Test Shape:  (17, 6, 1) (17,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955ms/step\n",
      "Train Shape:  (240, 8, 1) (240,)\n",
      "Validation Shape:  (24, 8, 1) (24,)\n",
      "Test Shape:  (15, 8, 1) (15,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Train Shape:  (240, 8, 1) (240,)\n",
      "Validation Shape:  (24, 8, 1) (24,)\n",
      "Test Shape:  (15, 8, 1) (15,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614ms/step\n",
      "Train Shape:  (240, 8, 1) (240,)\n",
      "Validation Shape:  (24, 8, 1) (24,)\n",
      "Test Shape:  (15, 8, 1) (15,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n",
      "Train Shape:  (240, 8, 1) (240,)\n",
      "Validation Shape:  (24, 8, 1) (24,)\n",
      "Test Shape:  (15, 8, 1) (15,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682ms/step\n",
      "Train Shape:  (240, 10, 1) (240,)\n",
      "Validation Shape:  (24, 10, 1) (24,)\n",
      "Test Shape:  (13, 10, 1) (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Train Shape:  (240, 10, 1) (240,)\n",
      "Validation Shape:  (24, 10, 1) (24,)\n",
      "Test Shape:  (13, 10, 1) (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Train Shape:  (240, 10, 1) (240,)\n",
      "Validation Shape:  (24, 10, 1) (24,)\n",
      "Test Shape:  (13, 10, 1) (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989ms/step\n",
      "Train Shape:  (240, 10, 1) (240,)\n",
      "Validation Shape:  (24, 10, 1) (24,)\n",
      "Test Shape:  (13, 10, 1) (13,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: early stopping\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853ms/step\n",
      "**************************************************\n",
      "Best Parameters:  {'n_features': 4, 'patience': 20}\n",
      "Best RMSE:  0.04761749836465496\n",
      "Prediction :-  [[0.337689  ]\n",
      " [0.34482515]\n",
      " [0.37528187]\n",
      " [0.39724836]\n",
      " [0.3871983 ]\n",
      " [0.4139311 ]\n",
      " [0.4344053 ]\n",
      " [0.3970126 ]\n",
      " [0.38764927]\n",
      " [0.37651494]\n",
      " [0.46868095]\n",
      " [0.46416026]\n",
      " [0.4745898 ]\n",
      " [0.52696174]\n",
      " [0.48586258]\n",
      " [0.44578168]\n",
      " [0.40453264]\n",
      " [0.35744718]\n",
      " [0.5219861 ]\n",
      " [0.6287734 ]\n",
      " [0.6472267 ]\n",
      " [0.6504896 ]\n",
      " [0.6572327 ]\n",
      " [0.51023555]]\n"
     ]
    }
   ],
   "source": [
    "for n_features in n_feat_list:\n",
    "    for pat in patience_lst:\n",
    "        X, y = prepare_data(time_series_data, n_features)\n",
    "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        test_size = 18\n",
    "        val_size = 24\n",
    "        train_size = X.shape[0] + (n_features - 5) - test_size - val_size\n",
    "\n",
    "        X_train, y_train = X[:train_size], y[:train_size]\n",
    "        X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\n",
    "        X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]\n",
    "\n",
    "            # Print the shapes of the train, validation and test sets\n",
    "        print(\"Train Shape: \", X_train.shape, y_train.shape)\n",
    "        print(\"Validation Shape: \", X_val.shape, y_val.shape)\n",
    "        print(\"Test Shape: \", X_test.shape, y_test.shape)\n",
    "\n",
    "            \n",
    "            # Building the LSTM Model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_features, 1)))\n",
    "        model.add(LSTM(50, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "            # Early stopping\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "\n",
    "            # Fitting the model\n",
    "        model.fit(X_train, y_train, epochs = 300, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "            # Choosing the best model based on the validation loss\n",
    "        predictions = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "        \n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_parameter['n_features'] = n_features\n",
    "            best_parameter['patience'] = pat\n",
    "            best_predictions = predictions\n",
    "            best_model = model\n",
    "\n",
    "print(\"*\" * 50)\n",
    "print(\"Best Parameters: \", best_parameter)\n",
    "print(\"Best RMSE: \", best_rmse)\n",
    "print(\"Prediction :- \", best_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92.858315,  93.17231 ,  94.5124  ,  95.47892 ,  95.03672 ,\n",
       "        96.21297 ,  97.11383 ,  95.46856 ,  95.056564,  94.56666 ,\n",
       "        98.621956,  98.42305 ,  98.88195 , 101.18632 ,  99.377945,\n",
       "        97.614395,  95.79944 ,  93.72768 , 100.96739 , 105.66603 ,\n",
       "       106.47798 , 106.62154 , 106.91824 , 100.45036 ], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_predictions_in_original_scale = scaler.inverse_transform(best_predictions)\n",
    "xlst = validation_predictions_in_original_scale.flatten()\n",
    "xlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 96.        ,  94.        ,  93.5       ,  93.        ,\n",
       "        93.        ,  94.        ,  95.        ,  95.        ,\n",
       "        96.        ,  97.        ,  96.        ,  95.5       ,\n",
       "        95.        ,  98.        ,  98.5       ,  99.        ,\n",
       "       101.        ,  99.66666667,  98.33333333,  97.        ,\n",
       "        95.        , 100.        , 105.        , 106.        ])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_values = df['reading'].values[train_size:train_size+val_size]\n",
    "actual_values = actual_values.reshape(-1, 1)\n",
    "actual_values_in_original_scale = scaler.inverse_transform(actual_values)\n",
    "actual_values_in_original_scale.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# Now I want it to be printed in the form of a dataframe with the predicted values with a shift of 1 and the actual values\n",
    "\n",
    "final = pd.DataFrame()\n",
    "# Append the time of time series from values 240 to 264\n",
    "final['time'] = df.index[train_size:train_size+val_size]\n",
    "\n",
    "\n",
    "# Append the precited values with a shift of 1 and the predicted value at 240 being the mean of actual values at 237, 238 and 239. Append the mean first and then the predicted values\n",
    "final['Shifted_prediction'] = [np.mean(actual_values_in_original_scale[237:240])] + validation_predictions_in_original_scale.flatten().tolist()[:-1]\n",
    "final['unshifted_prediction'] = xlst.flatten().tolist()\n",
    "\n",
    "# Append the actual values\n",
    "final['actual'] = actual_values_in_original_scale.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Shifted_prediction</th>\n",
       "      <th>unshifted_prediction</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-05 20:05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.858315</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-05 20:10:00</td>\n",
       "      <td>92.858315</td>\n",
       "      <td>93.172310</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-05 20:15:00</td>\n",
       "      <td>93.172310</td>\n",
       "      <td>94.512398</td>\n",
       "      <td>93.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-05 20:20:00</td>\n",
       "      <td>94.512398</td>\n",
       "      <td>95.478920</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-05 20:25:00</td>\n",
       "      <td>95.478920</td>\n",
       "      <td>95.036720</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-03-05 20:30:00</td>\n",
       "      <td>95.036720</td>\n",
       "      <td>96.212967</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-03-05 20:35:00</td>\n",
       "      <td>96.212967</td>\n",
       "      <td>97.113831</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-03-05 20:40:00</td>\n",
       "      <td>97.113831</td>\n",
       "      <td>95.468559</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-03-05 20:45:00</td>\n",
       "      <td>95.468559</td>\n",
       "      <td>95.056564</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-03-05 20:50:00</td>\n",
       "      <td>95.056564</td>\n",
       "      <td>94.566658</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-03-05 20:55:00</td>\n",
       "      <td>94.566658</td>\n",
       "      <td>98.621956</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-03-05 21:00:00</td>\n",
       "      <td>98.621956</td>\n",
       "      <td>98.423050</td>\n",
       "      <td>95.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-03-05 21:05:00</td>\n",
       "      <td>98.423050</td>\n",
       "      <td>98.881950</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-03-05 21:10:00</td>\n",
       "      <td>98.881950</td>\n",
       "      <td>101.186317</td>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-03-05 21:15:00</td>\n",
       "      <td>101.186317</td>\n",
       "      <td>99.377945</td>\n",
       "      <td>98.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-03-05 21:20:00</td>\n",
       "      <td>99.377945</td>\n",
       "      <td>97.614395</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-03-05 21:25:00</td>\n",
       "      <td>97.614395</td>\n",
       "      <td>95.799438</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-03-05 21:30:00</td>\n",
       "      <td>95.799438</td>\n",
       "      <td>93.727676</td>\n",
       "      <td>99.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-03-05 21:35:00</td>\n",
       "      <td>93.727676</td>\n",
       "      <td>100.967392</td>\n",
       "      <td>98.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-03-05 21:40:00</td>\n",
       "      <td>100.967392</td>\n",
       "      <td>105.666031</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-03-05 21:45:00</td>\n",
       "      <td>105.666031</td>\n",
       "      <td>106.477982</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-03-05 21:50:00</td>\n",
       "      <td>106.477982</td>\n",
       "      <td>106.621536</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-03-05 21:55:00</td>\n",
       "      <td>106.621536</td>\n",
       "      <td>106.918243</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-03-05 22:00:00</td>\n",
       "      <td>106.918243</td>\n",
       "      <td>100.450363</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  Shifted_prediction  unshifted_prediction      actual\n",
       "0  2023-03-05 20:05:00                 NaN             92.858315   96.000000\n",
       "1  2023-03-05 20:10:00           92.858315             93.172310   94.000000\n",
       "2  2023-03-05 20:15:00           93.172310             94.512398   93.500000\n",
       "3  2023-03-05 20:20:00           94.512398             95.478920   93.000000\n",
       "4  2023-03-05 20:25:00           95.478920             95.036720   93.000000\n",
       "5  2023-03-05 20:30:00           95.036720             96.212967   94.000000\n",
       "6  2023-03-05 20:35:00           96.212967             97.113831   95.000000\n",
       "7  2023-03-05 20:40:00           97.113831             95.468559   95.000000\n",
       "8  2023-03-05 20:45:00           95.468559             95.056564   96.000000\n",
       "9  2023-03-05 20:50:00           95.056564             94.566658   97.000000\n",
       "10 2023-03-05 20:55:00           94.566658             98.621956   96.000000\n",
       "11 2023-03-05 21:00:00           98.621956             98.423050   95.500000\n",
       "12 2023-03-05 21:05:00           98.423050             98.881950   95.000000\n",
       "13 2023-03-05 21:10:00           98.881950            101.186317   98.000000\n",
       "14 2023-03-05 21:15:00          101.186317             99.377945   98.500000\n",
       "15 2023-03-05 21:20:00           99.377945             97.614395   99.000000\n",
       "16 2023-03-05 21:25:00           97.614395             95.799438  101.000000\n",
       "17 2023-03-05 21:30:00           95.799438             93.727676   99.666667\n",
       "18 2023-03-05 21:35:00           93.727676            100.967392   98.333333\n",
       "19 2023-03-05 21:40:00          100.967392            105.666031   97.000000\n",
       "20 2023-03-05 21:45:00          105.666031            106.477982   95.000000\n",
       "21 2023-03-05 21:50:00          106.477982            106.621536  100.000000\n",
       "22 2023-03-05 21:55:00          106.621536            106.918243  105.000000\n",
       "23 2023-03-05 22:00:00          106.918243            100.450363  106.000000"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Cell Is For N Values = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([116.27296 , 116.624115, 117.079094, 117.673996, 118.4611  ,\n",
       "       119.518776, 120.96956 , 123.01547 , 126.01288 , 130.64818 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have a value of Glucose Reading which is a single value. And we need to predict the next value of Glucose Reading. So, we will use the LSTM model to predict next 10 values of Glucose Reading\n",
    "Reading_Given = [116.0]\n",
    "Reading_Given_scaled = scaler.transform(np.array([Reading_Given]))\n",
    "\n",
    "n_features = best_parameter['n_features']\n",
    "\n",
    "# Now we will predict the next 10 values of Glucose Reading\n",
    "X_new = Reading_Given_scaled\n",
    "X_new = X_new.reshape((1, n_features, 1))\n",
    "predictions = []\n",
    "for i in range(10):\n",
    "    pred = best_model.predict(X_new)\n",
    "    predictions.append(pred)\n",
    "    X_new = pred\n",
    "    X_new = X_new.reshape((1, n_features, 1))\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "predictions = predictions.reshape(-1, 1)\n",
    "predictions_in_original_scale = scaler.inverse_transform(predictions)\n",
    "predictions_in_original_scale.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Cell Is For N_Values > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 5 into shape (1,2,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# n_features = 2\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Now we will predict the next 10 values of Glucose Reading\u001b[39;00m\n\u001b[0;32m     11\u001b[0m X_new \u001b[38;5;241m=\u001b[39m Reading_Given_scaled\n\u001b[1;32m---> 12\u001b[0m X_new \u001b[38;5;241m=\u001b[39m \u001b[43mX_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 5 into shape (1,2,1)"
     ]
    }
   ],
   "source": [
    "# Given readings\n",
    "Reading_Given = [116.0, 115.0, 118.0, 114.0, 115.75, 116.0]\n",
    "\n",
    "# Scale the given readings\n",
    "Reading_Given_scaled = scaler.transform(np.array(Reading_Given).reshape(-1, 1))\n",
    "\n",
    "n_features = best_parameter['n_features']\n",
    "# n_features = 2\n",
    "\n",
    "# Now we will predict the next 10 values of Glucose Reading\n",
    "X_new = Reading_Given_scaled\n",
    "X_new = X_new.reshape((1, n_features, 1))\n",
    "predictions = []\n",
    "\n",
    "for i in range(10):\n",
    "    pred = best_model.predict(X_new)\n",
    "    predictions.append(pred)\n",
    "    X_new = np.append(X_new, pred)\n",
    "    X_new = X_new[-n_features:]\n",
    "    X_new = X_new.reshape((1, n_features, 1))\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "predictions = predictions.reshape(-1, 1)\n",
    "predictions_in_original_scale = scaler.inverse_transform(predictions)\n",
    "predictions_in_original_scale.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([97.11383 , 96.86169 , 96.42415 , 95.86365 , 95.30283 , 94.8166  ,\n",
       "       94.45424 , 94.241455, 94.144104, 94.132034], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reading_Given = [96, 94, 93.5, 93, 94, 95, 95, 96, 97, 96]\n",
    "Reading_Given_scaled = scaler.transform(np.array(Reading_Given).reshape(-1, 1))\n",
    "\n",
    "n_features = best_parameter['n_features']\n",
    "\n",
    "X_new, _ = prepare_data(Reading_Given_scaled, n_features)\n",
    "\n",
    "# Handle the case where not enough data is available to create the required sequence\n",
    "if X_new.size == 0:\n",
    "    # Pad the sequence with the initial readings (scaled)\n",
    "    X_new = np.zeros((1, n_features, 1))\n",
    "    X_new[0, :len(Reading_Given_scaled), 0] = Reading_Given_scaled.flatten()\n",
    "else:\n",
    "    # Reshape the data to the format expected by the LSTM model\n",
    "    X_new = X_new.reshape((X_new.shape[0], n_features, 1))\n",
    "\n",
    "# Ensure X_new is the correct shape for prediction\n",
    "if X_new.shape[0] != 1:\n",
    "    X_new = X_new[-1].reshape((1, n_features, 1))\n",
    "\n",
    "predictions = []\n",
    "for i in range(10):\n",
    "    pred = best_model.predict(X_new)\n",
    "    predictions.append(pred[0, 0])  # Append the first element of the prediction\n",
    "    # Update X_new by removing the first value and adding the new prediction\n",
    "    X_new = np.append(X_new[:, 1:, :], pred.reshape(1, 1, 1), axis=1)\n",
    "\n",
    "# Inverse transform the predictions to get them back to the original scale\n",
    "predictions_in_original_scale = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "predictions_in_original_scale = predictions_in_original_scale.flatten()\n",
    "\n",
    "predictions_in_original_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BMVSI-138\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 8 into shape (1,4,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m     X_new[\u001b[38;5;241m0\u001b[39m, :\u001b[38;5;28mlen\u001b[39m(Reading_Given_scaled), \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m Reading_Given_scaled\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Reshape the data to the format expected by the LSTM model\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m \u001b[43mX_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 8 into shape (1,4,1)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
